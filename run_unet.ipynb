{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46709,"status":"ok","timestamp":1636685717695,"user":{"displayName":"이혁","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ght-yr-bTsO_ykcEl-fzdbbP8xb8FENKF76913C=s64","userId":"03546437808129049357"},"user_tz":-540},"id":"tvVTufOPpynS","outputId":"8d3fbfde-fa13-496c-9224-6d8371e9a8e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":563,"status":"ok","timestamp":1636685719706,"user":{"displayName":"이혁","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ght-yr-bTsO_ykcEl-fzdbbP8xb8FENKF76913C=s64","userId":"03546437808129049357"},"user_tz":-540},"id":"eJ_i5JBVqW4B"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YcL3mIAePz-"},"outputs":[],"source":["# python3 './train.py' \\\n","# --lr 1e-3 --batch_size 4 --num_epoch 2 \\\n","# --img_dir \"./datasets_npy/dent/train/images\" \\\n","# --label_dir \"./datasets_npy/dent/train/masks\" \\\n","# --ckpt_dir \"./checkpoint\" \\\n","# --log_dir \"./log\" \\\n","# --result_dir \"./results\" \\\n","# --mode \"train\" \\\n","# --train_continue \"off\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"oJEG-wkqnK1G"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Train: EPOCH 0001 / 0001 | BATCH 0001 \\ 1153 | LOSS 0.7839\n","Train: EPOCH 0001 / 0001 | BATCH 0002 \\ 1153 | LOSS 0.7725\n","Train: EPOCH 0001 / 0001 | BATCH 0003 \\ 1153 | LOSS 0.7525\n","Train: EPOCH 0001 / 0001 | BATCH 0004 \\ 1153 | LOSS 0.7360\n","Train: EPOCH 0001 / 0001 | BATCH 0005 \\ 1153 | LOSS 0.7174\n","Train: EPOCH 0001 / 0001 | BATCH 0006 \\ 1153 | LOSS 0.7003\n","Train: EPOCH 0001 / 0001 | BATCH 0007 \\ 1153 | LOSS 0.6831\n","Train: EPOCH 0001 / 0001 | BATCH 0008 \\ 1153 | LOSS 0.6666\n","Train: EPOCH 0001 / 0001 | BATCH 0009 \\ 1153 | LOSS 0.6544\n","Train: EPOCH 0001 / 0001 | BATCH 0010 \\ 1153 | LOSS 0.6435\n","Train: EPOCH 0001 / 0001 | BATCH 0011 \\ 1153 | LOSS 0.6317\n","Train: EPOCH 0001 / 0001 | BATCH 0012 \\ 1153 | LOSS 0.6206\n","Train: EPOCH 0001 / 0001 | BATCH 0013 \\ 1153 | LOSS 0.6108\n","Train: EPOCH 0001 / 0001 | BATCH 0014 \\ 1153 | LOSS 0.6013\n","Train: EPOCH 0001 / 0001 | BATCH 0015 \\ 1153 | LOSS 0.5923\n","Train: EPOCH 0001 / 0001 | BATCH 0016 \\ 1153 | LOSS 0.5840\n","Train: EPOCH 0001 / 0001 | BATCH 0017 \\ 1153 | LOSS 0.5763\n","Train: EPOCH 0001 / 0001 | BATCH 0018 \\ 1153 | LOSS 0.5689\n","Train: EPOCH 0001 / 0001 | BATCH 0019 \\ 1153 | LOSS 0.5624\n","Train: EPOCH 0001 / 0001 | BATCH 0020 \\ 1153 | LOSS 0.5558\n","Train: EPOCH 0001 / 0001 | BATCH 0021 \\ 1153 | LOSS 0.5497\n","Train: EPOCH 0001 / 0001 | BATCH 0022 \\ 1153 | LOSS 0.5434\n","Train: EPOCH 0001 / 0001 | BATCH 0023 \\ 1153 | LOSS 0.5374\n","Train: EPOCH 0001 / 0001 | BATCH 0024 \\ 1153 | LOSS 0.5316\n","Train: EPOCH 0001 / 0001 | BATCH 0025 \\ 1153 | LOSS 0.5280\n","Train: EPOCH 0001 / 0001 | BATCH 0026 \\ 1153 | LOSS 0.5226\n","Train: EPOCH 0001 / 0001 | BATCH 0027 \\ 1153 | LOSS 0.5181\n","Train: EPOCH 0001 / 0001 | BATCH 0028 \\ 1153 | LOSS 0.5126\n","Train: EPOCH 0001 / 0001 | BATCH 0029 \\ 1153 | LOSS 0.5074\n","Train: EPOCH 0001 / 0001 | BATCH 0030 \\ 1153 | LOSS 0.5019\n","Train: EPOCH 0001 / 0001 | BATCH 0031 \\ 1153 | LOSS 0.4969\n","Train: EPOCH 0001 / 0001 | BATCH 0032 \\ 1153 | LOSS 0.4918\n","Train: EPOCH 0001 / 0001 | BATCH 0033 \\ 1153 | LOSS 0.4867\n","Train: EPOCH 0001 / 0001 | BATCH 0034 \\ 1153 | LOSS 0.4830\n","Train: EPOCH 0001 / 0001 | BATCH 0035 \\ 1153 | LOSS 0.4783\n","Train: EPOCH 0001 / 0001 | BATCH 0036 \\ 1153 | LOSS 0.4753\n","Train: EPOCH 0001 / 0001 | BATCH 0037 \\ 1153 | LOSS 0.4707\n","Train: EPOCH 0001 / 0001 | BATCH 0038 \\ 1153 | LOSS 0.4666\n","Train: EPOCH 0001 / 0001 | BATCH 0039 \\ 1153 | LOSS 0.4625\n","Train: EPOCH 0001 / 0001 | BATCH 0040 \\ 1153 | LOSS 0.4583\n","Train: EPOCH 0001 / 0001 | BATCH 0041 \\ 1153 | LOSS 0.4547\n","Train: EPOCH 0001 / 0001 | BATCH 0042 \\ 1153 | LOSS 0.4504\n","Train: EPOCH 0001 / 0001 | BATCH 0043 \\ 1153 | LOSS 0.4463\n","Train: EPOCH 0001 / 0001 | BATCH 0044 \\ 1153 | LOSS 0.4423\n","Train: EPOCH 0001 / 0001 | BATCH 0045 \\ 1153 | LOSS 0.4401\n","Train: EPOCH 0001 / 0001 | BATCH 0046 \\ 1153 | LOSS 0.4359\n","Train: EPOCH 0001 / 0001 | BATCH 0047 \\ 1153 | LOSS 0.4321\n","Train: EPOCH 0001 / 0001 | BATCH 0048 \\ 1153 | LOSS 0.4284\n","Train: EPOCH 0001 / 0001 | BATCH 0049 \\ 1153 | LOSS 0.4248\n","Train: EPOCH 0001 / 0001 | BATCH 0050 \\ 1153 | LOSS 0.4212\n","Train: EPOCH 0001 / 0001 | BATCH 0051 \\ 1153 | LOSS 0.4187\n","Train: EPOCH 0001 / 0001 | BATCH 0052 \\ 1153 | LOSS 0.4149\n","Train: EPOCH 0001 / 0001 | BATCH 0053 \\ 1153 | LOSS 0.4118\n","Train: EPOCH 0001 / 0001 | BATCH 0054 \\ 1153 | LOSS 0.4082\n","Train: EPOCH 0001 / 0001 | BATCH 0055 \\ 1153 | LOSS 0.4052\n","Train: EPOCH 0001 / 0001 | BATCH 0056 \\ 1153 | LOSS 0.4023\n","Train: EPOCH 0001 / 0001 | BATCH 0057 \\ 1153 | LOSS 0.3990\n","Train: EPOCH 0001 / 0001 | BATCH 0058 \\ 1153 | LOSS 0.3970\n","Train: EPOCH 0001 / 0001 | BATCH 0059 \\ 1153 | LOSS 0.3940\n","Train: EPOCH 0001 / 0001 | BATCH 0060 \\ 1153 | LOSS 0.3906\n","Train: EPOCH 0001 / 0001 | BATCH 0061 \\ 1153 | LOSS 0.3879\n","Train: EPOCH 0001 / 0001 | BATCH 0062 \\ 1153 | LOSS 0.3849\n","Train: EPOCH 0001 / 0001 | BATCH 0063 \\ 1153 | LOSS 0.3819\n","Train: EPOCH 0001 / 0001 | BATCH 0064 \\ 1153 | LOSS 0.3797\n","Train: EPOCH 0001 / 0001 | BATCH 0065 \\ 1153 | LOSS 0.3770\n","Train: EPOCH 0001 / 0001 | BATCH 0066 \\ 1153 | LOSS 0.3738\n","Train: EPOCH 0001 / 0001 | BATCH 0067 \\ 1153 | LOSS 0.3707\n","Train: EPOCH 0001 / 0001 | BATCH 0068 \\ 1153 | LOSS 0.3682\n","Train: EPOCH 0001 / 0001 | BATCH 0069 \\ 1153 | LOSS 0.3654\n","Train: EPOCH 0001 / 0001 | BATCH 0070 \\ 1153 | LOSS 0.3628\n","Train: EPOCH 0001 / 0001 | BATCH 0071 \\ 1153 | LOSS 0.3600\n","Train: EPOCH 0001 / 0001 | BATCH 0072 \\ 1153 | LOSS 0.3572\n","Train: EPOCH 0001 / 0001 | BATCH 0073 \\ 1153 | LOSS 0.3545\n","Train: EPOCH 0001 / 0001 | BATCH 0074 \\ 1153 | LOSS 0.3526\n","Train: EPOCH 0001 / 0001 | BATCH 0075 \\ 1153 | LOSS 0.3507\n","Train: EPOCH 0001 / 0001 | BATCH 0076 \\ 1153 | LOSS 0.3486\n","Train: EPOCH 0001 / 0001 | BATCH 0077 \\ 1153 | LOSS 0.3459\n","Train: EPOCH 0001 / 0001 | BATCH 0078 \\ 1153 | LOSS 0.3436\n","Train: EPOCH 0001 / 0001 | BATCH 0079 \\ 1153 | LOSS 0.3409\n","Train: EPOCH 0001 / 0001 | BATCH 0080 \\ 1153 | LOSS 0.3388\n","Train: EPOCH 0001 / 0001 | BATCH 0081 \\ 1153 | LOSS 0.3369\n","Train: EPOCH 0001 / 0001 | BATCH 0082 \\ 1153 | LOSS 0.3346\n","Train: EPOCH 0001 / 0001 | BATCH 0083 \\ 1153 | LOSS 0.3322\n","Train: EPOCH 0001 / 0001 | BATCH 0084 \\ 1153 | LOSS 0.3298\n","Train: EPOCH 0001 / 0001 | BATCH 0085 \\ 1153 | LOSS 0.3275\n","Train: EPOCH 0001 / 0001 | BATCH 0086 \\ 1153 | LOSS 0.3263\n","Train: EPOCH 0001 / 0001 | BATCH 0087 \\ 1153 | LOSS 0.3244\n","Train: EPOCH 0001 / 0001 | BATCH 0088 \\ 1153 | LOSS 0.3252\n","Train: EPOCH 0001 / 0001 | BATCH 0089 \\ 1153 | LOSS 0.3233\n","Train: EPOCH 0001 / 0001 | BATCH 0090 \\ 1153 | LOSS 0.3211\n","Train: EPOCH 0001 / 0001 | BATCH 0091 \\ 1153 | LOSS 0.3190\n","Train: EPOCH 0001 / 0001 | BATCH 0092 \\ 1153 | LOSS 0.3183\n","Train: EPOCH 0001 / 0001 | BATCH 0093 \\ 1153 | LOSS 0.3162\n","Train: EPOCH 0001 / 0001 | BATCH 0094 \\ 1153 | LOSS 0.3140\n","Train: EPOCH 0001 / 0001 | BATCH 0095 \\ 1153 | LOSS 0.3120\n","Train: EPOCH 0001 / 0001 | BATCH 0096 \\ 1153 | LOSS 0.3109\n","Train: EPOCH 0001 / 0001 | BATCH 0097 \\ 1153 | LOSS 0.3088\n","Train: EPOCH 0001 / 0001 | BATCH 0098 \\ 1153 | LOSS 0.3073\n","Train: EPOCH 0001 / 0001 | BATCH 0099 \\ 1153 | LOSS 0.3052\n","Train: EPOCH 0001 / 0001 | BATCH 0100 \\ 1153 | LOSS 0.3034\n","Train: EPOCH 0001 / 0001 | BATCH 0101 \\ 1153 | LOSS 0.3016\n","Train: EPOCH 0001 / 0001 | BATCH 0102 \\ 1153 | LOSS 0.3003\n","Train: EPOCH 0001 / 0001 | BATCH 0103 \\ 1153 | LOSS 0.2989\n","Train: EPOCH 0001 / 0001 | BATCH 0104 \\ 1153 | LOSS 0.2972\n","Train: EPOCH 0001 / 0001 | BATCH 0105 \\ 1153 | LOSS 0.2957\n","Train: EPOCH 0001 / 0001 | BATCH 0106 \\ 1153 | LOSS 0.2942\n","Train: EPOCH 0001 / 0001 | BATCH 0107 \\ 1153 | LOSS 0.2924\n","Train: EPOCH 0001 / 0001 | BATCH 0108 \\ 1153 | LOSS 0.2913\n","Train: EPOCH 0001 / 0001 | BATCH 0109 \\ 1153 | LOSS 0.2899\n","Train: EPOCH 0001 / 0001 | BATCH 0110 \\ 1153 | LOSS 0.2882\n","Train: EPOCH 0001 / 0001 | BATCH 0111 \\ 1153 | LOSS 0.2867\n","Train: EPOCH 0001 / 0001 | BATCH 0112 \\ 1153 | LOSS 0.2861\n","Train: EPOCH 0001 / 0001 | BATCH 0113 \\ 1153 | LOSS 0.2850\n","Train: EPOCH 0001 / 0001 | BATCH 0114 \\ 1153 | LOSS 0.2837\n","Train: EPOCH 0001 / 0001 | BATCH 0115 \\ 1153 | LOSS 0.2822\n","Train: EPOCH 0001 / 0001 | BATCH 0116 \\ 1153 | LOSS 0.2811\n","Train: EPOCH 0001 / 0001 | BATCH 0117 \\ 1153 | LOSS 0.2800\n","Train: EPOCH 0001 / 0001 | BATCH 0118 \\ 1153 | LOSS 0.2785\n","Train: EPOCH 0001 / 0001 | BATCH 0119 \\ 1153 | LOSS 0.2778\n","Train: EPOCH 0001 / 0001 | BATCH 0120 \\ 1153 | LOSS 0.2764\n","Train: EPOCH 0001 / 0001 | BATCH 0121 \\ 1153 | LOSS 0.2757\n","Train: EPOCH 0001 / 0001 | BATCH 0122 \\ 1153 | LOSS 0.2748\n","Train: EPOCH 0001 / 0001 | BATCH 0123 \\ 1153 | LOSS 0.2734\n","Train: EPOCH 0001 / 0001 | BATCH 0124 \\ 1153 | LOSS 0.2727\n","Train: EPOCH 0001 / 0001 | BATCH 0125 \\ 1153 | LOSS 0.2715\n","Train: EPOCH 0001 / 0001 | BATCH 0126 \\ 1153 | LOSS 0.2699\n","Train: EPOCH 0001 / 0001 | BATCH 0127 \\ 1153 | LOSS 0.2687\n","Train: EPOCH 0001 / 0001 | BATCH 0128 \\ 1153 | LOSS 0.2672\n","Train: EPOCH 0001 / 0001 | BATCH 0129 \\ 1153 | LOSS 0.2659\n","Train: EPOCH 0001 / 0001 | BATCH 0130 \\ 1153 | LOSS 0.2647\n","Train: EPOCH 0001 / 0001 | BATCH 0131 \\ 1153 | LOSS 0.2634\n","Train: EPOCH 0001 / 0001 | BATCH 0132 \\ 1153 | LOSS 0.2620\n","Train: EPOCH 0001 / 0001 | BATCH 0133 \\ 1153 | LOSS 0.2610\n","Train: EPOCH 0001 / 0001 | BATCH 0134 \\ 1153 | LOSS 0.2599\n","Train: EPOCH 0001 / 0001 | BATCH 0135 \\ 1153 | LOSS 0.2587\n","Train: EPOCH 0001 / 0001 | BATCH 0136 \\ 1153 | LOSS 0.2574\n","Train: EPOCH 0001 / 0001 | BATCH 0137 \\ 1153 | LOSS 0.2564\n","Train: EPOCH 0001 / 0001 | BATCH 0138 \\ 1153 | LOSS 0.2552\n","Train: EPOCH 0001 / 0001 | BATCH 0139 \\ 1153 | LOSS 0.2547\n","Train: EPOCH 0001 / 0001 | BATCH 0140 \\ 1153 | LOSS 0.2534\n","Train: EPOCH 0001 / 0001 | BATCH 0141 \\ 1153 | LOSS 0.2521\n","Train: EPOCH 0001 / 0001 | BATCH 0142 \\ 1153 | LOSS 0.2511\n","Train: EPOCH 0001 / 0001 | BATCH 0143 \\ 1153 | LOSS 0.2498\n","Train: EPOCH 0001 / 0001 | BATCH 0144 \\ 1153 | LOSS 0.2487\n","Train: EPOCH 0001 / 0001 | BATCH 0145 \\ 1153 | LOSS 0.2476\n","Train: EPOCH 0001 / 0001 | BATCH 0146 \\ 1153 | LOSS 0.2464\n","Train: EPOCH 0001 / 0001 | BATCH 0147 \\ 1153 | LOSS 0.2455\n","Train: EPOCH 0001 / 0001 | BATCH 0148 \\ 1153 | LOSS 0.2444\n","Train: EPOCH 0001 / 0001 | BATCH 0149 \\ 1153 | LOSS 0.2434\n","Train: EPOCH 0001 / 0001 | BATCH 0150 \\ 1153 | LOSS 0.2428\n","Train: EPOCH 0001 / 0001 | BATCH 0151 \\ 1153 | LOSS 0.2421\n","Train: EPOCH 0001 / 0001 | BATCH 0152 \\ 1153 | LOSS 0.2413\n","Train: EPOCH 0001 / 0001 | BATCH 0153 \\ 1153 | LOSS 0.2401\n","Train: EPOCH 0001 / 0001 | BATCH 0154 \\ 1153 | LOSS 0.2393\n","Train: EPOCH 0001 / 0001 | BATCH 0155 \\ 1153 | LOSS 0.2381\n","Train: EPOCH 0001 / 0001 | BATCH 0156 \\ 1153 | LOSS 0.2372\n","Train: EPOCH 0001 / 0001 | BATCH 0157 \\ 1153 | LOSS 0.2360\n","Train: EPOCH 0001 / 0001 | BATCH 0158 \\ 1153 | LOSS 0.2350\n","Train: EPOCH 0001 / 0001 | BATCH 0159 \\ 1153 | LOSS 0.2341\n","Train: EPOCH 0001 / 0001 | BATCH 0160 \\ 1153 | LOSS 0.2330\n","Train: EPOCH 0001 / 0001 | BATCH 0161 \\ 1153 | LOSS 0.2321\n","Train: EPOCH 0001 / 0001 | BATCH 0162 \\ 1153 | LOSS 0.2311\n","Train: EPOCH 0001 / 0001 | BATCH 0163 \\ 1153 | LOSS 0.2305\n","Train: EPOCH 0001 / 0001 | BATCH 0164 \\ 1153 | LOSS 0.2298\n","Train: EPOCH 0001 / 0001 | BATCH 0165 \\ 1153 | LOSS 0.2298\n","Train: EPOCH 0001 / 0001 | BATCH 0166 \\ 1153 | LOSS 0.2290\n","Train: EPOCH 0001 / 0001 | BATCH 0167 \\ 1153 | LOSS 0.2280\n","Train: EPOCH 0001 / 0001 | BATCH 0168 \\ 1153 | LOSS 0.2272\n","Train: EPOCH 0001 / 0001 | BATCH 0169 \\ 1153 | LOSS 0.2262\n","Train: EPOCH 0001 / 0001 | BATCH 0170 \\ 1153 | LOSS 0.2259\n","Train: EPOCH 0001 / 0001 | BATCH 0171 \\ 1153 | LOSS 0.2253\n","Train: EPOCH 0001 / 0001 | BATCH 0172 \\ 1153 | LOSS 0.2244\n","Train: EPOCH 0001 / 0001 | BATCH 0173 \\ 1153 | LOSS 0.2234\n","Train: EPOCH 0001 / 0001 | BATCH 0174 \\ 1153 | LOSS 0.2226\n","Train: EPOCH 0001 / 0001 | BATCH 0175 \\ 1153 | LOSS 0.2221\n","Train: EPOCH 0001 / 0001 | BATCH 0176 \\ 1153 | LOSS 0.2217\n","Train: EPOCH 0001 / 0001 | BATCH 0177 \\ 1153 | LOSS 0.2209\n","Train: EPOCH 0001 / 0001 | BATCH 0178 \\ 1153 | LOSS 0.2203\n","Train: EPOCH 0001 / 0001 | BATCH 0179 \\ 1153 | LOSS 0.2196\n","Train: EPOCH 0001 / 0001 | BATCH 0180 \\ 1153 | LOSS 0.2190\n","Train: EPOCH 0001 / 0001 | BATCH 0181 \\ 1153 | LOSS 0.2183\n","Train: EPOCH 0001 / 0001 | BATCH 0182 \\ 1153 | LOSS 0.2177\n","Train: EPOCH 0001 / 0001 | BATCH 0183 \\ 1153 | LOSS 0.2168\n","Train: EPOCH 0001 / 0001 | BATCH 0184 \\ 1153 | LOSS 0.2164\n","Train: EPOCH 0001 / 0001 | BATCH 0185 \\ 1153 | LOSS 0.2156\n","Train: EPOCH 0001 / 0001 | BATCH 0186 \\ 1153 | LOSS 0.2150\n","Train: EPOCH 0001 / 0001 | BATCH 0187 \\ 1153 | LOSS 0.2141\n","Train: EPOCH 0001 / 0001 | BATCH 0188 \\ 1153 | LOSS 0.2133\n","Train: EPOCH 0001 / 0001 | BATCH 0189 \\ 1153 | LOSS 0.2132\n","Train: EPOCH 0001 / 0001 | BATCH 0190 \\ 1153 | LOSS 0.2131\n","Train: EPOCH 0001 / 0001 | BATCH 0191 \\ 1153 | LOSS 0.2122\n","Train: EPOCH 0001 / 0001 | BATCH 0192 \\ 1153 | LOSS 0.2114\n","Train: EPOCH 0001 / 0001 | BATCH 0193 \\ 1153 | LOSS 0.2106\n","Train: EPOCH 0001 / 0001 | BATCH 0194 \\ 1153 | LOSS 0.2099\n","Train: EPOCH 0001 / 0001 | BATCH 0195 \\ 1153 | LOSS 0.2091\n","Train: EPOCH 0001 / 0001 | BATCH 0196 \\ 1153 | LOSS 0.2088\n","Train: EPOCH 0001 / 0001 | BATCH 0197 \\ 1153 | LOSS 0.2081\n","Train: EPOCH 0001 / 0001 | BATCH 0198 \\ 1153 | LOSS 0.2076\n","Train: EPOCH 0001 / 0001 | BATCH 0199 \\ 1153 | LOSS 0.2073\n","Train: EPOCH 0001 / 0001 | BATCH 0200 \\ 1153 | LOSS 0.2068\n","Train: EPOCH 0001 / 0001 | BATCH 0201 \\ 1153 | LOSS 0.2061\n","Train: EPOCH 0001 / 0001 | BATCH 0202 \\ 1153 | LOSS 0.2056\n","Train: EPOCH 0001 / 0001 | BATCH 0203 \\ 1153 | LOSS 0.2050\n","Train: EPOCH 0001 / 0001 | BATCH 0204 \\ 1153 | LOSS 0.2047\n","Train: EPOCH 0001 / 0001 | BATCH 0205 \\ 1153 | LOSS 0.2042\n","Train: EPOCH 0001 / 0001 | BATCH 0206 \\ 1153 | LOSS 0.2035\n","Train: EPOCH 0001 / 0001 | BATCH 0207 \\ 1153 | LOSS 0.2029\n","Train: EPOCH 0001 / 0001 | BATCH 0208 \\ 1153 | LOSS 0.2025\n","Train: EPOCH 0001 / 0001 | BATCH 0209 \\ 1153 | LOSS 0.2019\n","Train: EPOCH 0001 / 0001 | BATCH 0210 \\ 1153 | LOSS 0.2013\n","Train: EPOCH 0001 / 0001 | BATCH 0211 \\ 1153 | LOSS 0.2007\n","Train: EPOCH 0001 / 0001 | BATCH 0212 \\ 1153 | LOSS 0.2003\n","Train: EPOCH 0001 / 0001 | BATCH 0213 \\ 1153 | LOSS 0.1996\n","Train: EPOCH 0001 / 0001 | BATCH 0214 \\ 1153 | LOSS 0.1988\n","Train: EPOCH 0001 / 0001 | BATCH 0215 \\ 1153 | LOSS 0.1980\n","Train: EPOCH 0001 / 0001 | BATCH 0216 \\ 1153 | LOSS 0.1983\n","Train: EPOCH 0001 / 0001 | BATCH 0217 \\ 1153 | LOSS 0.1981\n","Train: EPOCH 0001 / 0001 | BATCH 0218 \\ 1153 | LOSS 0.1974\n","Train: EPOCH 0001 / 0001 | BATCH 0219 \\ 1153 | LOSS 0.1966\n","Train: EPOCH 0001 / 0001 | BATCH 0220 \\ 1153 | LOSS 0.1966\n","Train: EPOCH 0001 / 0001 | BATCH 0221 \\ 1153 | LOSS 0.1961\n","Train: EPOCH 0001 / 0001 | BATCH 0222 \\ 1153 | LOSS 0.1961\n","Train: EPOCH 0001 / 0001 | BATCH 0223 \\ 1153 | LOSS 0.1956\n","Train: EPOCH 0001 / 0001 | BATCH 0224 \\ 1153 | LOSS 0.1951\n","Train: EPOCH 0001 / 0001 | BATCH 0225 \\ 1153 | LOSS 0.1947\n","Train: EPOCH 0001 / 0001 | BATCH 0226 \\ 1153 | LOSS 0.1948\n","Train: EPOCH 0001 / 0001 | BATCH 0227 \\ 1153 | LOSS 0.1942\n","Train: EPOCH 0001 / 0001 | BATCH 0228 \\ 1153 | LOSS 0.1936\n","Train: EPOCH 0001 / 0001 | BATCH 0229 \\ 1153 | LOSS 0.1932\n","Train: EPOCH 0001 / 0001 | BATCH 0230 \\ 1153 | LOSS 0.1928\n","Train: EPOCH 0001 / 0001 | BATCH 0231 \\ 1153 | LOSS 0.1923\n","Train: EPOCH 0001 / 0001 | BATCH 0232 \\ 1153 | LOSS 0.1918\n","Train: EPOCH 0001 / 0001 | BATCH 0233 \\ 1153 | LOSS 0.1920\n","Train: EPOCH 0001 / 0001 | BATCH 0234 \\ 1153 | LOSS 0.1913\n","Train: EPOCH 0001 / 0001 | BATCH 0235 \\ 1153 | LOSS 0.1906\n","Train: EPOCH 0001 / 0001 | BATCH 0236 \\ 1153 | LOSS 0.1904\n","Train: EPOCH 0001 / 0001 | BATCH 0237 \\ 1153 | LOSS 0.1900\n","Train: EPOCH 0001 / 0001 | BATCH 0238 \\ 1153 | LOSS 0.1894\n","Train: EPOCH 0001 / 0001 | BATCH 0239 \\ 1153 | LOSS 0.1890\n","Train: EPOCH 0001 / 0001 | BATCH 0240 \\ 1153 | LOSS 0.1890\n","Train: EPOCH 0001 / 0001 | BATCH 0241 \\ 1153 | LOSS 0.1885\n","Train: EPOCH 0001 / 0001 | BATCH 0242 \\ 1153 | LOSS 0.1879\n","Train: EPOCH 0001 / 0001 | BATCH 0243 \\ 1153 | LOSS 0.1874\n","Train: EPOCH 0001 / 0001 | BATCH 0244 \\ 1153 | LOSS 0.1870\n","Train: EPOCH 0001 / 0001 | BATCH 0245 \\ 1153 | LOSS 0.1864\n","Train: EPOCH 0001 / 0001 | BATCH 0246 \\ 1153 | LOSS 0.1859\n","Train: EPOCH 0001 / 0001 | BATCH 0247 \\ 1153 | LOSS 0.1854\n","Train: EPOCH 0001 / 0001 | BATCH 0248 \\ 1153 | LOSS 0.1848\n","Train: EPOCH 0001 / 0001 | BATCH 0249 \\ 1153 | LOSS 0.1842\n","Train: EPOCH 0001 / 0001 | BATCH 0250 \\ 1153 | LOSS 0.1836\n","Train: EPOCH 0001 / 0001 | BATCH 0251 \\ 1153 | LOSS 0.1831\n","Train: EPOCH 0001 / 0001 | BATCH 0252 \\ 1153 | LOSS 0.1829\n","Train: EPOCH 0001 / 0001 | BATCH 0253 \\ 1153 | LOSS 0.1826\n","Train: EPOCH 0001 / 0001 | BATCH 0254 \\ 1153 | LOSS 0.1820\n","Train: EPOCH 0001 / 0001 | BATCH 0255 \\ 1153 | LOSS 0.1814\n","Train: EPOCH 0001 / 0001 | BATCH 0256 \\ 1153 | LOSS 0.1810\n","Train: EPOCH 0001 / 0001 | BATCH 0257 \\ 1153 | LOSS 0.1805\n","Train: EPOCH 0001 / 0001 | BATCH 0258 \\ 1153 | LOSS 0.1801\n","Train: EPOCH 0001 / 0001 | BATCH 0259 \\ 1153 | LOSS 0.1796\n","Train: EPOCH 0001 / 0001 | BATCH 0260 \\ 1153 | LOSS 0.1790\n","Train: EPOCH 0001 / 0001 | BATCH 0261 \\ 1153 | LOSS 0.1785\n","Train: EPOCH 0001 / 0001 | BATCH 0262 \\ 1153 | LOSS 0.1779\n","Train: EPOCH 0001 / 0001 | BATCH 0263 \\ 1153 | LOSS 0.1780\n","Train: EPOCH 0001 / 0001 | BATCH 0264 \\ 1153 | LOSS 0.1780\n","Train: EPOCH 0001 / 0001 | BATCH 0265 \\ 1153 | LOSS 0.1775\n","Train: EPOCH 0001 / 0001 | BATCH 0266 \\ 1153 | LOSS 0.1769\n","Train: EPOCH 0001 / 0001 | BATCH 0267 \\ 1153 | LOSS 0.1765\n","Train: EPOCH 0001 / 0001 | BATCH 0268 \\ 1153 | LOSS 0.1772\n","Train: EPOCH 0001 / 0001 | BATCH 0269 \\ 1153 | LOSS 0.1767\n","Train: EPOCH 0001 / 0001 | BATCH 0270 \\ 1153 | LOSS 0.1768\n","Train: EPOCH 0001 / 0001 | BATCH 0271 \\ 1153 | LOSS 0.1768\n","Train: EPOCH 0001 / 0001 | BATCH 0272 \\ 1153 | LOSS 0.1765\n","Train: EPOCH 0001 / 0001 | BATCH 0273 \\ 1153 | LOSS 0.1760\n","Train: EPOCH 0001 / 0001 | BATCH 0274 \\ 1153 | LOSS 0.1758\n","Train: EPOCH 0001 / 0001 | BATCH 0275 \\ 1153 | LOSS 0.1755\n","Train: EPOCH 0001 / 0001 | BATCH 0276 \\ 1153 | LOSS 0.1755\n","Train: EPOCH 0001 / 0001 | BATCH 0277 \\ 1153 | LOSS 0.1755\n","Train: EPOCH 0001 / 0001 | BATCH 0278 \\ 1153 | LOSS 0.1754\n","Train: EPOCH 0001 / 0001 | BATCH 0279 \\ 1153 | LOSS 0.1749\n","Train: EPOCH 0001 / 0001 | BATCH 0280 \\ 1153 | LOSS 0.1745\n","Train: EPOCH 0001 / 0001 | BATCH 0281 \\ 1153 | LOSS 0.1742\n","Train: EPOCH 0001 / 0001 | BATCH 0282 \\ 1153 | LOSS 0.1738\n","Train: EPOCH 0001 / 0001 | BATCH 0283 \\ 1153 | LOSS 0.1740\n","Train: EPOCH 0001 / 0001 | BATCH 0284 \\ 1153 | LOSS 0.1735\n","Train: EPOCH 0001 / 0001 | BATCH 0285 \\ 1153 | LOSS 0.1736\n","Train: EPOCH 0001 / 0001 | BATCH 0286 \\ 1153 | LOSS 0.1732\n","Train: EPOCH 0001 / 0001 | BATCH 0287 \\ 1153 | LOSS 0.1730\n","Train: EPOCH 0001 / 0001 | BATCH 0288 \\ 1153 | LOSS 0.1726\n","Train: EPOCH 0001 / 0001 | BATCH 0289 \\ 1153 | LOSS 0.1723\n","Train: EPOCH 0001 / 0001 | BATCH 0290 \\ 1153 | LOSS 0.1720\n","Train: EPOCH 0001 / 0001 | BATCH 0291 \\ 1153 | LOSS 0.1717\n","Train: EPOCH 0001 / 0001 | BATCH 0292 \\ 1153 | LOSS 0.1716\n","Train: EPOCH 0001 / 0001 | BATCH 0293 \\ 1153 | LOSS 0.1716\n","Train: EPOCH 0001 / 0001 | BATCH 0294 \\ 1153 | LOSS 0.1711\n","Train: EPOCH 0001 / 0001 | BATCH 0295 \\ 1153 | LOSS 0.1711\n","Train: EPOCH 0001 / 0001 | BATCH 0296 \\ 1153 | LOSS 0.1709\n","Train: EPOCH 0001 / 0001 | BATCH 0297 \\ 1153 | LOSS 0.1709\n","Train: EPOCH 0001 / 0001 | BATCH 0298 \\ 1153 | LOSS 0.1705\n","Train: EPOCH 0001 / 0001 | BATCH 0299 \\ 1153 | LOSS 0.1701\n","Train: EPOCH 0001 / 0001 | BATCH 0300 \\ 1153 | LOSS 0.1697\n","Train: EPOCH 0001 / 0001 | BATCH 0301 \\ 1153 | LOSS 0.1698\n","Train: EPOCH 0001 / 0001 | BATCH 0302 \\ 1153 | LOSS 0.1694\n","Train: EPOCH 0001 / 0001 | BATCH 0303 \\ 1153 | LOSS 0.1690\n","Train: EPOCH 0001 / 0001 | BATCH 0304 \\ 1153 | LOSS 0.1686\n","Train: EPOCH 0001 / 0001 | BATCH 0305 \\ 1153 | LOSS 0.1683\n","Train: EPOCH 0001 / 0001 | BATCH 0306 \\ 1153 | LOSS 0.1679\n","Train: EPOCH 0001 / 0001 | BATCH 0307 \\ 1153 | LOSS 0.1676\n","Train: EPOCH 0001 / 0001 | BATCH 0308 \\ 1153 | LOSS 0.1672\n","Train: EPOCH 0001 / 0001 | BATCH 0309 \\ 1153 | LOSS 0.1670\n","Train: EPOCH 0001 / 0001 | BATCH 0310 \\ 1153 | LOSS 0.1666\n","Train: EPOCH 0001 / 0001 | BATCH 0311 \\ 1153 | LOSS 0.1662\n","Train: EPOCH 0001 / 0001 | BATCH 0312 \\ 1153 | LOSS 0.1661\n","Train: EPOCH 0001 / 0001 | BATCH 0313 \\ 1153 | LOSS 0.1657\n","Train: EPOCH 0001 / 0001 | BATCH 0314 \\ 1153 | LOSS 0.1653\n","Train: EPOCH 0001 / 0001 | BATCH 0315 \\ 1153 | LOSS 0.1649\n","Train: EPOCH 0001 / 0001 | BATCH 0316 \\ 1153 | LOSS 0.1649\n","Train: EPOCH 0001 / 0001 | BATCH 0317 \\ 1153 | LOSS 0.1644\n","Train: EPOCH 0001 / 0001 | BATCH 0318 \\ 1153 | LOSS 0.1642\n","Train: EPOCH 0001 / 0001 | BATCH 0319 \\ 1153 | LOSS 0.1641\n","Train: EPOCH 0001 / 0001 | BATCH 0320 \\ 1153 | LOSS 0.1640\n","Train: EPOCH 0001 / 0001 | BATCH 0321 \\ 1153 | LOSS 0.1636\n","Train: EPOCH 0001 / 0001 | BATCH 0322 \\ 1153 | LOSS 0.1634\n","Train: EPOCH 0001 / 0001 | BATCH 0323 \\ 1153 | LOSS 0.1630\n","Train: EPOCH 0001 / 0001 | BATCH 0324 \\ 1153 | LOSS 0.1625\n","Train: EPOCH 0001 / 0001 | BATCH 0325 \\ 1153 | LOSS 0.1622\n","Train: EPOCH 0001 / 0001 | BATCH 0326 \\ 1153 | LOSS 0.1619\n","Train: EPOCH 0001 / 0001 | BATCH 0327 \\ 1153 | LOSS 0.1617\n","Train: EPOCH 0001 / 0001 | BATCH 0328 \\ 1153 | LOSS 0.1619\n","Train: EPOCH 0001 / 0001 | BATCH 0329 \\ 1153 | LOSS 0.1616\n","Train: EPOCH 0001 / 0001 | BATCH 0330 \\ 1153 | LOSS 0.1615\n","Train: EPOCH 0001 / 0001 | BATCH 0331 \\ 1153 | LOSS 0.1611\n","Train: EPOCH 0001 / 0001 | BATCH 0332 \\ 1153 | LOSS 0.1607\n","Train: EPOCH 0001 / 0001 | BATCH 0333 \\ 1153 | LOSS 0.1603\n","Train: EPOCH 0001 / 0001 | BATCH 0334 \\ 1153 | LOSS 0.1601\n","Train: EPOCH 0001 / 0001 | BATCH 0335 \\ 1153 | LOSS 0.1599\n","Train: EPOCH 0001 / 0001 | BATCH 0336 \\ 1153 | LOSS 0.1597\n","Train: EPOCH 0001 / 0001 | BATCH 0337 \\ 1153 | LOSS 0.1594\n","Train: EPOCH 0001 / 0001 | BATCH 0338 \\ 1153 | LOSS 0.1590\n","Train: EPOCH 0001 / 0001 | BATCH 0339 \\ 1153 | LOSS 0.1588\n","Train: EPOCH 0001 / 0001 | BATCH 0340 \\ 1153 | LOSS 0.1586\n","Train: EPOCH 0001 / 0001 | BATCH 0341 \\ 1153 | LOSS 0.1583\n","Train: EPOCH 0001 / 0001 | BATCH 0342 \\ 1153 | LOSS 0.1579\n","Train: EPOCH 0001 / 0001 | BATCH 0343 \\ 1153 | LOSS 0.1578\n","Train: EPOCH 0001 / 0001 | BATCH 0344 \\ 1153 | LOSS 0.1575\n","Train: EPOCH 0001 / 0001 | BATCH 0345 \\ 1153 | LOSS 0.1571\n","Train: EPOCH 0001 / 0001 | BATCH 0346 \\ 1153 | LOSS 0.1567\n","Train: EPOCH 0001 / 0001 | BATCH 0347 \\ 1153 | LOSS 0.1566\n","Train: EPOCH 0001 / 0001 | BATCH 0348 \\ 1153 | LOSS 0.1562\n","Train: EPOCH 0001 / 0001 | BATCH 0349 \\ 1153 | LOSS 0.1561\n","Train: EPOCH 0001 / 0001 | BATCH 0350 \\ 1153 | LOSS 0.1558\n","Train: EPOCH 0001 / 0001 | BATCH 0351 \\ 1153 | LOSS 0.1564\n","Train: EPOCH 0001 / 0001 | BATCH 0352 \\ 1153 | LOSS 0.1561\n","Train: EPOCH 0001 / 0001 | BATCH 0353 \\ 1153 | LOSS 0.1558\n","Train: EPOCH 0001 / 0001 | BATCH 0354 \\ 1153 | LOSS 0.1556\n","Train: EPOCH 0001 / 0001 | BATCH 0355 \\ 1153 | LOSS 0.1554\n","Train: EPOCH 0001 / 0001 | BATCH 0356 \\ 1153 | LOSS 0.1553\n","Train: EPOCH 0001 / 0001 | BATCH 0357 \\ 1153 | LOSS 0.1549\n","Train: EPOCH 0001 / 0001 | BATCH 0358 \\ 1153 | LOSS 0.1548\n","Train: EPOCH 0001 / 0001 | BATCH 0359 \\ 1153 | LOSS 0.1544\n","Train: EPOCH 0001 / 0001 | BATCH 0360 \\ 1153 | LOSS 0.1543\n","Train: EPOCH 0001 / 0001 | BATCH 0361 \\ 1153 | LOSS 0.1545\n","Train: EPOCH 0001 / 0001 | BATCH 0362 \\ 1153 | LOSS 0.1543\n","Train: EPOCH 0001 / 0001 | BATCH 0363 \\ 1153 | LOSS 0.1540\n","Train: EPOCH 0001 / 0001 | BATCH 0364 \\ 1153 | LOSS 0.1536\n","Train: EPOCH 0001 / 0001 | BATCH 0365 \\ 1153 | LOSS 0.1533\n","Train: EPOCH 0001 / 0001 | BATCH 0366 \\ 1153 | LOSS 0.1534\n","Train: EPOCH 0001 / 0001 | BATCH 0367 \\ 1153 | LOSS 0.1531\n","Train: EPOCH 0001 / 0001 | BATCH 0368 \\ 1153 | LOSS 0.1527\n","Train: EPOCH 0001 / 0001 | BATCH 0369 \\ 1153 | LOSS 0.1525\n","Train: EPOCH 0001 / 0001 | BATCH 0370 \\ 1153 | LOSS 0.1522\n","Train: EPOCH 0001 / 0001 | BATCH 0371 \\ 1153 | LOSS 0.1523\n","Train: EPOCH 0001 / 0001 | BATCH 0372 \\ 1153 | LOSS 0.1520\n","Train: EPOCH 0001 / 0001 | BATCH 0373 \\ 1153 | LOSS 0.1517\n","Train: EPOCH 0001 / 0001 | BATCH 0374 \\ 1153 | LOSS 0.1514\n","Train: EPOCH 0001 / 0001 | BATCH 0375 \\ 1153 | LOSS 0.1515\n","Train: EPOCH 0001 / 0001 | BATCH 0376 \\ 1153 | LOSS 0.1515\n","Train: EPOCH 0001 / 0001 | BATCH 0377 \\ 1153 | LOSS 0.1513\n","Train: EPOCH 0001 / 0001 | BATCH 0378 \\ 1153 | LOSS 0.1512\n","Train: EPOCH 0001 / 0001 | BATCH 0379 \\ 1153 | LOSS 0.1510\n","Train: EPOCH 0001 / 0001 | BATCH 0380 \\ 1153 | LOSS 0.1508\n","Train: EPOCH 0001 / 0001 | BATCH 0381 \\ 1153 | LOSS 0.1508\n","Train: EPOCH 0001 / 0001 | BATCH 0382 \\ 1153 | LOSS 0.1507\n","Train: EPOCH 0001 / 0001 | BATCH 0383 \\ 1153 | LOSS 0.1506\n","Train: EPOCH 0001 / 0001 | BATCH 0384 \\ 1153 | LOSS 0.1503\n","Train: EPOCH 0001 / 0001 | BATCH 0385 \\ 1153 | LOSS 0.1500\n","Train: EPOCH 0001 / 0001 | BATCH 0386 \\ 1153 | LOSS 0.1496\n","Train: EPOCH 0001 / 0001 | BATCH 0387 \\ 1153 | LOSS 0.1495\n","Train: EPOCH 0001 / 0001 | BATCH 0388 \\ 1153 | LOSS 0.1493\n","Train: EPOCH 0001 / 0001 | BATCH 0389 \\ 1153 | LOSS 0.1491\n","Train: EPOCH 0001 / 0001 | BATCH 0390 \\ 1153 | LOSS 0.1489\n","Train: EPOCH 0001 / 0001 | BATCH 0391 \\ 1153 | LOSS 0.1486\n","Train: EPOCH 0001 / 0001 | BATCH 0392 \\ 1153 | LOSS 0.1484\n","Train: EPOCH 0001 / 0001 | BATCH 0393 \\ 1153 | LOSS 0.1482\n","Train: EPOCH 0001 / 0001 | BATCH 0394 \\ 1153 | LOSS 0.1481\n","Train: EPOCH 0001 / 0001 | BATCH 0395 \\ 1153 | LOSS 0.1479\n","Train: EPOCH 0001 / 0001 | BATCH 0396 \\ 1153 | LOSS 0.1476\n","Train: EPOCH 0001 / 0001 | BATCH 0397 \\ 1153 | LOSS 0.1475\n","Train: EPOCH 0001 / 0001 | BATCH 0398 \\ 1153 | LOSS 0.1472\n","Train: EPOCH 0001 / 0001 | BATCH 0399 \\ 1153 | LOSS 0.1473\n","Train: EPOCH 0001 / 0001 | BATCH 0400 \\ 1153 | LOSS 0.1475\n","Train: EPOCH 0001 / 0001 | BATCH 0401 \\ 1153 | LOSS 0.1472\n","Train: EPOCH 0001 / 0001 | BATCH 0402 \\ 1153 | LOSS 0.1469\n","Train: EPOCH 0001 / 0001 | BATCH 0403 \\ 1153 | LOSS 0.1468\n","Train: EPOCH 0001 / 0001 | BATCH 0404 \\ 1153 | LOSS 0.1467\n","Train: EPOCH 0001 / 0001 | BATCH 0405 \\ 1153 | LOSS 0.1464\n","Train: EPOCH 0001 / 0001 | BATCH 0406 \\ 1153 | LOSS 0.1467\n","Train: EPOCH 0001 / 0001 | BATCH 0407 \\ 1153 | LOSS 0.1469\n","Train: EPOCH 0001 / 0001 | BATCH 0408 \\ 1153 | LOSS 0.1467\n","Train: EPOCH 0001 / 0001 | BATCH 0409 \\ 1153 | LOSS 0.1464\n","Train: EPOCH 0001 / 0001 | BATCH 0410 \\ 1153 | LOSS 0.1464\n","Train: EPOCH 0001 / 0001 | BATCH 0411 \\ 1153 | LOSS 0.1462\n","Train: EPOCH 0001 / 0001 | BATCH 0412 \\ 1153 | LOSS 0.1459\n","Train: EPOCH 0001 / 0001 | BATCH 0413 \\ 1153 | LOSS 0.1456\n","Train: EPOCH 0001 / 0001 | BATCH 0414 \\ 1153 | LOSS 0.1455\n","Train: EPOCH 0001 / 0001 | BATCH 0415 \\ 1153 | LOSS 0.1455\n","Train: EPOCH 0001 / 0001 | BATCH 0416 \\ 1153 | LOSS 0.1452\n","Train: EPOCH 0001 / 0001 | BATCH 0417 \\ 1153 | LOSS 0.1452\n","Train: EPOCH 0001 / 0001 | BATCH 0418 \\ 1153 | LOSS 0.1451\n","Train: EPOCH 0001 / 0001 | BATCH 0419 \\ 1153 | LOSS 0.1450\n","Train: EPOCH 0001 / 0001 | BATCH 0420 \\ 1153 | LOSS 0.1448\n","Train: EPOCH 0001 / 0001 | BATCH 0421 \\ 1153 | LOSS 0.1445\n","Train: EPOCH 0001 / 0001 | BATCH 0422 \\ 1153 | LOSS 0.1445\n","Train: EPOCH 0001 / 0001 | BATCH 0423 \\ 1153 | LOSS 0.1444\n","Train: EPOCH 0001 / 0001 | BATCH 0424 \\ 1153 | LOSS 0.1446\n","Train: EPOCH 0001 / 0001 | BATCH 0425 \\ 1153 | LOSS 0.1443\n","Train: EPOCH 0001 / 0001 | BATCH 0426 \\ 1153 | LOSS 0.1440\n","Train: EPOCH 0001 / 0001 | BATCH 0427 \\ 1153 | LOSS 0.1439\n","Train: EPOCH 0001 / 0001 | BATCH 0428 \\ 1153 | LOSS 0.1437\n","Train: EPOCH 0001 / 0001 | BATCH 0429 \\ 1153 | LOSS 0.1435\n","Train: EPOCH 0001 / 0001 | BATCH 0430 \\ 1153 | LOSS 0.1434\n","Train: EPOCH 0001 / 0001 | BATCH 0431 \\ 1153 | LOSS 0.1433\n","Train: EPOCH 0001 / 0001 | BATCH 0432 \\ 1153 | LOSS 0.1432\n","Train: EPOCH 0001 / 0001 | BATCH 0433 \\ 1153 | LOSS 0.1429\n","Train: EPOCH 0001 / 0001 | BATCH 0434 \\ 1153 | LOSS 0.1431\n","Train: EPOCH 0001 / 0001 | BATCH 0435 \\ 1153 | LOSS 0.1433\n","Train: EPOCH 0001 / 0001 | BATCH 0436 \\ 1153 | LOSS 0.1431\n","Train: EPOCH 0001 / 0001 | BATCH 0437 \\ 1153 | LOSS 0.1430\n","Train: EPOCH 0001 / 0001 | BATCH 0438 \\ 1153 | LOSS 0.1430\n","Train: EPOCH 0001 / 0001 | BATCH 0439 \\ 1153 | LOSS 0.1432\n","Train: EPOCH 0001 / 0001 | BATCH 0440 \\ 1153 | LOSS 0.1431\n","Train: EPOCH 0001 / 0001 | BATCH 0441 \\ 1153 | LOSS 0.1433\n","Train: EPOCH 0001 / 0001 | BATCH 0442 \\ 1153 | LOSS 0.1432\n","Train: EPOCH 0001 / 0001 | BATCH 0443 \\ 1153 | LOSS 0.1431\n","Train: EPOCH 0001 / 0001 | BATCH 0444 \\ 1153 | LOSS 0.1430\n","Train: EPOCH 0001 / 0001 | BATCH 0445 \\ 1153 | LOSS 0.1428\n","Train: EPOCH 0001 / 0001 | BATCH 0446 \\ 1153 | LOSS 0.1426\n","Train: EPOCH 0001 / 0001 | BATCH 0447 \\ 1153 | LOSS 0.1427\n","Train: EPOCH 0001 / 0001 | BATCH 0448 \\ 1153 | LOSS 0.1424\n","Train: EPOCH 0001 / 0001 | BATCH 0449 \\ 1153 | LOSS 0.1423\n","Train: EPOCH 0001 / 0001 | BATCH 0450 \\ 1153 | LOSS 0.1421\n","Train: EPOCH 0001 / 0001 | BATCH 0451 \\ 1153 | LOSS 0.1420\n","Train: EPOCH 0001 / 0001 | BATCH 0452 \\ 1153 | LOSS 0.1418\n","Train: EPOCH 0001 / 0001 | BATCH 0453 \\ 1153 | LOSS 0.1417\n","Train: EPOCH 0001 / 0001 | BATCH 0454 \\ 1153 | LOSS 0.1415\n","Train: EPOCH 0001 / 0001 | BATCH 0455 \\ 1153 | LOSS 0.1414\n","Train: EPOCH 0001 / 0001 | BATCH 0456 \\ 1153 | LOSS 0.1412\n","Train: EPOCH 0001 / 0001 | BATCH 0457 \\ 1153 | LOSS 0.1410\n","Train: EPOCH 0001 / 0001 | BATCH 0458 \\ 1153 | LOSS 0.1410\n","Train: EPOCH 0001 / 0001 | BATCH 0459 \\ 1153 | LOSS 0.1407\n","Train: EPOCH 0001 / 0001 | BATCH 0460 \\ 1153 | LOSS 0.1405\n","Train: EPOCH 0001 / 0001 | BATCH 0461 \\ 1153 | LOSS 0.1404\n","Train: EPOCH 0001 / 0001 | BATCH 0462 \\ 1153 | LOSS 0.1402\n","Train: EPOCH 0001 / 0001 | BATCH 0463 \\ 1153 | LOSS 0.1403\n","Train: EPOCH 0001 / 0001 | BATCH 0464 \\ 1153 | LOSS 0.1402\n","Train: EPOCH 0001 / 0001 | BATCH 0465 \\ 1153 | LOSS 0.1402\n","Train: EPOCH 0001 / 0001 | BATCH 0466 \\ 1153 | LOSS 0.1400\n","Train: EPOCH 0001 / 0001 | BATCH 0467 \\ 1153 | LOSS 0.1398\n","Train: EPOCH 0001 / 0001 | BATCH 0468 \\ 1153 | LOSS 0.1397\n","Train: EPOCH 0001 / 0001 | BATCH 0469 \\ 1153 | LOSS 0.1394\n","Train: EPOCH 0001 / 0001 | BATCH 0470 \\ 1153 | LOSS 0.1392\n","Train: EPOCH 0001 / 0001 | BATCH 0471 \\ 1153 | LOSS 0.1390\n","Train: EPOCH 0001 / 0001 | BATCH 0472 \\ 1153 | LOSS 0.1389\n","Train: EPOCH 0001 / 0001 | BATCH 0473 \\ 1153 | LOSS 0.1387\n","Train: EPOCH 0001 / 0001 | BATCH 0474 \\ 1153 | LOSS 0.1385\n","Train: EPOCH 0001 / 0001 | BATCH 0475 \\ 1153 | LOSS 0.1382\n","Train: EPOCH 0001 / 0001 | BATCH 0476 \\ 1153 | LOSS 0.1381\n","Train: EPOCH 0001 / 0001 | BATCH 0477 \\ 1153 | LOSS 0.1379\n","Train: EPOCH 0001 / 0001 | BATCH 0478 \\ 1153 | LOSS 0.1380\n","Train: EPOCH 0001 / 0001 | BATCH 0479 \\ 1153 | LOSS 0.1382\n","Train: EPOCH 0001 / 0001 | BATCH 0480 \\ 1153 | LOSS 0.1382\n","Train: EPOCH 0001 / 0001 | BATCH 0481 \\ 1153 | LOSS 0.1381\n","Train: EPOCH 0001 / 0001 | BATCH 0482 \\ 1153 | LOSS 0.1379\n","Train: EPOCH 0001 / 0001 | BATCH 0483 \\ 1153 | LOSS 0.1378\n","Train: EPOCH 0001 / 0001 | BATCH 0484 \\ 1153 | LOSS 0.1378\n","Train: EPOCH 0001 / 0001 | BATCH 0485 \\ 1153 | LOSS 0.1376\n","Train: EPOCH 0001 / 0001 | BATCH 0486 \\ 1153 | LOSS 0.1379\n","Train: EPOCH 0001 / 0001 | BATCH 0487 \\ 1153 | LOSS 0.1379\n","Train: EPOCH 0001 / 0001 | BATCH 0488 \\ 1153 | LOSS 0.1377\n","Train: EPOCH 0001 / 0001 | BATCH 0489 \\ 1153 | LOSS 0.1374\n","Train: EPOCH 0001 / 0001 | BATCH 0490 \\ 1153 | LOSS 0.1373\n","Train: EPOCH 0001 / 0001 | BATCH 0491 \\ 1153 | LOSS 0.1371\n","Train: EPOCH 0001 / 0001 | BATCH 0492 \\ 1153 | LOSS 0.1370\n","Train: EPOCH 0001 / 0001 | BATCH 0493 \\ 1153 | LOSS 0.1371\n","Train: EPOCH 0001 / 0001 | BATCH 0494 \\ 1153 | LOSS 0.1368\n","Train: EPOCH 0001 / 0001 | BATCH 0495 \\ 1153 | LOSS 0.1367\n","Train: EPOCH 0001 / 0001 | BATCH 0496 \\ 1153 | LOSS 0.1369\n","Train: EPOCH 0001 / 0001 | BATCH 0497 \\ 1153 | LOSS 0.1368\n","Train: EPOCH 0001 / 0001 | BATCH 0498 \\ 1153 | LOSS 0.1367\n","Train: EPOCH 0001 / 0001 | BATCH 0499 \\ 1153 | LOSS 0.1365\n","Train: EPOCH 0001 / 0001 | BATCH 0500 \\ 1153 | LOSS 0.1364\n","Train: EPOCH 0001 / 0001 | BATCH 0501 \\ 1153 | LOSS 0.1363\n","Train: EPOCH 0001 / 0001 | BATCH 0502 \\ 1153 | LOSS 0.1361\n","Train: EPOCH 0001 / 0001 | BATCH 0503 \\ 1153 | LOSS 0.1363\n","Train: EPOCH 0001 / 0001 | BATCH 0504 \\ 1153 | LOSS 0.1361\n","Train: EPOCH 0001 / 0001 | BATCH 0505 \\ 1153 | LOSS 0.1361\n","Train: EPOCH 0001 / 0001 | BATCH 0506 \\ 1153 | LOSS 0.1360\n","Train: EPOCH 0001 / 0001 | BATCH 0507 \\ 1153 | LOSS 0.1362\n","Train: EPOCH 0001 / 0001 | BATCH 0508 \\ 1153 | LOSS 0.1360\n","Train: EPOCH 0001 / 0001 | BATCH 0509 \\ 1153 | LOSS 0.1359\n","Train: EPOCH 0001 / 0001 | BATCH 0510 \\ 1153 | LOSS 0.1360\n","Train: EPOCH 0001 / 0001 | BATCH 0511 \\ 1153 | LOSS 0.1358\n","Train: EPOCH 0001 / 0001 | BATCH 0512 \\ 1153 | LOSS 0.1357\n","Train: EPOCH 0001 / 0001 | BATCH 0513 \\ 1153 | LOSS 0.1358\n","Train: EPOCH 0001 / 0001 | BATCH 0514 \\ 1153 | LOSS 0.1356\n","Train: EPOCH 0001 / 0001 | BATCH 0515 \\ 1153 | LOSS 0.1355\n","Train: EPOCH 0001 / 0001 | BATCH 0516 \\ 1153 | LOSS 0.1354\n","Train: EPOCH 0001 / 0001 | BATCH 0517 \\ 1153 | LOSS 0.1353\n","Train: EPOCH 0001 / 0001 | BATCH 0518 \\ 1153 | LOSS 0.1350\n","Train: EPOCH 0001 / 0001 | BATCH 0519 \\ 1153 | LOSS 0.1353\n","Train: EPOCH 0001 / 0001 | BATCH 0520 \\ 1153 | LOSS 0.1357\n","Train: EPOCH 0001 / 0001 | BATCH 0521 \\ 1153 | LOSS 0.1356\n","Train: EPOCH 0001 / 0001 | BATCH 0522 \\ 1153 | LOSS 0.1360\n","Train: EPOCH 0001 / 0001 | BATCH 0523 \\ 1153 | LOSS 0.1358\n","Train: EPOCH 0001 / 0001 | BATCH 0524 \\ 1153 | LOSS 0.1360\n","Train: EPOCH 0001 / 0001 | BATCH 0525 \\ 1153 | LOSS 0.1359\n","Train: EPOCH 0001 / 0001 | BATCH 0526 \\ 1153 | LOSS 0.1358\n","Train: EPOCH 0001 / 0001 | BATCH 0527 \\ 1153 | LOSS 0.1358\n","Train: EPOCH 0001 / 0001 | BATCH 0528 \\ 1153 | LOSS 0.1359\n","Train: EPOCH 0001 / 0001 | BATCH 0529 \\ 1153 | LOSS 0.1357\n","Train: EPOCH 0001 / 0001 | BATCH 0530 \\ 1153 | LOSS 0.1356\n","Train: EPOCH 0001 / 0001 | BATCH 0531 \\ 1153 | LOSS 0.1354\n","Train: EPOCH 0001 / 0001 | BATCH 0532 \\ 1153 | LOSS 0.1353\n","Train: EPOCH 0001 / 0001 | BATCH 0533 \\ 1153 | LOSS 0.1352\n","Train: EPOCH 0001 / 0001 | BATCH 0534 \\ 1153 | LOSS 0.1351\n","Train: EPOCH 0001 / 0001 | BATCH 0535 \\ 1153 | LOSS 0.1349\n","Train: EPOCH 0001 / 0001 | BATCH 0536 \\ 1153 | LOSS 0.1348\n","Train: EPOCH 0001 / 0001 | BATCH 0537 \\ 1153 | LOSS 0.1346\n","Train: EPOCH 0001 / 0001 | BATCH 0538 \\ 1153 | LOSS 0.1345\n","Train: EPOCH 0001 / 0001 | BATCH 0539 \\ 1153 | LOSS 0.1343\n","Train: EPOCH 0001 / 0001 | BATCH 0540 \\ 1153 | LOSS 0.1344\n","Train: EPOCH 0001 / 0001 | BATCH 0541 \\ 1153 | LOSS 0.1343\n","Train: EPOCH 0001 / 0001 | BATCH 0542 \\ 1153 | LOSS 0.1342\n","Train: EPOCH 0001 / 0001 | BATCH 0543 \\ 1153 | LOSS 0.1340\n","Train: EPOCH 0001 / 0001 | BATCH 0544 \\ 1153 | LOSS 0.1338\n","Train: EPOCH 0001 / 0001 | BATCH 0545 \\ 1153 | LOSS 0.1340\n","Train: EPOCH 0001 / 0001 | BATCH 0546 \\ 1153 | LOSS 0.1338\n","Train: EPOCH 0001 / 0001 | BATCH 0547 \\ 1153 | LOSS 0.1336\n","Train: EPOCH 0001 / 0001 | BATCH 0548 \\ 1153 | LOSS 0.1335\n","Train: EPOCH 0001 / 0001 | BATCH 0549 \\ 1153 | LOSS 0.1334\n","Train: EPOCH 0001 / 0001 | BATCH 0550 \\ 1153 | LOSS 0.1332\n","Train: EPOCH 0001 / 0001 | BATCH 0551 \\ 1153 | LOSS 0.1331\n","Train: EPOCH 0001 / 0001 | BATCH 0552 \\ 1153 | LOSS 0.1330\n","Train: EPOCH 0001 / 0001 | BATCH 0553 \\ 1153 | LOSS 0.1328\n","Train: EPOCH 0001 / 0001 | BATCH 0554 \\ 1153 | LOSS 0.1328\n","Train: EPOCH 0001 / 0001 | BATCH 0555 \\ 1153 | LOSS 0.1329\n","Train: EPOCH 0001 / 0001 | BATCH 0556 \\ 1153 | LOSS 0.1327\n","Train: EPOCH 0001 / 0001 | BATCH 0557 \\ 1153 | LOSS 0.1326\n","Train: EPOCH 0001 / 0001 | BATCH 0558 \\ 1153 | LOSS 0.1328\n","Train: EPOCH 0001 / 0001 | BATCH 0559 \\ 1153 | LOSS 0.1328\n","Train: EPOCH 0001 / 0001 | BATCH 0560 \\ 1153 | LOSS 0.1326\n","Train: EPOCH 0001 / 0001 | BATCH 0561 \\ 1153 | LOSS 0.1325\n","Train: EPOCH 0001 / 0001 | BATCH 0562 \\ 1153 | LOSS 0.1323\n","Train: EPOCH 0001 / 0001 | BATCH 0563 \\ 1153 | LOSS 0.1321\n","Train: EPOCH 0001 / 0001 | BATCH 0564 \\ 1153 | LOSS 0.1320\n","Train: EPOCH 0001 / 0001 | BATCH 0565 \\ 1153 | LOSS 0.1319\n","Train: EPOCH 0001 / 0001 | BATCH 0566 \\ 1153 | LOSS 0.1318\n","Train: EPOCH 0001 / 0001 | BATCH 0567 \\ 1153 | LOSS 0.1317\n","Train: EPOCH 0001 / 0001 | BATCH 0568 \\ 1153 | LOSS 0.1315\n","Train: EPOCH 0001 / 0001 | BATCH 0569 \\ 1153 | LOSS 0.1314\n","Train: EPOCH 0001 / 0001 | BATCH 0570 \\ 1153 | LOSS 0.1312\n","Train: EPOCH 0001 / 0001 | BATCH 0571 \\ 1153 | LOSS 0.1310\n","Train: EPOCH 0001 / 0001 | BATCH 0572 \\ 1153 | LOSS 0.1309\n","Train: EPOCH 0001 / 0001 | BATCH 0573 \\ 1153 | LOSS 0.1307\n","Train: EPOCH 0001 / 0001 | BATCH 0574 \\ 1153 | LOSS 0.1305\n","Train: EPOCH 0001 / 0001 | BATCH 0575 \\ 1153 | LOSS 0.1304\n","Train: EPOCH 0001 / 0001 | BATCH 0576 \\ 1153 | LOSS 0.1302\n","Train: EPOCH 0001 / 0001 | BATCH 0577 \\ 1153 | LOSS 0.1301\n","Train: EPOCH 0001 / 0001 | BATCH 0578 \\ 1153 | LOSS 0.1303\n","Train: EPOCH 0001 / 0001 | BATCH 0579 \\ 1153 | LOSS 0.1305\n","Train: EPOCH 0001 / 0001 | BATCH 0580 \\ 1153 | LOSS 0.1305\n","Train: EPOCH 0001 / 0001 | BATCH 0581 \\ 1153 | LOSS 0.1307\n","Train: EPOCH 0001 / 0001 | BATCH 0582 \\ 1153 | LOSS 0.1305\n","Train: EPOCH 0001 / 0001 | BATCH 0583 \\ 1153 | LOSS 0.1304\n","Train: EPOCH 0001 / 0001 | BATCH 0584 \\ 1153 | LOSS 0.1305\n","Train: EPOCH 0001 / 0001 | BATCH 0585 \\ 1153 | LOSS 0.1304\n","Train: EPOCH 0001 / 0001 | BATCH 0586 \\ 1153 | LOSS 0.1302\n","Train: EPOCH 0001 / 0001 | BATCH 0587 \\ 1153 | LOSS 0.1301\n","Train: EPOCH 0001 / 0001 | BATCH 0588 \\ 1153 | LOSS 0.1300\n","Train: EPOCH 0001 / 0001 | BATCH 0589 \\ 1153 | LOSS 0.1299\n","Train: EPOCH 0001 / 0001 | BATCH 0590 \\ 1153 | LOSS 0.1298\n","Train: EPOCH 0001 / 0001 | BATCH 0591 \\ 1153 | LOSS 0.1296\n","Train: EPOCH 0001 / 0001 | BATCH 0592 \\ 1153 | LOSS 0.1295\n","Train: EPOCH 0001 / 0001 | BATCH 0593 \\ 1153 | LOSS 0.1295\n","Train: EPOCH 0001 / 0001 | BATCH 0594 \\ 1153 | LOSS 0.1293\n","Train: EPOCH 0001 / 0001 | BATCH 0595 \\ 1153 | LOSS 0.1292\n","Train: EPOCH 0001 / 0001 | BATCH 0596 \\ 1153 | LOSS 0.1291\n","Train: EPOCH 0001 / 0001 | BATCH 0597 \\ 1153 | LOSS 0.1291\n","Train: EPOCH 0001 / 0001 | BATCH 0598 \\ 1153 | LOSS 0.1290\n","Train: EPOCH 0001 / 0001 | BATCH 0599 \\ 1153 | LOSS 0.1288\n","Train: EPOCH 0001 / 0001 | BATCH 0600 \\ 1153 | LOSS 0.1288\n","Train: EPOCH 0001 / 0001 | BATCH 0601 \\ 1153 | LOSS 0.1286\n","Train: EPOCH 0001 / 0001 | BATCH 0602 \\ 1153 | LOSS 0.1284\n","Train: EPOCH 0001 / 0001 | BATCH 0603 \\ 1153 | LOSS 0.1283\n","Train: EPOCH 0001 / 0001 | BATCH 0604 \\ 1153 | LOSS 0.1281\n","Train: EPOCH 0001 / 0001 | BATCH 0605 \\ 1153 | LOSS 0.1281\n","Train: EPOCH 0001 / 0001 | BATCH 0606 \\ 1153 | LOSS 0.1279\n","Train: EPOCH 0001 / 0001 | BATCH 0607 \\ 1153 | LOSS 0.1277\n","Train: EPOCH 0001 / 0001 | BATCH 0608 \\ 1153 | LOSS 0.1276\n","Train: EPOCH 0001 / 0001 | BATCH 0609 \\ 1153 | LOSS 0.1278\n","Train: EPOCH 0001 / 0001 | BATCH 0610 \\ 1153 | LOSS 0.1276\n","Train: EPOCH 0001 / 0001 | BATCH 0611 \\ 1153 | LOSS 0.1274\n","Train: EPOCH 0001 / 0001 | BATCH 0612 \\ 1153 | LOSS 0.1273\n","Train: EPOCH 0001 / 0001 | BATCH 0613 \\ 1153 | LOSS 0.1273\n","Train: EPOCH 0001 / 0001 | BATCH 0614 \\ 1153 | LOSS 0.1272\n","Train: EPOCH 0001 / 0001 | BATCH 0615 \\ 1153 | LOSS 0.1271\n","Train: EPOCH 0001 / 0001 | BATCH 0616 \\ 1153 | LOSS 0.1269\n","Train: EPOCH 0001 / 0001 | BATCH 0617 \\ 1153 | LOSS 0.1268\n","Train: EPOCH 0001 / 0001 | BATCH 0618 \\ 1153 | LOSS 0.1267\n","Train: EPOCH 0001 / 0001 | BATCH 0619 \\ 1153 | LOSS 0.1267\n","Train: EPOCH 0001 / 0001 | BATCH 0620 \\ 1153 | LOSS 0.1265\n","Train: EPOCH 0001 / 0001 | BATCH 0621 \\ 1153 | LOSS 0.1264\n","Train: EPOCH 0001 / 0001 | BATCH 0622 \\ 1153 | LOSS 0.1262\n","Train: EPOCH 0001 / 0001 | BATCH 0623 \\ 1153 | LOSS 0.1261\n","Train: EPOCH 0001 / 0001 | BATCH 0624 \\ 1153 | LOSS 0.1259\n","Train: EPOCH 0001 / 0001 | BATCH 0625 \\ 1153 | LOSS 0.1259\n","Train: EPOCH 0001 / 0001 | BATCH 0626 \\ 1153 | LOSS 0.1258\n","Train: EPOCH 0001 / 0001 | BATCH 0627 \\ 1153 | LOSS 0.1258\n","Train: EPOCH 0001 / 0001 | BATCH 0628 \\ 1153 | LOSS 0.1256\n","Train: EPOCH 0001 / 0001 | BATCH 0629 \\ 1153 | LOSS 0.1255\n","Train: EPOCH 0001 / 0001 | BATCH 0630 \\ 1153 | LOSS 0.1254\n","Train: EPOCH 0001 / 0001 | BATCH 0631 \\ 1153 | LOSS 0.1253\n","Train: EPOCH 0001 / 0001 | BATCH 0632 \\ 1153 | LOSS 0.1251\n","Train: EPOCH 0001 / 0001 | BATCH 0633 \\ 1153 | LOSS 0.1250\n","Train: EPOCH 0001 / 0001 | BATCH 0634 \\ 1153 | LOSS 0.1251\n","Train: EPOCH 0001 / 0001 | BATCH 0635 \\ 1153 | LOSS 0.1250\n","Train: EPOCH 0001 / 0001 | BATCH 0636 \\ 1153 | LOSS 0.1249\n","Train: EPOCH 0001 / 0001 | BATCH 0637 \\ 1153 | LOSS 0.1248\n","Train: EPOCH 0001 / 0001 | BATCH 0638 \\ 1153 | LOSS 0.1247\n","Train: EPOCH 0001 / 0001 | BATCH 0639 \\ 1153 | LOSS 0.1246\n","Train: EPOCH 0001 / 0001 | BATCH 0640 \\ 1153 | LOSS 0.1245\n","Train: EPOCH 0001 / 0001 | BATCH 0641 \\ 1153 | LOSS 0.1245\n","Train: EPOCH 0001 / 0001 | BATCH 0642 \\ 1153 | LOSS 0.1248\n","Train: EPOCH 0001 / 0001 | BATCH 0643 \\ 1153 | LOSS 0.1248\n","Train: EPOCH 0001 / 0001 | BATCH 0644 \\ 1153 | LOSS 0.1246\n","Train: EPOCH 0001 / 0001 | BATCH 0645 \\ 1153 | LOSS 0.1246\n","Train: EPOCH 0001 / 0001 | BATCH 0646 \\ 1153 | LOSS 0.1245\n","Train: EPOCH 0001 / 0001 | BATCH 0647 \\ 1153 | LOSS 0.1244\n","Train: EPOCH 0001 / 0001 | BATCH 0648 \\ 1153 | LOSS 0.1243\n","Train: EPOCH 0001 / 0001 | BATCH 0649 \\ 1153 | LOSS 0.1242\n","Train: EPOCH 0001 / 0001 | BATCH 0650 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0651 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0652 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0653 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0654 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0655 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0656 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0657 \\ 1153 | LOSS 0.1237\n","Train: EPOCH 0001 / 0001 | BATCH 0658 \\ 1153 | LOSS 0.1236\n","Train: EPOCH 0001 / 0001 | BATCH 0659 \\ 1153 | LOSS 0.1238\n","Train: EPOCH 0001 / 0001 | BATCH 0660 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0661 \\ 1153 | LOSS 0.1242\n","Train: EPOCH 0001 / 0001 | BATCH 0662 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0663 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0664 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0665 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0666 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0667 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0668 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0669 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0670 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0671 \\ 1153 | LOSS 0.1241\n","Train: EPOCH 0001 / 0001 | BATCH 0672 \\ 1153 | LOSS 0.1240\n","Train: EPOCH 0001 / 0001 | BATCH 0673 \\ 1153 | LOSS 0.1239\n","Train: EPOCH 0001 / 0001 | BATCH 0674 \\ 1153 | LOSS 0.1238\n","Train: EPOCH 0001 / 0001 | BATCH 0675 \\ 1153 | LOSS 0.1237\n","Train: EPOCH 0001 / 0001 | BATCH 0676 \\ 1153 | LOSS 0.1236\n","Train: EPOCH 0001 / 0001 | BATCH 0677 \\ 1153 | LOSS 0.1235\n","Train: EPOCH 0001 / 0001 | BATCH 0678 \\ 1153 | LOSS 0.1235\n","Train: EPOCH 0001 / 0001 | BATCH 0679 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0680 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0681 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0682 \\ 1153 | LOSS 0.1234\n","Train: EPOCH 0001 / 0001 | BATCH 0683 \\ 1153 | LOSS 0.1234\n","Train: EPOCH 0001 / 0001 | BATCH 0684 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0685 \\ 1153 | LOSS 0.1232\n","Train: EPOCH 0001 / 0001 | BATCH 0686 \\ 1153 | LOSS 0.1231\n","Train: EPOCH 0001 / 0001 | BATCH 0687 \\ 1153 | LOSS 0.1231\n","Train: EPOCH 0001 / 0001 | BATCH 0688 \\ 1153 | LOSS 0.1235\n","Train: EPOCH 0001 / 0001 | BATCH 0689 \\ 1153 | LOSS 0.1234\n","Train: EPOCH 0001 / 0001 | BATCH 0690 \\ 1153 | LOSS 0.1235\n","Train: EPOCH 0001 / 0001 | BATCH 0691 \\ 1153 | LOSS 0.1235\n","Train: EPOCH 0001 / 0001 | BATCH 0692 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0693 \\ 1153 | LOSS 0.1233\n","Train: EPOCH 0001 / 0001 | BATCH 0694 \\ 1153 | LOSS 0.1232\n","Train: EPOCH 0001 / 0001 | BATCH 0695 \\ 1153 | LOSS 0.1230\n","Train: EPOCH 0001 / 0001 | BATCH 0696 \\ 1153 | LOSS 0.1229\n","Train: EPOCH 0001 / 0001 | BATCH 0697 \\ 1153 | LOSS 0.1230\n","Train: EPOCH 0001 / 0001 | BATCH 0698 \\ 1153 | LOSS 0.1229\n","Train: EPOCH 0001 / 0001 | BATCH 0699 \\ 1153 | LOSS 0.1229\n","Train: EPOCH 0001 / 0001 | BATCH 0700 \\ 1153 | LOSS 0.1229\n","Train: EPOCH 0001 / 0001 | BATCH 0701 \\ 1153 | LOSS 0.1229\n","Train: EPOCH 0001 / 0001 | BATCH 0702 \\ 1153 | LOSS 0.1228\n","Train: EPOCH 0001 / 0001 | BATCH 0703 \\ 1153 | LOSS 0.1227\n","Train: EPOCH 0001 / 0001 | BATCH 0704 \\ 1153 | LOSS 0.1226\n","Train: EPOCH 0001 / 0001 | BATCH 0705 \\ 1153 | LOSS 0.1225\n","Train: EPOCH 0001 / 0001 | BATCH 0706 \\ 1153 | LOSS 0.1225\n","Train: EPOCH 0001 / 0001 | BATCH 0707 \\ 1153 | LOSS 0.1224\n","Train: EPOCH 0001 / 0001 | BATCH 0708 \\ 1153 | LOSS 0.1223\n","Train: EPOCH 0001 / 0001 | BATCH 0709 \\ 1153 | LOSS 0.1223\n","Train: EPOCH 0001 / 0001 | BATCH 0710 \\ 1153 | LOSS 0.1222\n","Train: EPOCH 0001 / 0001 | BATCH 0711 \\ 1153 | LOSS 0.1222\n","Train: EPOCH 0001 / 0001 | BATCH 0712 \\ 1153 | LOSS 0.1221\n","Train: EPOCH 0001 / 0001 | BATCH 0713 \\ 1153 | LOSS 0.1220\n","Train: EPOCH 0001 / 0001 | BATCH 0714 \\ 1153 | LOSS 0.1219\n","Train: EPOCH 0001 / 0001 | BATCH 0715 \\ 1153 | LOSS 0.1221\n","Train: EPOCH 0001 / 0001 | BATCH 0716 \\ 1153 | LOSS 0.1220\n","Train: EPOCH 0001 / 0001 | BATCH 0717 \\ 1153 | LOSS 0.1218\n","Train: EPOCH 0001 / 0001 | BATCH 0718 \\ 1153 | LOSS 0.1217\n","Train: EPOCH 0001 / 0001 | BATCH 0719 \\ 1153 | LOSS 0.1216\n","Train: EPOCH 0001 / 0001 | BATCH 0720 \\ 1153 | LOSS 0.1215\n","Train: EPOCH 0001 / 0001 | BATCH 0721 \\ 1153 | LOSS 0.1216\n","Train: EPOCH 0001 / 0001 | BATCH 0722 \\ 1153 | LOSS 0.1216\n","Train: EPOCH 0001 / 0001 | BATCH 0723 \\ 1153 | LOSS 0.1217\n","Train: EPOCH 0001 / 0001 | BATCH 0724 \\ 1153 | LOSS 0.1216\n","Train: EPOCH 0001 / 0001 | BATCH 0725 \\ 1153 | LOSS 0.1214\n","Train: EPOCH 0001 / 0001 | BATCH 0726 \\ 1153 | LOSS 0.1213\n","Train: EPOCH 0001 / 0001 | BATCH 0727 \\ 1153 | LOSS 0.1212\n","Train: EPOCH 0001 / 0001 | BATCH 0728 \\ 1153 | LOSS 0.1213\n","Train: EPOCH 0001 / 0001 | BATCH 0729 \\ 1153 | LOSS 0.1212\n","Train: EPOCH 0001 / 0001 | BATCH 0730 \\ 1153 | LOSS 0.1211\n","Train: EPOCH 0001 / 0001 | BATCH 0731 \\ 1153 | LOSS 0.1211\n","Train: EPOCH 0001 / 0001 | BATCH 0732 \\ 1153 | LOSS 0.1211\n","Train: EPOCH 0001 / 0001 | BATCH 0733 \\ 1153 | LOSS 0.1210\n","Train: EPOCH 0001 / 0001 | BATCH 0734 \\ 1153 | LOSS 0.1210\n","Train: EPOCH 0001 / 0001 | BATCH 0735 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0736 \\ 1153 | LOSS 0.1210\n","Train: EPOCH 0001 / 0001 | BATCH 0737 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0738 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0739 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0740 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0741 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0742 \\ 1153 | LOSS 0.1208\n","Train: EPOCH 0001 / 0001 | BATCH 0743 \\ 1153 | LOSS 0.1207\n","Train: EPOCH 0001 / 0001 | BATCH 0744 \\ 1153 | LOSS 0.1207\n","Train: EPOCH 0001 / 0001 | BATCH 0745 \\ 1153 | LOSS 0.1206\n","Train: EPOCH 0001 / 0001 | BATCH 0746 \\ 1153 | LOSS 0.1206\n","Train: EPOCH 0001 / 0001 | BATCH 0747 \\ 1153 | LOSS 0.1208\n","Train: EPOCH 0001 / 0001 | BATCH 0748 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0749 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0750 \\ 1153 | LOSS 0.1209\n","Train: EPOCH 0001 / 0001 | BATCH 0751 \\ 1153 | LOSS 0.1208\n","Train: EPOCH 0001 / 0001 | BATCH 0752 \\ 1153 | LOSS 0.1207\n","Train: EPOCH 0001 / 0001 | BATCH 0753 \\ 1153 | LOSS 0.1206\n","Train: EPOCH 0001 / 0001 | BATCH 0754 \\ 1153 | LOSS 0.1207\n","Train: EPOCH 0001 / 0001 | BATCH 0755 \\ 1153 | LOSS 0.1206\n","Train: EPOCH 0001 / 0001 | BATCH 0756 \\ 1153 | LOSS 0.1205\n","Train: EPOCH 0001 / 0001 | BATCH 0757 \\ 1153 | LOSS 0.1206\n","Train: EPOCH 0001 / 0001 | BATCH 0758 \\ 1153 | LOSS 0.1205\n","Train: EPOCH 0001 / 0001 | BATCH 0759 \\ 1153 | LOSS 0.1205\n","Train: EPOCH 0001 / 0001 | BATCH 0760 \\ 1153 | LOSS 0.1204\n","Train: EPOCH 0001 / 0001 | BATCH 0761 \\ 1153 | LOSS 0.1203\n","Train: EPOCH 0001 / 0001 | BATCH 0762 \\ 1153 | LOSS 0.1202\n","Train: EPOCH 0001 / 0001 | BATCH 0763 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0764 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0765 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0766 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0767 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0768 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0769 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0770 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0771 \\ 1153 | LOSS 0.1197\n","Train: EPOCH 0001 / 0001 | BATCH 0772 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0773 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0774 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0775 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0776 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0777 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0778 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0779 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0780 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0781 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0782 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0783 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0784 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0785 \\ 1153 | LOSS 0.1201\n","Train: EPOCH 0001 / 0001 | BATCH 0786 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0787 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0788 \\ 1153 | LOSS 0.1200\n","Train: EPOCH 0001 / 0001 | BATCH 0789 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0790 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0791 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0792 \\ 1153 | LOSS 0.1196\n","Train: EPOCH 0001 / 0001 | BATCH 0793 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0794 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0795 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0796 \\ 1153 | LOSS 0.1199\n","Train: EPOCH 0001 / 0001 | BATCH 0797 \\ 1153 | LOSS 0.1198\n","Train: EPOCH 0001 / 0001 | BATCH 0798 \\ 1153 | LOSS 0.1197\n","Train: EPOCH 0001 / 0001 | BATCH 0799 \\ 1153 | LOSS 0.1196\n","Train: EPOCH 0001 / 0001 | BATCH 0800 \\ 1153 | LOSS 0.1196\n","Train: EPOCH 0001 / 0001 | BATCH 0801 \\ 1153 | LOSS 0.1196\n","Train: EPOCH 0001 / 0001 | BATCH 0802 \\ 1153 | LOSS 0.1195\n","Train: EPOCH 0001 / 0001 | BATCH 0803 \\ 1153 | LOSS 0.1194\n","Train: EPOCH 0001 / 0001 | BATCH 0804 \\ 1153 | LOSS 0.1193\n","Train: EPOCH 0001 / 0001 | BATCH 0805 \\ 1153 | LOSS 0.1192\n","Train: EPOCH 0001 / 0001 | BATCH 0806 \\ 1153 | LOSS 0.1191\n","Train: EPOCH 0001 / 0001 | BATCH 0807 \\ 1153 | LOSS 0.1190\n","Train: EPOCH 0001 / 0001 | BATCH 0808 \\ 1153 | LOSS 0.1189\n","Train: EPOCH 0001 / 0001 | BATCH 0809 \\ 1153 | LOSS 0.1191\n","Train: EPOCH 0001 / 0001 | BATCH 0810 \\ 1153 | LOSS 0.1190\n","Train: EPOCH 0001 / 0001 | BATCH 0811 \\ 1153 | LOSS 0.1189\n","Train: EPOCH 0001 / 0001 | BATCH 0812 \\ 1153 | LOSS 0.1189\n","Train: EPOCH 0001 / 0001 | BATCH 0813 \\ 1153 | LOSS 0.1189\n","Train: EPOCH 0001 / 0001 | BATCH 0814 \\ 1153 | LOSS 0.1188\n","Train: EPOCH 0001 / 0001 | BATCH 0815 \\ 1153 | LOSS 0.1189\n","Train: EPOCH 0001 / 0001 | BATCH 0816 \\ 1153 | LOSS 0.1188\n","Train: EPOCH 0001 / 0001 | BATCH 0817 \\ 1153 | LOSS 0.1188\n","Train: EPOCH 0001 / 0001 | BATCH 0818 \\ 1153 | LOSS 0.1188\n","Train: EPOCH 0001 / 0001 | BATCH 0819 \\ 1153 | LOSS 0.1188\n","Train: EPOCH 0001 / 0001 | BATCH 0820 \\ 1153 | LOSS 0.1187\n","Train: EPOCH 0001 / 0001 | BATCH 0821 \\ 1153 | LOSS 0.1186\n","Train: EPOCH 0001 / 0001 | BATCH 0822 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0823 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0824 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0825 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0826 \\ 1153 | LOSS 0.1186\n","Train: EPOCH 0001 / 0001 | BATCH 0827 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0828 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0829 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0830 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0831 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0832 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0833 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0834 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0835 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0836 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0837 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0838 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0839 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0840 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0841 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0842 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0843 \\ 1153 | LOSS 0.1185\n","Train: EPOCH 0001 / 0001 | BATCH 0844 \\ 1153 | LOSS 0.1184\n","Train: EPOCH 0001 / 0001 | BATCH 0845 \\ 1153 | LOSS 0.1183\n","Train: EPOCH 0001 / 0001 | BATCH 0846 \\ 1153 | LOSS 0.1182\n","Train: EPOCH 0001 / 0001 | BATCH 0847 \\ 1153 | LOSS 0.1181\n","Train: EPOCH 0001 / 0001 | BATCH 0848 \\ 1153 | LOSS 0.1182\n","Train: EPOCH 0001 / 0001 | BATCH 0849 \\ 1153 | LOSS 0.1181\n","Train: EPOCH 0001 / 0001 | BATCH 0850 \\ 1153 | LOSS 0.1181\n","Train: EPOCH 0001 / 0001 | BATCH 0851 \\ 1153 | LOSS 0.1181\n","Train: EPOCH 0001 / 0001 | BATCH 0852 \\ 1153 | LOSS 0.1180\n","Train: EPOCH 0001 / 0001 | BATCH 0853 \\ 1153 | LOSS 0.1179\n","Train: EPOCH 0001 / 0001 | BATCH 0854 \\ 1153 | LOSS 0.1182\n","Train: EPOCH 0001 / 0001 | BATCH 0855 \\ 1153 | LOSS 0.1181\n","Train: EPOCH 0001 / 0001 | BATCH 0856 \\ 1153 | LOSS 0.1180\n","Train: EPOCH 0001 / 0001 | BATCH 0857 \\ 1153 | LOSS 0.1180\n","Train: EPOCH 0001 / 0001 | BATCH 0858 \\ 1153 | LOSS 0.1178\n","Train: EPOCH 0001 / 0001 | BATCH 0859 \\ 1153 | LOSS 0.1178\n","Train: EPOCH 0001 / 0001 | BATCH 0860 \\ 1153 | LOSS 0.1178\n","Train: EPOCH 0001 / 0001 | BATCH 0861 \\ 1153 | LOSS 0.1177\n","Train: EPOCH 0001 / 0001 | BATCH 0862 \\ 1153 | LOSS 0.1177\n","Train: EPOCH 0001 / 0001 | BATCH 0863 \\ 1153 | LOSS 0.1176\n","Train: EPOCH 0001 / 0001 | BATCH 0864 \\ 1153 | LOSS 0.1175\n","Train: EPOCH 0001 / 0001 | BATCH 0865 \\ 1153 | LOSS 0.1175\n","Train: EPOCH 0001 / 0001 | BATCH 0866 \\ 1153 | LOSS 0.1174\n","Train: EPOCH 0001 / 0001 | BATCH 0867 \\ 1153 | LOSS 0.1173\n","Train: EPOCH 0001 / 0001 | BATCH 0868 \\ 1153 | LOSS 0.1172\n","Train: EPOCH 0001 / 0001 | BATCH 0869 \\ 1153 | LOSS 0.1174\n","Train: EPOCH 0001 / 0001 | BATCH 0870 \\ 1153 | LOSS 0.1173\n","Train: EPOCH 0001 / 0001 | BATCH 0871 \\ 1153 | LOSS 0.1173\n","Train: EPOCH 0001 / 0001 | BATCH 0872 \\ 1153 | LOSS 0.1172\n","Train: EPOCH 0001 / 0001 | BATCH 0873 \\ 1153 | LOSS 0.1171\n","Train: EPOCH 0001 / 0001 | BATCH 0874 \\ 1153 | LOSS 0.1170\n","Train: EPOCH 0001 / 0001 | BATCH 0875 \\ 1153 | LOSS 0.1170\n","Train: EPOCH 0001 / 0001 | BATCH 0876 \\ 1153 | LOSS 0.1169\n","Train: EPOCH 0001 / 0001 | BATCH 0877 \\ 1153 | LOSS 0.1168\n","Train: EPOCH 0001 / 0001 | BATCH 0878 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0879 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0880 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0881 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0882 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0883 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0884 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0885 \\ 1153 | LOSS 0.1168\n","Train: EPOCH 0001 / 0001 | BATCH 0886 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0887 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0888 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0889 \\ 1153 | LOSS 0.1169\n","Train: EPOCH 0001 / 0001 | BATCH 0890 \\ 1153 | LOSS 0.1169\n","Train: EPOCH 0001 / 0001 | BATCH 0891 \\ 1153 | LOSS 0.1169\n","Train: EPOCH 0001 / 0001 | BATCH 0892 \\ 1153 | LOSS 0.1169\n","Train: EPOCH 0001 / 0001 | BATCH 0893 \\ 1153 | LOSS 0.1168\n","Train: EPOCH 0001 / 0001 | BATCH 0894 \\ 1153 | LOSS 0.1168\n","Train: EPOCH 0001 / 0001 | BATCH 0895 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0896 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0897 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0898 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0899 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0900 \\ 1153 | LOSS 0.1164\n","Train: EPOCH 0001 / 0001 | BATCH 0901 \\ 1153 | LOSS 0.1164\n","Train: EPOCH 0001 / 0001 | BATCH 0902 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0903 \\ 1153 | LOSS 0.1162\n","Train: EPOCH 0001 / 0001 | BATCH 0904 \\ 1153 | LOSS 0.1161\n","Train: EPOCH 0001 / 0001 | BATCH 0905 \\ 1153 | LOSS 0.1161\n","Train: EPOCH 0001 / 0001 | BATCH 0906 \\ 1153 | LOSS 0.1161\n","Train: EPOCH 0001 / 0001 | BATCH 0907 \\ 1153 | LOSS 0.1160\n","Train: EPOCH 0001 / 0001 | BATCH 0908 \\ 1153 | LOSS 0.1160\n","Train: EPOCH 0001 / 0001 | BATCH 0909 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0910 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0911 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0912 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0913 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0914 \\ 1153 | LOSS 0.1167\n","Train: EPOCH 0001 / 0001 | BATCH 0915 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0916 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0917 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0918 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0919 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0920 \\ 1153 | LOSS 0.1166\n","Train: EPOCH 0001 / 0001 | BATCH 0921 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0922 \\ 1153 | LOSS 0.1165\n","Train: EPOCH 0001 / 0001 | BATCH 0923 \\ 1153 | LOSS 0.1164\n","Train: EPOCH 0001 / 0001 | BATCH 0924 \\ 1153 | LOSS 0.1164\n","Train: EPOCH 0001 / 0001 | BATCH 0925 \\ 1153 | LOSS 0.1164\n","Train: EPOCH 0001 / 0001 | BATCH 0926 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0927 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0928 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0929 \\ 1153 | LOSS 0.1163\n","Train: EPOCH 0001 / 0001 | BATCH 0930 \\ 1153 | LOSS 0.1162\n","Train: EPOCH 0001 / 0001 | BATCH 0931 \\ 1153 | LOSS 0.1162\n","Train: EPOCH 0001 / 0001 | BATCH 0932 \\ 1153 | LOSS 0.1161\n","Train: EPOCH 0001 / 0001 | BATCH 0933 \\ 1153 | LOSS 0.1160\n","Train: EPOCH 0001 / 0001 | BATCH 0934 \\ 1153 | LOSS 0.1160\n","Train: EPOCH 0001 / 0001 | BATCH 0935 \\ 1153 | LOSS 0.1159\n","Train: EPOCH 0001 / 0001 | BATCH 0936 \\ 1153 | LOSS 0.1159\n","Train: EPOCH 0001 / 0001 | BATCH 0937 \\ 1153 | LOSS 0.1158\n","Train: EPOCH 0001 / 0001 | BATCH 0938 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0939 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0940 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0941 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0942 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0943 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0944 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0945 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0946 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0947 \\ 1153 | LOSS 0.1154\n","Train: EPOCH 0001 / 0001 | BATCH 0948 \\ 1153 | LOSS 0.1154\n","Train: EPOCH 0001 / 0001 | BATCH 0949 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0950 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0951 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0952 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0953 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0954 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0955 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0956 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0957 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0958 \\ 1153 | LOSS 0.1157\n","Train: EPOCH 0001 / 0001 | BATCH 0959 \\ 1153 | LOSS 0.1156\n","Train: EPOCH 0001 / 0001 | BATCH 0960 \\ 1153 | LOSS 0.1155\n","Train: EPOCH 0001 / 0001 | BATCH 0961 \\ 1153 | LOSS 0.1154\n","Train: EPOCH 0001 / 0001 | BATCH 0962 \\ 1153 | LOSS 0.1154\n","Train: EPOCH 0001 / 0001 | BATCH 0963 \\ 1153 | LOSS 0.1153\n","Train: EPOCH 0001 / 0001 | BATCH 0964 \\ 1153 | LOSS 0.1153\n","Train: EPOCH 0001 / 0001 | BATCH 0965 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0966 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0967 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0968 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0969 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0970 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0971 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0972 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0973 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0974 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0975 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0976 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0977 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0978 \\ 1153 | LOSS 0.1153\n","Train: EPOCH 0001 / 0001 | BATCH 0979 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0980 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0981 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0982 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0983 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0984 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0985 \\ 1153 | LOSS 0.1152\n","Train: EPOCH 0001 / 0001 | BATCH 0986 \\ 1153 | LOSS 0.1151\n","Train: EPOCH 0001 / 0001 | BATCH 0987 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0988 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0989 \\ 1153 | LOSS 0.1149\n","Train: EPOCH 0001 / 0001 | BATCH 0990 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0991 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0992 \\ 1153 | LOSS 0.1149\n","Train: EPOCH 0001 / 0001 | BATCH 0993 \\ 1153 | LOSS 0.1150\n","Train: EPOCH 0001 / 0001 | BATCH 0994 \\ 1153 | LOSS 0.1149\n","Train: EPOCH 0001 / 0001 | BATCH 0995 \\ 1153 | LOSS 0.1148\n","Train: EPOCH 0001 / 0001 | BATCH 0996 \\ 1153 | LOSS 0.1147\n","Train: EPOCH 0001 / 0001 | BATCH 0997 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 0998 \\ 1153 | LOSS 0.1147\n","Train: EPOCH 0001 / 0001 | BATCH 0999 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 1000 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 1001 \\ 1153 | LOSS 0.1145\n","Train: EPOCH 0001 / 0001 | BATCH 1002 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 1003 \\ 1153 | LOSS 0.1145\n","Train: EPOCH 0001 / 0001 | BATCH 1004 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1005 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1006 \\ 1153 | LOSS 0.1147\n","Train: EPOCH 0001 / 0001 | BATCH 1007 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 1008 \\ 1153 | LOSS 0.1147\n","Train: EPOCH 0001 / 0001 | BATCH 1009 \\ 1153 | LOSS 0.1146\n","Train: EPOCH 0001 / 0001 | BATCH 1010 \\ 1153 | LOSS 0.1145\n","Train: EPOCH 0001 / 0001 | BATCH 1011 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1012 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1013 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1014 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1015 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1016 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1017 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1018 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1019 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1020 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1021 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1022 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1023 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1024 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1025 \\ 1153 | LOSS 0.1145\n","Train: EPOCH 0001 / 0001 | BATCH 1026 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1027 \\ 1153 | LOSS 0.1145\n","Train: EPOCH 0001 / 0001 | BATCH 1028 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1029 \\ 1153 | LOSS 0.1144\n","Train: EPOCH 0001 / 0001 | BATCH 1030 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1031 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1032 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1033 \\ 1153 | LOSS 0.1143\n","Train: EPOCH 0001 / 0001 | BATCH 1034 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1035 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1036 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1037 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1038 \\ 1153 | LOSS 0.1142\n","Train: EPOCH 0001 / 0001 | BATCH 1039 \\ 1153 | LOSS 0.1141\n","Train: EPOCH 0001 / 0001 | BATCH 1040 \\ 1153 | LOSS 0.1141\n","Train: EPOCH 0001 / 0001 | BATCH 1041 \\ 1153 | LOSS 0.1140\n","Train: EPOCH 0001 / 0001 | BATCH 1042 \\ 1153 | LOSS 0.1139\n","Train: EPOCH 0001 / 0001 | BATCH 1043 \\ 1153 | LOSS 0.1140\n","Train: EPOCH 0001 / 0001 | BATCH 1044 \\ 1153 | LOSS 0.1139\n","Train: EPOCH 0001 / 0001 | BATCH 1045 \\ 1153 | LOSS 0.1139\n","Train: EPOCH 0001 / 0001 | BATCH 1046 \\ 1153 | LOSS 0.1138\n","Train: EPOCH 0001 / 0001 | BATCH 1047 \\ 1153 | LOSS 0.1138\n","Train: EPOCH 0001 / 0001 | BATCH 1048 \\ 1153 | LOSS 0.1138\n","Train: EPOCH 0001 / 0001 | BATCH 1049 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1050 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1051 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1052 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1053 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1054 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1055 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1056 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1057 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1058 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1059 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1060 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1061 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1062 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1063 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1064 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1065 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1066 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1067 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1068 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1069 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1070 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1071 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1072 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1073 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1074 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1075 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1076 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1077 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1078 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1079 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1080 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1081 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1082 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1083 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1084 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1085 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1086 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1087 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1088 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1089 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1090 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1091 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1092 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1093 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1094 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1095 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1096 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1097 \\ 1153 | LOSS 0.1137\n","Train: EPOCH 0001 / 0001 | BATCH 1098 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1099 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1100 \\ 1153 | LOSS 0.1136\n","Train: EPOCH 0001 / 0001 | BATCH 1101 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1102 \\ 1153 | LOSS 0.1135\n","Train: EPOCH 0001 / 0001 | BATCH 1103 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1104 \\ 1153 | LOSS 0.1134\n","Train: EPOCH 0001 / 0001 | BATCH 1105 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1106 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1107 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1108 \\ 1153 | LOSS 0.1133\n","Train: EPOCH 0001 / 0001 | BATCH 1109 \\ 1153 | LOSS 0.1132\n","Train: EPOCH 0001 / 0001 | BATCH 1110 \\ 1153 | LOSS 0.1131\n","Train: EPOCH 0001 / 0001 | BATCH 1111 \\ 1153 | LOSS 0.1131\n","Train: EPOCH 0001 / 0001 | BATCH 1112 \\ 1153 | LOSS 0.1131\n","Train: EPOCH 0001 / 0001 | BATCH 1113 \\ 1153 | LOSS 0.1130\n","Train: EPOCH 0001 / 0001 | BATCH 1114 \\ 1153 | LOSS 0.1130\n","Train: EPOCH 0001 / 0001 | BATCH 1115 \\ 1153 | LOSS 0.1130\n","Train: EPOCH 0001 / 0001 | BATCH 1116 \\ 1153 | LOSS 0.1129\n","Train: EPOCH 0001 / 0001 | BATCH 1117 \\ 1153 | LOSS 0.1129\n","Train: EPOCH 0001 / 0001 | BATCH 1118 \\ 1153 | LOSS 0.1128\n","Train: EPOCH 0001 / 0001 | BATCH 1119 \\ 1153 | LOSS 0.1127\n","Train: EPOCH 0001 / 0001 | BATCH 1120 \\ 1153 | LOSS 0.1127\n","Train: EPOCH 0001 / 0001 | BATCH 1121 \\ 1153 | LOSS 0.1127\n","Train: EPOCH 0001 / 0001 | BATCH 1122 \\ 1153 | LOSS 0.1126\n","Train: EPOCH 0001 / 0001 | BATCH 1123 \\ 1153 | LOSS 0.1127\n","Train: EPOCH 0001 / 0001 | BATCH 1124 \\ 1153 | LOSS 0.1126\n","Train: EPOCH 0001 / 0001 | BATCH 1125 \\ 1153 | LOSS 0.1126\n","Train: EPOCH 0001 / 0001 | BATCH 1126 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1127 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1128 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1129 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1130 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1131 \\ 1153 | LOSS 0.1126\n","Train: EPOCH 0001 / 0001 | BATCH 1132 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1133 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1134 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1135 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1136 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1137 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1138 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1139 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1140 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1141 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1142 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1143 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1144 \\ 1153 | LOSS 0.1125\n","Train: EPOCH 0001 / 0001 | BATCH 1145 \\ 1153 | LOSS 0.1124\n","Train: EPOCH 0001 / 0001 | BATCH 1146 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1147 \\ 1153 | LOSS 0.1122\n","Train: EPOCH 0001 / 0001 | BATCH 1148 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1149 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1150 \\ 1153 | LOSS 0.1122\n","Train: EPOCH 0001 / 0001 | BATCH 1151 \\ 1153 | LOSS 0.1122\n","Train: EPOCH 0001 / 0001 | BATCH 1152 \\ 1153 | LOSS 0.1123\n","Train: EPOCH 0001 / 0001 | BATCH 1153 \\ 1153 | LOSS 0.1122\n","Validation: EPOCH 0001 / 0001 | BATCH 0001 \\ 0145 | LOSS 0.0148\n","Validation: EPOCH 0001 / 0001 | BATCH 0002 \\ 0145 | LOSS 0.0142\n","Validation: EPOCH 0001 / 0001 | BATCH 0003 \\ 0145 | LOSS 0.0148\n","Validation: EPOCH 0001 / 0001 | BATCH 0004 \\ 0145 | LOSS 0.0140\n","Validation: EPOCH 0001 / 0001 | BATCH 0005 \\ 0145 | LOSS 0.0149\n","Validation: EPOCH 0001 / 0001 | BATCH 0006 \\ 0145 | LOSS 0.0148\n","Validation: EPOCH 0001 / 0001 | BATCH 0007 \\ 0145 | LOSS 0.0157\n","Validation: EPOCH 0001 / 0001 | BATCH 0008 \\ 0145 | LOSS 0.0159\n","Validation: EPOCH 0001 / 0001 | BATCH 0009 \\ 0145 | LOSS 0.0160\n","Validation: EPOCH 0001 / 0001 | BATCH 0010 \\ 0145 | LOSS 0.0164\n","Validation: EPOCH 0001 / 0001 | BATCH 0011 \\ 0145 | LOSS 0.0165\n","Validation: EPOCH 0001 / 0001 | BATCH 0012 \\ 0145 | LOSS 0.0167\n","Validation: EPOCH 0001 / 0001 | BATCH 0013 \\ 0145 | LOSS 0.0168\n","Validation: EPOCH 0001 / 0001 | BATCH 0014 \\ 0145 | LOSS 0.0167\n","Validation: EPOCH 0001 / 0001 | BATCH 0015 \\ 0145 | LOSS 0.0169\n","Validation: EPOCH 0001 / 0001 | BATCH 0016 \\ 0145 | LOSS 0.0170\n","Validation: EPOCH 0001 / 0001 | BATCH 0017 \\ 0145 | LOSS 0.0170\n","Validation: EPOCH 0001 / 0001 | BATCH 0018 \\ 0145 | LOSS 0.0171\n","Validation: EPOCH 0001 / 0001 | BATCH 0019 \\ 0145 | LOSS 0.0171\n","Validation: EPOCH 0001 / 0001 | BATCH 0020 \\ 0145 | LOSS 0.0170\n","Validation: EPOCH 0001 / 0001 | BATCH 0021 \\ 0145 | LOSS 0.0170\n","Validation: EPOCH 0001 / 0001 | BATCH 0022 \\ 0145 | LOSS 0.0213\n","Validation: EPOCH 0001 / 0001 | BATCH 0023 \\ 0145 | LOSS 0.0258\n","Validation: EPOCH 0001 / 0001 | BATCH 0024 \\ 0145 | LOSS 0.0278\n","Validation: EPOCH 0001 / 0001 | BATCH 0025 \\ 0145 | LOSS 0.0298\n","Validation: EPOCH 0001 / 0001 | BATCH 0026 \\ 0145 | LOSS 0.0292\n","Validation: EPOCH 0001 / 0001 | BATCH 0027 \\ 0145 | LOSS 0.0290\n","Validation: EPOCH 0001 / 0001 | BATCH 0028 \\ 0145 | LOSS 0.0339\n","Validation: EPOCH 0001 / 0001 | BATCH 0029 \\ 0145 | LOSS 0.0339\n","Validation: EPOCH 0001 / 0001 | BATCH 0030 \\ 0145 | LOSS 0.0335\n","Validation: EPOCH 0001 / 0001 | BATCH 0031 \\ 0145 | LOSS 0.0359\n","Validation: EPOCH 0001 / 0001 | BATCH 0032 \\ 0145 | LOSS 0.0402\n","Validation: EPOCH 0001 / 0001 | BATCH 0033 \\ 0145 | LOSS 0.0411\n","Validation: EPOCH 0001 / 0001 | BATCH 0034 \\ 0145 | LOSS 0.0412\n","Validation: EPOCH 0001 / 0001 | BATCH 0035 \\ 0145 | LOSS 0.0405\n","Validation: EPOCH 0001 / 0001 | BATCH 0036 \\ 0145 | LOSS 0.0400\n","Validation: EPOCH 0001 / 0001 | BATCH 0037 \\ 0145 | LOSS 0.0394\n","Validation: EPOCH 0001 / 0001 | BATCH 0038 \\ 0145 | LOSS 0.0390\n","Validation: EPOCH 0001 / 0001 | BATCH 0039 \\ 0145 | LOSS 0.0401\n","Validation: EPOCH 0001 / 0001 | BATCH 0040 \\ 0145 | LOSS 0.0397\n","Validation: EPOCH 0001 / 0001 | BATCH 0041 \\ 0145 | LOSS 0.0398\n","Validation: EPOCH 0001 / 0001 | BATCH 0042 \\ 0145 | LOSS 0.0397\n","Validation: EPOCH 0001 / 0001 | BATCH 0043 \\ 0145 | LOSS 0.0397\n","Validation: EPOCH 0001 / 0001 | BATCH 0044 \\ 0145 | LOSS 0.0415\n","Validation: EPOCH 0001 / 0001 | BATCH 0045 \\ 0145 | LOSS 0.0421\n","Validation: EPOCH 0001 / 0001 | BATCH 0046 \\ 0145 | LOSS 0.0420\n","Validation: EPOCH 0001 / 0001 | BATCH 0047 \\ 0145 | LOSS 0.0416\n","Validation: EPOCH 0001 / 0001 | BATCH 0048 \\ 0145 | LOSS 0.0418\n","Validation: EPOCH 0001 / 0001 | BATCH 0049 \\ 0145 | LOSS 0.0426\n","Validation: EPOCH 0001 / 0001 | BATCH 0050 \\ 0145 | LOSS 0.0427\n","Validation: EPOCH 0001 / 0001 | BATCH 0051 \\ 0145 | LOSS 0.0440\n","Validation: EPOCH 0001 / 0001 | BATCH 0052 \\ 0145 | LOSS 0.0446\n","Validation: EPOCH 0001 / 0001 | BATCH 0053 \\ 0145 | LOSS 0.0443\n","Validation: EPOCH 0001 / 0001 | BATCH 0054 \\ 0145 | LOSS 0.0441\n","Validation: EPOCH 0001 / 0001 | BATCH 0055 \\ 0145 | LOSS 0.0464\n","Validation: EPOCH 0001 / 0001 | BATCH 0056 \\ 0145 | LOSS 0.0481\n","Validation: EPOCH 0001 / 0001 | BATCH 0057 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0058 \\ 0145 | LOSS 0.0504\n","Validation: EPOCH 0001 / 0001 | BATCH 0059 \\ 0145 | LOSS 0.0502\n","Validation: EPOCH 0001 / 0001 | BATCH 0060 \\ 0145 | LOSS 0.0497\n","Validation: EPOCH 0001 / 0001 | BATCH 0061 \\ 0145 | LOSS 0.0492\n","Validation: EPOCH 0001 / 0001 | BATCH 0062 \\ 0145 | LOSS 0.0491\n","Validation: EPOCH 0001 / 0001 | BATCH 0063 \\ 0145 | LOSS 0.0487\n","Validation: EPOCH 0001 / 0001 | BATCH 0064 \\ 0145 | LOSS 0.0483\n","Validation: EPOCH 0001 / 0001 | BATCH 0065 \\ 0145 | LOSS 0.0479\n","Validation: EPOCH 0001 / 0001 | BATCH 0066 \\ 0145 | LOSS 0.0491\n","Validation: EPOCH 0001 / 0001 | BATCH 0067 \\ 0145 | LOSS 0.0487\n","Validation: EPOCH 0001 / 0001 | BATCH 0068 \\ 0145 | LOSS 0.0487\n","Validation: EPOCH 0001 / 0001 | BATCH 0069 \\ 0145 | LOSS 0.0483\n","Validation: EPOCH 0001 / 0001 | BATCH 0070 \\ 0145 | LOSS 0.0480\n","Validation: EPOCH 0001 / 0001 | BATCH 0071 \\ 0145 | LOSS 0.0481\n","Validation: EPOCH 0001 / 0001 | BATCH 0072 \\ 0145 | LOSS 0.0479\n","Validation: EPOCH 0001 / 0001 | BATCH 0073 \\ 0145 | LOSS 0.0477\n","Validation: EPOCH 0001 / 0001 | BATCH 0074 \\ 0145 | LOSS 0.0474\n","Validation: EPOCH 0001 / 0001 | BATCH 0075 \\ 0145 | LOSS 0.0473\n","Validation: EPOCH 0001 / 0001 | BATCH 0076 \\ 0145 | LOSS 0.0470\n","Validation: EPOCH 0001 / 0001 | BATCH 0077 \\ 0145 | LOSS 0.0467\n","Validation: EPOCH 0001 / 0001 | BATCH 0078 \\ 0145 | LOSS 0.0469\n","Validation: EPOCH 0001 / 0001 | BATCH 0079 \\ 0145 | LOSS 0.0468\n","Validation: EPOCH 0001 / 0001 | BATCH 0080 \\ 0145 | LOSS 0.0471\n","Validation: EPOCH 0001 / 0001 | BATCH 0081 \\ 0145 | LOSS 0.0471\n","Validation: EPOCH 0001 / 0001 | BATCH 0082 \\ 0145 | LOSS 0.0468\n","Validation: EPOCH 0001 / 0001 | BATCH 0083 \\ 0145 | LOSS 0.0465\n","Validation: EPOCH 0001 / 0001 | BATCH 0084 \\ 0145 | LOSS 0.0464\n","Validation: EPOCH 0001 / 0001 | BATCH 0085 \\ 0145 | LOSS 0.0483\n","Validation: EPOCH 0001 / 0001 | BATCH 0086 \\ 0145 | LOSS 0.0480\n","Validation: EPOCH 0001 / 0001 | BATCH 0087 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0088 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0089 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0090 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0091 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0092 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0093 \\ 0145 | LOSS 0.0505\n","Validation: EPOCH 0001 / 0001 | BATCH 0094 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0095 \\ 0145 | LOSS 0.0506\n","Validation: EPOCH 0001 / 0001 | BATCH 0096 \\ 0145 | LOSS 0.0502\n","Validation: EPOCH 0001 / 0001 | BATCH 0097 \\ 0145 | LOSS 0.0506\n","Validation: EPOCH 0001 / 0001 | BATCH 0098 \\ 0145 | LOSS 0.0505\n","Validation: EPOCH 0001 / 0001 | BATCH 0099 \\ 0145 | LOSS 0.0502\n","Validation: EPOCH 0001 / 0001 | BATCH 0100 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0101 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0102 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0103 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0104 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0105 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0106 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0107 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0108 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0109 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0110 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0111 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0112 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0113 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0114 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0115 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0116 \\ 0145 | LOSS 0.0529\n","Validation: EPOCH 0001 / 0001 | BATCH 0117 \\ 0145 | LOSS 0.0529\n","Validation: EPOCH 0001 / 0001 | BATCH 0118 \\ 0145 | LOSS 0.0526\n","Validation: EPOCH 0001 / 0001 | BATCH 0119 \\ 0145 | LOSS 0.0524\n","Validation: EPOCH 0001 / 0001 | BATCH 0120 \\ 0145 | LOSS 0.0524\n","Validation: EPOCH 0001 / 0001 | BATCH 0121 \\ 0145 | LOSS 0.0523\n","Validation: EPOCH 0001 / 0001 | BATCH 0122 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0123 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0124 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0125 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0126 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0127 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0128 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0129 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0130 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0131 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0132 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0133 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0134 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0135 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0136 \\ 0145 | LOSS 0.0526\n","Validation: EPOCH 0001 / 0001 | BATCH 0137 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0138 \\ 0145 | LOSS 0.0522\n","Validation: EPOCH 0001 / 0001 | BATCH 0139 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0140 \\ 0145 | LOSS 0.0527\n","Validation: EPOCH 0001 / 0001 | BATCH 0141 \\ 0145 | LOSS 0.0526\n","Validation: EPOCH 0001 / 0001 | BATCH 0142 \\ 0145 | LOSS 0.0524\n","Validation: EPOCH 0001 / 0001 | BATCH 0143 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0144 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0145 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0146 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0147 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0148 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0149 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0150 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0151 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0152 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0153 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0154 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0155 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0156 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0157 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0158 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0159 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0160 \\ 0145 | LOSS 0.0523\n","Validation: EPOCH 0001 / 0001 | BATCH 0161 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0162 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0163 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0164 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0165 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0166 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0167 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0168 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0169 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0170 \\ 0145 | LOSS 0.0521\n","Validation: EPOCH 0001 / 0001 | BATCH 0171 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0172 \\ 0145 | LOSS 0.0520\n","Validation: EPOCH 0001 / 0001 | BATCH 0173 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0174 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0175 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0176 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0177 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0178 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0179 \\ 0145 | LOSS 0.0518\n","Validation: EPOCH 0001 / 0001 | BATCH 0180 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0181 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0182 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0183 \\ 0145 | LOSS 0.0519\n","Validation: EPOCH 0001 / 0001 | BATCH 0184 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0185 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0186 \\ 0145 | LOSS 0.0516\n","Validation: EPOCH 0001 / 0001 | BATCH 0187 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0188 \\ 0145 | LOSS 0.0513\n","Validation: EPOCH 0001 / 0001 | BATCH 0189 \\ 0145 | LOSS 0.0511\n","Validation: EPOCH 0001 / 0001 | BATCH 0190 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0191 \\ 0145 | LOSS 0.0510\n","Validation: EPOCH 0001 / 0001 | BATCH 0192 \\ 0145 | LOSS 0.0509\n","Validation: EPOCH 0001 / 0001 | BATCH 0193 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0194 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0195 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0196 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0197 \\ 0145 | LOSS 0.0507\n","Validation: EPOCH 0001 / 0001 | BATCH 0198 \\ 0145 | LOSS 0.0505\n","Validation: EPOCH 0001 / 0001 | BATCH 0199 \\ 0145 | LOSS 0.0508\n","Validation: EPOCH 0001 / 0001 | BATCH 0200 \\ 0145 | LOSS 0.0507\n","Validation: EPOCH 0001 / 0001 | BATCH 0201 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0202 \\ 0145 | LOSS 0.0513\n","Validation: EPOCH 0001 / 0001 | BATCH 0203 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0204 \\ 0145 | LOSS 0.0512\n","Validation: EPOCH 0001 / 0001 | BATCH 0205 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0206 \\ 0145 | LOSS 0.0517\n","Validation: EPOCH 0001 / 0001 | BATCH 0207 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0208 \\ 0145 | LOSS 0.0515\n","Validation: EPOCH 0001 / 0001 | BATCH 0209 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0210 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0211 \\ 0145 | LOSS 0.0514\n","Validation: EPOCH 0001 / 0001 | BATCH 0212 \\ 0145 | LOSS 0.0534\n","Validation: EPOCH 0001 / 0001 | BATCH 0213 \\ 0145 | LOSS 0.0533\n","Validation: EPOCH 0001 / 0001 | BATCH 0214 \\ 0145 | LOSS 0.0531\n","Validation: EPOCH 0001 / 0001 | BATCH 0215 \\ 0145 | LOSS 0.0531\n","Validation: EPOCH 0001 / 0001 | BATCH 0216 \\ 0145 | LOSS 0.0529\n","Validation: EPOCH 0001 / 0001 | BATCH 0217 \\ 0145 | LOSS 0.0528\n","Validation: EPOCH 0001 / 0001 | BATCH 0218 \\ 0145 | LOSS 0.0527\n","Validation: EPOCH 0001 / 0001 | BATCH 0219 \\ 0145 | LOSS 0.0528\n","Validation: EPOCH 0001 / 0001 | BATCH 0220 \\ 0145 | LOSS 0.0527\n","Validation: EPOCH 0001 / 0001 | BATCH 0221 \\ 0145 | LOSS 0.0526\n","Validation: EPOCH 0001 / 0001 | BATCH 0222 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0223 \\ 0145 | LOSS 0.0535\n","Validation: EPOCH 0001 / 0001 | BATCH 0224 \\ 0145 | LOSS 0.0538\n","Validation: EPOCH 0001 / 0001 | BATCH 0225 \\ 0145 | LOSS 0.0538\n","Validation: EPOCH 0001 / 0001 | BATCH 0226 \\ 0145 | LOSS 0.0541\n","Validation: EPOCH 0001 / 0001 | BATCH 0227 \\ 0145 | LOSS 0.0546\n","Validation: EPOCH 0001 / 0001 | BATCH 0228 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0229 \\ 0145 | LOSS 0.0546\n","Validation: EPOCH 0001 / 0001 | BATCH 0230 \\ 0145 | LOSS 0.0545\n","Validation: EPOCH 0001 / 0001 | BATCH 0231 \\ 0145 | LOSS 0.0543\n","Validation: EPOCH 0001 / 0001 | BATCH 0232 \\ 0145 | LOSS 0.0544\n","Validation: EPOCH 0001 / 0001 | BATCH 0233 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0234 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0235 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0236 \\ 0145 | LOSS 0.0552\n","Validation: EPOCH 0001 / 0001 | BATCH 0237 \\ 0145 | LOSS 0.0552\n","Validation: EPOCH 0001 / 0001 | BATCH 0238 \\ 0145 | LOSS 0.0550\n","Validation: EPOCH 0001 / 0001 | BATCH 0239 \\ 0145 | LOSS 0.0550\n","Validation: EPOCH 0001 / 0001 | BATCH 0240 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0241 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0242 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0243 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0244 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0245 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0246 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0247 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0248 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0249 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0250 \\ 0145 | LOSS 0.0559\n","Validation: EPOCH 0001 / 0001 | BATCH 0251 \\ 0145 | LOSS 0.0558\n","Validation: EPOCH 0001 / 0001 | BATCH 0252 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0253 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0254 \\ 0145 | LOSS 0.0555\n","Validation: EPOCH 0001 / 0001 | BATCH 0255 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0256 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0257 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0258 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0259 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0260 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0261 \\ 0145 | LOSS 0.0558\n","Validation: EPOCH 0001 / 0001 | BATCH 0262 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0263 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0264 \\ 0145 | LOSS 0.0555\n","Validation: EPOCH 0001 / 0001 | BATCH 0265 \\ 0145 | LOSS 0.0562\n","Validation: EPOCH 0001 / 0001 | BATCH 0266 \\ 0145 | LOSS 0.0561\n","Validation: EPOCH 0001 / 0001 | BATCH 0267 \\ 0145 | LOSS 0.0560\n","Validation: EPOCH 0001 / 0001 | BATCH 0268 \\ 0145 | LOSS 0.0559\n","Validation: EPOCH 0001 / 0001 | BATCH 0269 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0270 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0271 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0272 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0273 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0274 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0275 \\ 0145 | LOSS 0.0564\n","Validation: EPOCH 0001 / 0001 | BATCH 0276 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0277 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0278 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0279 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0280 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0281 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0282 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0283 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0284 \\ 0145 | LOSS 0.0564\n","Validation: EPOCH 0001 / 0001 | BATCH 0285 \\ 0145 | LOSS 0.0564\n","Validation: EPOCH 0001 / 0001 | BATCH 0286 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0287 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0288 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0289 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0290 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0291 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0292 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0293 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0294 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0295 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0296 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0297 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0298 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0299 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0300 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0301 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0302 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0303 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0304 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0305 \\ 0145 | LOSS 0.0575\n","Validation: EPOCH 0001 / 0001 | BATCH 0306 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0307 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0308 \\ 0145 | LOSS 0.0575\n","Validation: EPOCH 0001 / 0001 | BATCH 0309 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0310 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0311 \\ 0145 | LOSS 0.0575\n","Validation: EPOCH 0001 / 0001 | BATCH 0312 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0313 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0314 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0315 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0316 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0317 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0318 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0319 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0320 \\ 0145 | LOSS 0.0571\n","Validation: EPOCH 0001 / 0001 | BATCH 0321 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0322 \\ 0145 | LOSS 0.0575\n","Validation: EPOCH 0001 / 0001 | BATCH 0323 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0324 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0325 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0326 \\ 0145 | LOSS 0.0571\n","Validation: EPOCH 0001 / 0001 | BATCH 0327 \\ 0145 | LOSS 0.0570\n","Validation: EPOCH 0001 / 0001 | BATCH 0328 \\ 0145 | LOSS 0.0569\n","Validation: EPOCH 0001 / 0001 | BATCH 0329 \\ 0145 | LOSS 0.0569\n","Validation: EPOCH 0001 / 0001 | BATCH 0330 \\ 0145 | LOSS 0.0569\n","Validation: EPOCH 0001 / 0001 | BATCH 0331 \\ 0145 | LOSS 0.0569\n","Validation: EPOCH 0001 / 0001 | BATCH 0332 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0333 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0334 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0335 \\ 0145 | LOSS 0.0579\n","Validation: EPOCH 0001 / 0001 | BATCH 0336 \\ 0145 | LOSS 0.0578\n","Validation: EPOCH 0001 / 0001 | BATCH 0337 \\ 0145 | LOSS 0.0577\n","Validation: EPOCH 0001 / 0001 | BATCH 0338 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0339 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0340 \\ 0145 | LOSS 0.0575\n","Validation: EPOCH 0001 / 0001 | BATCH 0341 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0342 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0343 \\ 0145 | LOSS 0.0581\n","Validation: EPOCH 0001 / 0001 | BATCH 0344 \\ 0145 | LOSS 0.0580\n","Validation: EPOCH 0001 / 0001 | BATCH 0345 \\ 0145 | LOSS 0.0579\n","Validation: EPOCH 0001 / 0001 | BATCH 0346 \\ 0145 | LOSS 0.0578\n","Validation: EPOCH 0001 / 0001 | BATCH 0347 \\ 0145 | LOSS 0.0577\n","Validation: EPOCH 0001 / 0001 | BATCH 0348 \\ 0145 | LOSS 0.0577\n","Validation: EPOCH 0001 / 0001 | BATCH 0349 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0350 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0351 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0352 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0353 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0354 \\ 0145 | LOSS 0.0571\n","Validation: EPOCH 0001 / 0001 | BATCH 0355 \\ 0145 | LOSS 0.0572\n","Validation: EPOCH 0001 / 0001 | BATCH 0356 \\ 0145 | LOSS 0.0571\n","Validation: EPOCH 0001 / 0001 | BATCH 0357 \\ 0145 | LOSS 0.0570\n","Validation: EPOCH 0001 / 0001 | BATCH 0358 \\ 0145 | LOSS 0.0569\n","Validation: EPOCH 0001 / 0001 | BATCH 0359 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0360 \\ 0145 | LOSS 0.0568\n","Validation: EPOCH 0001 / 0001 | BATCH 0361 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0362 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0363 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0364 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0365 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0366 \\ 0145 | LOSS 0.0567\n","Validation: EPOCH 0001 / 0001 | BATCH 0367 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0368 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0369 \\ 0145 | LOSS 0.0565\n","Validation: EPOCH 0001 / 0001 | BATCH 0370 \\ 0145 | LOSS 0.0564\n","Validation: EPOCH 0001 / 0001 | BATCH 0371 \\ 0145 | LOSS 0.0563\n","Validation: EPOCH 0001 / 0001 | BATCH 0372 \\ 0145 | LOSS 0.0563\n","Validation: EPOCH 0001 / 0001 | BATCH 0373 \\ 0145 | LOSS 0.0562\n","Validation: EPOCH 0001 / 0001 | BATCH 0374 \\ 0145 | LOSS 0.0561\n","Validation: EPOCH 0001 / 0001 | BATCH 0375 \\ 0145 | LOSS 0.0560\n","Validation: EPOCH 0001 / 0001 | BATCH 0376 \\ 0145 | LOSS 0.0560\n","Validation: EPOCH 0001 / 0001 | BATCH 0377 \\ 0145 | LOSS 0.0559\n","Validation: EPOCH 0001 / 0001 | BATCH 0378 \\ 0145 | LOSS 0.0558\n","Validation: EPOCH 0001 / 0001 | BATCH 0379 \\ 0145 | LOSS 0.0558\n","Validation: EPOCH 0001 / 0001 | BATCH 0380 \\ 0145 | LOSS 0.0558\n","Validation: EPOCH 0001 / 0001 | BATCH 0381 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0382 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0383 \\ 0145 | LOSS 0.0557\n","Validation: EPOCH 0001 / 0001 | BATCH 0384 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0385 \\ 0145 | LOSS 0.0555\n","Validation: EPOCH 0001 / 0001 | BATCH 0386 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0387 \\ 0145 | LOSS 0.0555\n","Validation: EPOCH 0001 / 0001 | BATCH 0388 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0389 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0390 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0391 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0392 \\ 0145 | LOSS 0.0555\n","Validation: EPOCH 0001 / 0001 | BATCH 0393 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0394 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0395 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0396 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0397 \\ 0145 | LOSS 0.0552\n","Validation: EPOCH 0001 / 0001 | BATCH 0398 \\ 0145 | LOSS 0.0551\n","Validation: EPOCH 0001 / 0001 | BATCH 0399 \\ 0145 | LOSS 0.0551\n","Validation: EPOCH 0001 / 0001 | BATCH 0400 \\ 0145 | LOSS 0.0550\n","Validation: EPOCH 0001 / 0001 | BATCH 0401 \\ 0145 | LOSS 0.0550\n","Validation: EPOCH 0001 / 0001 | BATCH 0402 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0403 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0404 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0405 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0406 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0407 \\ 0145 | LOSS 0.0549\n","Validation: EPOCH 0001 / 0001 | BATCH 0408 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0409 \\ 0145 | LOSS 0.0548\n","Validation: EPOCH 0001 / 0001 | BATCH 0410 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0411 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0412 \\ 0145 | LOSS 0.0547\n","Validation: EPOCH 0001 / 0001 | BATCH 0413 \\ 0145 | LOSS 0.0546\n","Validation: EPOCH 0001 / 0001 | BATCH 0414 \\ 0145 | LOSS 0.0545\n","Validation: EPOCH 0001 / 0001 | BATCH 0415 \\ 0145 | LOSS 0.0545\n","Validation: EPOCH 0001 / 0001 | BATCH 0416 \\ 0145 | LOSS 0.0544\n","Validation: EPOCH 0001 / 0001 | BATCH 0417 \\ 0145 | LOSS 0.0543\n","Validation: EPOCH 0001 / 0001 | BATCH 0418 \\ 0145 | LOSS 0.0542\n","Validation: EPOCH 0001 / 0001 | BATCH 0419 \\ 0145 | LOSS 0.0542\n","Validation: EPOCH 0001 / 0001 | BATCH 0420 \\ 0145 | LOSS 0.0541\n","Validation: EPOCH 0001 / 0001 | BATCH 0421 \\ 0145 | LOSS 0.0540\n","Validation: EPOCH 0001 / 0001 | BATCH 0422 \\ 0145 | LOSS 0.0541\n","Validation: EPOCH 0001 / 0001 | BATCH 0423 \\ 0145 | LOSS 0.0540\n","Validation: EPOCH 0001 / 0001 | BATCH 0424 \\ 0145 | LOSS 0.0539\n","Validation: EPOCH 0001 / 0001 | BATCH 0425 \\ 0145 | LOSS 0.0538\n","Validation: EPOCH 0001 / 0001 | BATCH 0426 \\ 0145 | LOSS 0.0538\n","Validation: EPOCH 0001 / 0001 | BATCH 0427 \\ 0145 | LOSS 0.0537\n","Validation: EPOCH 0001 / 0001 | BATCH 0428 \\ 0145 | LOSS 0.0536\n","Validation: EPOCH 0001 / 0001 | BATCH 0429 \\ 0145 | LOSS 0.0535\n","Validation: EPOCH 0001 / 0001 | BATCH 0430 \\ 0145 | LOSS 0.0534\n","Validation: EPOCH 0001 / 0001 | BATCH 0431 \\ 0145 | LOSS 0.0533\n","Validation: EPOCH 0001 / 0001 | BATCH 0432 \\ 0145 | LOSS 0.0532\n","Validation: EPOCH 0001 / 0001 | BATCH 0433 \\ 0145 | LOSS 0.0532\n","Validation: EPOCH 0001 / 0001 | BATCH 0434 \\ 0145 | LOSS 0.0531\n","Validation: EPOCH 0001 / 0001 | BATCH 0435 \\ 0145 | LOSS 0.0530\n","Validation: EPOCH 0001 / 0001 | BATCH 0436 \\ 0145 | LOSS 0.0529\n","Validation: EPOCH 0001 / 0001 | BATCH 0437 \\ 0145 | LOSS 0.0528\n","Validation: EPOCH 0001 / 0001 | BATCH 0438 \\ 0145 | LOSS 0.0528\n","Validation: EPOCH 0001 / 0001 | BATCH 0439 \\ 0145 | LOSS 0.0527\n","Validation: EPOCH 0001 / 0001 | BATCH 0440 \\ 0145 | LOSS 0.0526\n","Validation: EPOCH 0001 / 0001 | BATCH 0441 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0442 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0443 \\ 0145 | LOSS 0.0524\n","Validation: EPOCH 0001 / 0001 | BATCH 0444 \\ 0145 | LOSS 0.0523\n","Validation: EPOCH 0001 / 0001 | BATCH 0445 \\ 0145 | LOSS 0.0523\n","Validation: EPOCH 0001 / 0001 | BATCH 0446 \\ 0145 | LOSS 0.0525\n","Validation: EPOCH 0001 / 0001 | BATCH 0447 \\ 0145 | LOSS 0.0527\n","Validation: EPOCH 0001 / 0001 | BATCH 0448 \\ 0145 | LOSS 0.0530\n","Validation: EPOCH 0001 / 0001 | BATCH 0449 \\ 0145 | LOSS 0.0532\n","Validation: EPOCH 0001 / 0001 | BATCH 0450 \\ 0145 | LOSS 0.0542\n","Validation: EPOCH 0001 / 0001 | BATCH 0451 \\ 0145 | LOSS 0.0543\n","Validation: EPOCH 0001 / 0001 | BATCH 0452 \\ 0145 | LOSS 0.0545\n","Validation: EPOCH 0001 / 0001 | BATCH 0453 \\ 0145 | LOSS 0.0546\n","Validation: EPOCH 0001 / 0001 | BATCH 0454 \\ 0145 | LOSS 0.0553\n","Validation: EPOCH 0001 / 0001 | BATCH 0455 \\ 0145 | LOSS 0.0554\n","Validation: EPOCH 0001 / 0001 | BATCH 0456 \\ 0145 | LOSS 0.0556\n","Validation: EPOCH 0001 / 0001 | BATCH 0457 \\ 0145 | LOSS 0.0563\n","Validation: EPOCH 0001 / 0001 | BATCH 0458 \\ 0145 | LOSS 0.0564\n","Validation: EPOCH 0001 / 0001 | BATCH 0459 \\ 0145 | LOSS 0.0563\n","Validation: EPOCH 0001 / 0001 | BATCH 0460 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0461 \\ 0145 | LOSS 0.0566\n","Validation: EPOCH 0001 / 0001 | BATCH 0462 \\ 0145 | LOSS 0.0573\n","Validation: EPOCH 0001 / 0001 | BATCH 0463 \\ 0145 | LOSS 0.0574\n","Validation: EPOCH 0001 / 0001 | BATCH 0464 \\ 0145 | LOSS 0.0576\n","Validation: EPOCH 0001 / 0001 | BATCH 0465 \\ 0145 | LOSS 0.0578\n","Validation: EPOCH 0001 / 0001 | BATCH 0466 \\ 0145 | LOSS 0.0578\n","Validation: EPOCH 0001 / 0001 | BATCH 0467 \\ 0145 | LOSS 0.0583\n","Validation: EPOCH 0001 / 0001 | BATCH 0468 \\ 0145 | LOSS 0.0584\n","Validation: EPOCH 0001 / 0001 | BATCH 0469 \\ 0145 | LOSS 0.0587\n","Validation: EPOCH 0001 / 0001 | BATCH 0470 \\ 0145 | LOSS 0.0588\n","Validation: EPOCH 0001 / 0001 | BATCH 0471 \\ 0145 | LOSS 0.0589\n","Validation: EPOCH 0001 / 0001 | BATCH 0472 \\ 0145 | LOSS 0.0589\n","Validation: EPOCH 0001 / 0001 | BATCH 0473 \\ 0145 | LOSS 0.0591\n","Validation: EPOCH 0001 / 0001 | BATCH 0474 \\ 0145 | LOSS 0.0590\n","Validation: EPOCH 0001 / 0001 | BATCH 0475 \\ 0145 | LOSS 0.0591\n","Validation: EPOCH 0001 / 0001 | BATCH 0476 \\ 0145 | LOSS 0.0591\n","Validation: EPOCH 0001 / 0001 | BATCH 0477 \\ 0145 | LOSS 0.0594\n","Validation: EPOCH 0001 / 0001 | BATCH 0478 \\ 0145 | LOSS 0.0598\n","Validation: EPOCH 0001 / 0001 | BATCH 0479 \\ 0145 | LOSS 0.0598\n","Validation: EPOCH 0001 / 0001 | BATCH 0480 \\ 0145 | LOSS 0.0602\n","Validation: EPOCH 0001 / 0001 | BATCH 0481 \\ 0145 | LOSS 0.0602\n","Validation: EPOCH 0001 / 0001 | BATCH 0482 \\ 0145 | LOSS 0.0604\n","Validation: EPOCH 0001 / 0001 | BATCH 0483 \\ 0145 | LOSS 0.0605\n","Validation: EPOCH 0001 / 0001 | BATCH 0484 \\ 0145 | LOSS 0.0605\n","Validation: EPOCH 0001 / 0001 | BATCH 0485 \\ 0145 | LOSS 0.0605\n","Validation: EPOCH 0001 / 0001 | BATCH 0486 \\ 0145 | LOSS 0.0605\n","Validation: EPOCH 0001 / 0001 | BATCH 0487 \\ 0145 | LOSS 0.0605\n","Validation: EPOCH 0001 / 0001 | BATCH 0488 \\ 0145 | LOSS 0.0607\n","Validation: EPOCH 0001 / 0001 | BATCH 0489 \\ 0145 | LOSS 0.0612\n","Validation: EPOCH 0001 / 0001 | BATCH 0490 \\ 0145 | LOSS 0.0612\n","Validation: EPOCH 0001 / 0001 | BATCH 0491 \\ 0145 | LOSS 0.0612\n","Validation: EPOCH 0001 / 0001 | BATCH 0492 \\ 0145 | LOSS 0.0613\n","Validation: EPOCH 0001 / 0001 | BATCH 0493 \\ 0145 | LOSS 0.0613\n","Validation: EPOCH 0001 / 0001 | BATCH 0494 \\ 0145 | LOSS 0.0614\n","Validation: EPOCH 0001 / 0001 | BATCH 0495 \\ 0145 | LOSS 0.0615\n","Validation: EPOCH 0001 / 0001 | BATCH 0496 \\ 0145 | LOSS 0.0616\n","Validation: EPOCH 0001 / 0001 | BATCH 0497 \\ 0145 | LOSS 0.0620\n","Validation: EPOCH 0001 / 0001 | BATCH 0498 \\ 0145 | LOSS 0.0621\n","Validation: EPOCH 0001 / 0001 | BATCH 0499 \\ 0145 | LOSS 0.0621\n","Validation: EPOCH 0001 / 0001 | BATCH 0500 \\ 0145 | LOSS 0.0622\n","Validation: EPOCH 0001 / 0001 | BATCH 0501 \\ 0145 | LOSS 0.0623\n","Validation: EPOCH 0001 / 0001 | BATCH 0502 \\ 0145 | LOSS 0.0625\n","Validation: EPOCH 0001 / 0001 | BATCH 0503 \\ 0145 | LOSS 0.0626\n","Validation: EPOCH 0001 / 0001 | BATCH 0504 \\ 0145 | LOSS 0.0627\n","Validation: EPOCH 0001 / 0001 | BATCH 0505 \\ 0145 | LOSS 0.0630\n","Validation: EPOCH 0001 / 0001 | BATCH 0506 \\ 0145 | LOSS 0.0630\n","Validation: EPOCH 0001 / 0001 | BATCH 0507 \\ 0145 | LOSS 0.0632\n","Validation: EPOCH 0001 / 0001 | BATCH 0508 \\ 0145 | LOSS 0.0632\n","Validation: EPOCH 0001 / 0001 | BATCH 0509 \\ 0145 | LOSS 0.0634\n","Validation: EPOCH 0001 / 0001 | BATCH 0510 \\ 0145 | LOSS 0.0637\n","Validation: EPOCH 0001 / 0001 | BATCH 0511 \\ 0145 | LOSS 0.0637\n","Validation: EPOCH 0001 / 0001 | BATCH 0512 \\ 0145 | LOSS 0.0637\n","Validation: EPOCH 0001 / 0001 | BATCH 0513 \\ 0145 | LOSS 0.0638\n","Validation: EPOCH 0001 / 0001 | BATCH 0514 \\ 0145 | LOSS 0.0640\n","Validation: EPOCH 0001 / 0001 | BATCH 0515 \\ 0145 | LOSS 0.0642\n","Validation: EPOCH 0001 / 0001 | BATCH 0516 \\ 0145 | LOSS 0.0645\n","Validation: EPOCH 0001 / 0001 | BATCH 0517 \\ 0145 | LOSS 0.0646\n","Validation: EPOCH 0001 / 0001 | BATCH 0518 \\ 0145 | LOSS 0.0648\n","Validation: EPOCH 0001 / 0001 | BATCH 0519 \\ 0145 | LOSS 0.0649\n","Validation: EPOCH 0001 / 0001 | BATCH 0520 \\ 0145 | LOSS 0.0649\n","Validation: EPOCH 0001 / 0001 | BATCH 0521 \\ 0145 | LOSS 0.0648\n","Validation: EPOCH 0001 / 0001 | BATCH 0522 \\ 0145 | LOSS 0.0649\n","Validation: EPOCH 0001 / 0001 | BATCH 0523 \\ 0145 | LOSS 0.0650\n","Validation: EPOCH 0001 / 0001 | BATCH 0524 \\ 0145 | LOSS 0.0653\n","Validation: EPOCH 0001 / 0001 | BATCH 0525 \\ 0145 | LOSS 0.0653\n","Validation: EPOCH 0001 / 0001 | BATCH 0526 \\ 0145 | LOSS 0.0654\n","Validation: EPOCH 0001 / 0001 | BATCH 0527 \\ 0145 | LOSS 0.0656\n","Validation: EPOCH 0001 / 0001 | BATCH 0528 \\ 0145 | LOSS 0.0657\n","Validation: EPOCH 0001 / 0001 | BATCH 0529 \\ 0145 | LOSS 0.0659\n","Validation: EPOCH 0001 / 0001 | BATCH 0530 \\ 0145 | LOSS 0.0662\n","Validation: EPOCH 0001 / 0001 | BATCH 0531 \\ 0145 | LOSS 0.0662\n","Validation: EPOCH 0001 / 0001 | BATCH 0532 \\ 0145 | LOSS 0.0663\n","Validation: EPOCH 0001 / 0001 | BATCH 0533 \\ 0145 | LOSS 0.0667\n","Validation: EPOCH 0001 / 0001 | BATCH 0534 \\ 0145 | LOSS 0.0671\n","Validation: EPOCH 0001 / 0001 | BATCH 0535 \\ 0145 | LOSS 0.0673\n","Validation: EPOCH 0001 / 0001 | BATCH 0536 \\ 0145 | LOSS 0.0674\n","Validation: EPOCH 0001 / 0001 | BATCH 0537 \\ 0145 | LOSS 0.0677\n","Validation: EPOCH 0001 / 0001 | BATCH 0538 \\ 0145 | LOSS 0.0678\n","Validation: EPOCH 0001 / 0001 | BATCH 0539 \\ 0145 | LOSS 0.0678\n","Validation: EPOCH 0001 / 0001 | BATCH 0540 \\ 0145 | LOSS 0.0679\n","Validation: EPOCH 0001 / 0001 | BATCH 0541 \\ 0145 | LOSS 0.0680\n","Validation: EPOCH 0001 / 0001 | BATCH 0542 \\ 0145 | LOSS 0.0682\n","Validation: EPOCH 0001 / 0001 | BATCH 0543 \\ 0145 | LOSS 0.0685\n","Validation: EPOCH 0001 / 0001 | BATCH 0544 \\ 0145 | LOSS 0.0688\n","Validation: EPOCH 0001 / 0001 | BATCH 0545 \\ 0145 | LOSS 0.0690\n","Validation: EPOCH 0001 / 0001 | BATCH 0546 \\ 0145 | LOSS 0.0690\n","Validation: EPOCH 0001 / 0001 | BATCH 0547 \\ 0145 | LOSS 0.0694\n","Validation: EPOCH 0001 / 0001 | BATCH 0548 \\ 0145 | LOSS 0.0694\n","Validation: EPOCH 0001 / 0001 | BATCH 0549 \\ 0145 | LOSS 0.0695\n","Validation: EPOCH 0001 / 0001 | BATCH 0550 \\ 0145 | LOSS 0.0697\n","Validation: EPOCH 0001 / 0001 | BATCH 0551 \\ 0145 | LOSS 0.0697\n","Validation: EPOCH 0001 / 0001 | BATCH 0552 \\ 0145 | LOSS 0.0697\n","Validation: EPOCH 0001 / 0001 | BATCH 0553 \\ 0145 | LOSS 0.0701\n","Validation: EPOCH 0001 / 0001 | BATCH 0554 \\ 0145 | LOSS 0.0707\n","Validation: EPOCH 0001 / 0001 | BATCH 0555 \\ 0145 | LOSS 0.0709\n","Validation: EPOCH 0001 / 0001 | BATCH 0556 \\ 0145 | LOSS 0.0710\n","Validation: EPOCH 0001 / 0001 | BATCH 0557 \\ 0145 | LOSS 0.0710\n","Validation: EPOCH 0001 / 0001 | BATCH 0558 \\ 0145 | LOSS 0.0711\n","Validation: EPOCH 0001 / 0001 | BATCH 0559 \\ 0145 | LOSS 0.0713\n","Validation: EPOCH 0001 / 0001 | BATCH 0560 \\ 0145 | LOSS 0.0714\n","Validation: EPOCH 0001 / 0001 | BATCH 0561 \\ 0145 | LOSS 0.0715\n","Validation: EPOCH 0001 / 0001 | BATCH 0562 \\ 0145 | LOSS 0.0716\n","Validation: EPOCH 0001 / 0001 | BATCH 0563 \\ 0145 | LOSS 0.0718\n","Validation: EPOCH 0001 / 0001 | BATCH 0564 \\ 0145 | LOSS 0.0722\n","Validation: EPOCH 0001 / 0001 | BATCH 0565 \\ 0145 | LOSS 0.0724\n","Validation: EPOCH 0001 / 0001 | BATCH 0566 \\ 0145 | LOSS 0.0724\n","Validation: EPOCH 0001 / 0001 | BATCH 0567 \\ 0145 | LOSS 0.0725\n","Validation: EPOCH 0001 / 0001 | BATCH 0568 \\ 0145 | LOSS 0.0726\n","Validation: EPOCH 0001 / 0001 | BATCH 0569 \\ 0145 | LOSS 0.0727\n","Validation: EPOCH 0001 / 0001 | BATCH 0570 \\ 0145 | LOSS 0.0731\n","Validation: EPOCH 0001 / 0001 | BATCH 0571 \\ 0145 | LOSS 0.0735\n","Validation: EPOCH 0001 / 0001 | BATCH 0572 \\ 0145 | LOSS 0.0739\n","Validation: EPOCH 0001 / 0001 | BATCH 0573 \\ 0145 | LOSS 0.0741\n","Validation: EPOCH 0001 / 0001 | BATCH 0574 \\ 0145 | LOSS 0.0746\n","Validation: EPOCH 0001 / 0001 | BATCH 0575 \\ 0145 | LOSS 0.0747\n","Validation: EPOCH 0001 / 0001 | BATCH 0576 \\ 0145 | LOSS 0.0749\n","Validation: EPOCH 0001 / 0001 | BATCH 0577 \\ 0145 | LOSS 0.0750\n","Validation: EPOCH 0001 / 0001 | BATCH 0578 \\ 0145 | LOSS 0.0750\n","Validation: EPOCH 0001 / 0001 | BATCH 0579 \\ 0145 | LOSS 0.0752\n","Validation: EPOCH 0001 / 0001 | BATCH 0580 \\ 0145 | LOSS 0.0752\n","Validation: EPOCH 0001 / 0001 | BATCH 0581 \\ 0145 | LOSS 0.0755\n","Validation: EPOCH 0001 / 0001 | BATCH 0582 \\ 0145 | LOSS 0.0757\n","Validation: EPOCH 0001 / 0001 | BATCH 0583 \\ 0145 | LOSS 0.0760\n","Validation: EPOCH 0001 / 0001 | BATCH 0584 \\ 0145 | LOSS 0.0761\n","Validation: EPOCH 0001 / 0001 | BATCH 0585 \\ 0145 | LOSS 0.0761\n","Validation: EPOCH 0001 / 0001 | BATCH 0586 \\ 0145 | LOSS 0.0762\n","Validation: EPOCH 0001 / 0001 | BATCH 0587 \\ 0145 | LOSS 0.0764\n","Validation: EPOCH 0001 / 0001 | BATCH 0588 \\ 0145 | LOSS 0.0765\n","Validation: EPOCH 0001 / 0001 | BATCH 0589 \\ 0145 | LOSS 0.0769\n","Validation: EPOCH 0001 / 0001 | BATCH 0590 \\ 0145 | LOSS 0.0770\n","Validation: EPOCH 0001 / 0001 | BATCH 0591 \\ 0145 | LOSS 0.0771\n","Validation: EPOCH 0001 / 0001 | BATCH 0592 \\ 0145 | LOSS 0.0771\n","Validation: EPOCH 0001 / 0001 | BATCH 0593 \\ 0145 | LOSS 0.0772\n","Validation: EPOCH 0001 / 0001 | BATCH 0594 \\ 0145 | LOSS 0.0773\n","Validation: EPOCH 0001 / 0001 | BATCH 0595 \\ 0145 | LOSS 0.0775\n","Validation: EPOCH 0001 / 0001 | BATCH 0596 \\ 0145 | LOSS 0.0778\n","Validation: EPOCH 0001 / 0001 | BATCH 0597 \\ 0145 | LOSS 0.0780\n","Validation: EPOCH 0001 / 0001 | BATCH 0598 \\ 0145 | LOSS 0.0783\n","Validation: EPOCH 0001 / 0001 | BATCH 0599 \\ 0145 | LOSS 0.0784\n","Validation: EPOCH 0001 / 0001 | BATCH 0600 \\ 0145 | LOSS 0.0784\n","Validation: EPOCH 0001 / 0001 | BATCH 0601 \\ 0145 | LOSS 0.0785\n","Validation: EPOCH 0001 / 0001 | BATCH 0602 \\ 0145 | LOSS 0.0786\n","Validation: EPOCH 0001 / 0001 | BATCH 0603 \\ 0145 | LOSS 0.0788\n","Validation: EPOCH 0001 / 0001 | BATCH 0604 \\ 0145 | LOSS 0.0790\n","Validation: EPOCH 0001 / 0001 | BATCH 0605 \\ 0145 | LOSS 0.0794\n","Validation: EPOCH 0001 / 0001 | BATCH 0606 \\ 0145 | LOSS 0.0794\n","Validation: EPOCH 0001 / 0001 | BATCH 0607 \\ 0145 | LOSS 0.0798\n","Validation: EPOCH 0001 / 0001 | BATCH 0608 \\ 0145 | LOSS 0.0800\n","Validation: EPOCH 0001 / 0001 | BATCH 0609 \\ 0145 | LOSS 0.0804\n","Validation: EPOCH 0001 / 0001 | BATCH 0610 \\ 0145 | LOSS 0.0806\n","Validation: EPOCH 0001 / 0001 | BATCH 0611 \\ 0145 | LOSS 0.0807\n","Validation: EPOCH 0001 / 0001 | BATCH 0612 \\ 0145 | LOSS 0.0806\n","Validation: EPOCH 0001 / 0001 | BATCH 0613 \\ 0145 | LOSS 0.0808\n","Validation: EPOCH 0001 / 0001 | BATCH 0614 \\ 0145 | LOSS 0.0808\n","Validation: EPOCH 0001 / 0001 | BATCH 0615 \\ 0145 | LOSS 0.0809\n","Validation: EPOCH 0001 / 0001 | BATCH 0616 \\ 0145 | LOSS 0.0810\n","Validation: EPOCH 0001 / 0001 | BATCH 0617 \\ 0145 | LOSS 0.0812\n","Validation: EPOCH 0001 / 0001 | BATCH 0618 \\ 0145 | LOSS 0.0814\n","Validation: EPOCH 0001 / 0001 | BATCH 0619 \\ 0145 | LOSS 0.0816\n","Validation: EPOCH 0001 / 0001 | BATCH 0620 \\ 0145 | LOSS 0.0818\n","Validation: EPOCH 0001 / 0001 | BATCH 0621 \\ 0145 | LOSS 0.0819\n","Validation: EPOCH 0001 / 0001 | BATCH 0622 \\ 0145 | LOSS 0.0819\n","Validation: EPOCH 0001 / 0001 | BATCH 0623 \\ 0145 | LOSS 0.0820\n","Validation: EPOCH 0001 / 0001 | BATCH 0624 \\ 0145 | LOSS 0.0820\n","Validation: EPOCH 0001 / 0001 | BATCH 0625 \\ 0145 | LOSS 0.0821\n","Validation: EPOCH 0001 / 0001 | BATCH 0626 \\ 0145 | LOSS 0.0823\n","Validation: EPOCH 0001 / 0001 | BATCH 0627 \\ 0145 | LOSS 0.0832\n","Validation: EPOCH 0001 / 0001 | BATCH 0628 \\ 0145 | LOSS 0.0837\n","Validation: EPOCH 0001 / 0001 | BATCH 0629 \\ 0145 | LOSS 0.0839\n","Validation: EPOCH 0001 / 0001 | BATCH 0630 \\ 0145 | LOSS 0.0840\n","Validation: EPOCH 0001 / 0001 | BATCH 0631 \\ 0145 | LOSS 0.0840\n","Validation: EPOCH 0001 / 0001 | BATCH 0632 \\ 0145 | LOSS 0.0843\n","Validation: EPOCH 0001 / 0001 | BATCH 0633 \\ 0145 | LOSS 0.0847\n","Validation: EPOCH 0001 / 0001 | BATCH 0634 \\ 0145 | LOSS 0.0850\n","Validation: EPOCH 0001 / 0001 | BATCH 0635 \\ 0145 | LOSS 0.0852\n","Validation: EPOCH 0001 / 0001 | BATCH 0636 \\ 0145 | LOSS 0.0854\n","Validation: EPOCH 0001 / 0001 | BATCH 0637 \\ 0145 | LOSS 0.0854\n","Validation: EPOCH 0001 / 0001 | BATCH 0638 \\ 0145 | LOSS 0.0857\n","Validation: EPOCH 0001 / 0001 | BATCH 0639 \\ 0145 | LOSS 0.0860\n","Validation: EPOCH 0001 / 0001 | BATCH 0640 \\ 0145 | LOSS 0.0861\n","Validation: EPOCH 0001 / 0001 | BATCH 0641 \\ 0145 | LOSS 0.0863\n","Validation: EPOCH 0001 / 0001 | BATCH 0642 \\ 0145 | LOSS 0.0866\n","Validation: EPOCH 0001 / 0001 | BATCH 0643 \\ 0145 | LOSS 0.0867\n","Validation: EPOCH 0001 / 0001 | BATCH 0644 \\ 0145 | LOSS 0.0866\n","Validation: EPOCH 0001 / 0001 | BATCH 0645 \\ 0145 | LOSS 0.0871\n","Validation: EPOCH 0001 / 0001 | BATCH 0646 \\ 0145 | LOSS 0.0875\n","Validation: EPOCH 0001 / 0001 | BATCH 0647 \\ 0145 | LOSS 0.0877\n","Validation: EPOCH 0001 / 0001 | BATCH 0648 \\ 0145 | LOSS 0.0879\n","Validation: EPOCH 0001 / 0001 | BATCH 0649 \\ 0145 | LOSS 0.0879\n","Validation: EPOCH 0001 / 0001 | BATCH 0650 \\ 0145 | LOSS 0.0880\n","Validation: EPOCH 0001 / 0001 | BATCH 0651 \\ 0145 | LOSS 0.0882\n","Validation: EPOCH 0001 / 0001 | BATCH 0652 \\ 0145 | LOSS 0.0884\n","Validation: EPOCH 0001 / 0001 | BATCH 0653 \\ 0145 | LOSS 0.0887\n","Validation: EPOCH 0001 / 0001 | BATCH 0654 \\ 0145 | LOSS 0.0890\n","Validation: EPOCH 0001 / 0001 | BATCH 0655 \\ 0145 | LOSS 0.0891\n","Validation: EPOCH 0001 / 0001 | BATCH 0656 \\ 0145 | LOSS 0.0891\n","Validation: EPOCH 0001 / 0001 | BATCH 0657 \\ 0145 | LOSS 0.0895\n","Validation: EPOCH 0001 / 0001 | BATCH 0658 \\ 0145 | LOSS 0.0896\n","Validation: EPOCH 0001 / 0001 | BATCH 0659 \\ 0145 | LOSS 0.0898\n","Validation: EPOCH 0001 / 0001 | BATCH 0660 \\ 0145 | LOSS 0.0898\n","Validation: EPOCH 0001 / 0001 | BATCH 0661 \\ 0145 | LOSS 0.0900\n","Validation: EPOCH 0001 / 0001 | BATCH 0662 \\ 0145 | LOSS 0.0900\n","Validation: EPOCH 0001 / 0001 | BATCH 0663 \\ 0145 | LOSS 0.0901\n","Validation: EPOCH 0001 / 0001 | BATCH 0664 \\ 0145 | LOSS 0.0902\n","Validation: EPOCH 0001 / 0001 | BATCH 0665 \\ 0145 | LOSS 0.0905\n","Validation: EPOCH 0001 / 0001 | BATCH 0666 \\ 0145 | LOSS 0.0907\n","Validation: EPOCH 0001 / 0001 | BATCH 0667 \\ 0145 | LOSS 0.0908\n","Validation: EPOCH 0001 / 0001 | BATCH 0668 \\ 0145 | LOSS 0.0910\n","Validation: EPOCH 0001 / 0001 | BATCH 0669 \\ 0145 | LOSS 0.0913\n","Validation: EPOCH 0001 / 0001 | BATCH 0670 \\ 0145 | LOSS 0.0918\n","Validation: EPOCH 0001 / 0001 | BATCH 0671 \\ 0145 | LOSS 0.0920\n","Validation: EPOCH 0001 / 0001 | BATCH 0672 \\ 0145 | LOSS 0.0924\n","Validation: EPOCH 0001 / 0001 | BATCH 0673 \\ 0145 | LOSS 0.0924\n","Validation: EPOCH 0001 / 0001 | BATCH 0674 \\ 0145 | LOSS 0.0925\n","Validation: EPOCH 0001 / 0001 | BATCH 0675 \\ 0145 | LOSS 0.0929\n","Validation: EPOCH 0001 / 0001 | BATCH 0676 \\ 0145 | LOSS 0.0930\n","Validation: EPOCH 0001 / 0001 | BATCH 0677 \\ 0145 | LOSS 0.0931\n","Validation: EPOCH 0001 / 0001 | BATCH 0678 \\ 0145 | LOSS 0.0933\n","Validation: EPOCH 0001 / 0001 | BATCH 0679 \\ 0145 | LOSS 0.0937\n","Validation: EPOCH 0001 / 0001 | BATCH 0680 \\ 0145 | LOSS 0.0939\n","Validation: EPOCH 0001 / 0001 | BATCH 0681 \\ 0145 | LOSS 0.0942\n","Validation: EPOCH 0001 / 0001 | BATCH 0682 \\ 0145 | LOSS 0.0944\n","Validation: EPOCH 0001 / 0001 | BATCH 0683 \\ 0145 | LOSS 0.0947\n","Validation: EPOCH 0001 / 0001 | BATCH 0684 \\ 0145 | LOSS 0.0951\n","Validation: EPOCH 0001 / 0001 | BATCH 0685 \\ 0145 | LOSS 0.0952\n","Validation: EPOCH 0001 / 0001 | BATCH 0686 \\ 0145 | LOSS 0.0955\n","Validation: EPOCH 0001 / 0001 | BATCH 0687 \\ 0145 | LOSS 0.0956\n","Validation: EPOCH 0001 / 0001 | BATCH 0688 \\ 0145 | LOSS 0.0957\n","Validation: EPOCH 0001 / 0001 | BATCH 0689 \\ 0145 | LOSS 0.0957\n","Validation: EPOCH 0001 / 0001 | BATCH 0690 \\ 0145 | LOSS 0.0962\n","Validation: EPOCH 0001 / 0001 | BATCH 0691 \\ 0145 | LOSS 0.0963\n","Validation: EPOCH 0001 / 0001 | BATCH 0692 \\ 0145 | LOSS 0.0963\n","Validation: EPOCH 0001 / 0001 | BATCH 0693 \\ 0145 | LOSS 0.0964\n","Validation: EPOCH 0001 / 0001 | BATCH 0694 \\ 0145 | LOSS 0.0965\n","Validation: EPOCH 0001 / 0001 | BATCH 0695 \\ 0145 | LOSS 0.0969\n","Validation: EPOCH 0001 / 0001 | BATCH 0696 \\ 0145 | LOSS 0.0973\n","Validation: EPOCH 0001 / 0001 | BATCH 0697 \\ 0145 | LOSS 0.0979\n","Validation: EPOCH 0001 / 0001 | BATCH 0698 \\ 0145 | LOSS 0.0980\n","Validation: EPOCH 0001 / 0001 | BATCH 0699 \\ 0145 | LOSS 0.0981\n","Validation: EPOCH 0001 / 0001 | BATCH 0700 \\ 0145 | LOSS 0.0982\n","Validation: EPOCH 0001 / 0001 | BATCH 0701 \\ 0145 | LOSS 0.0983\n","Validation: EPOCH 0001 / 0001 | BATCH 0702 \\ 0145 | LOSS 0.0985\n","Validation: EPOCH 0001 / 0001 | BATCH 0703 \\ 0145 | LOSS 0.0989\n","Validation: EPOCH 0001 / 0001 | BATCH 0704 \\ 0145 | LOSS 0.0991\n","Validation: EPOCH 0001 / 0001 | BATCH 0705 \\ 0145 | LOSS 0.0995\n","Validation: EPOCH 0001 / 0001 | BATCH 0706 \\ 0145 | LOSS 0.0995\n","Validation: EPOCH 0001 / 0001 | BATCH 0707 \\ 0145 | LOSS 0.0996\n","Validation: EPOCH 0001 / 0001 | BATCH 0708 \\ 0145 | LOSS 0.0995\n","Validation: EPOCH 0001 / 0001 | BATCH 0709 \\ 0145 | LOSS 0.0997\n","Validation: EPOCH 0001 / 0001 | BATCH 0710 \\ 0145 | LOSS 0.0999\n","Validation: EPOCH 0001 / 0001 | BATCH 0711 \\ 0145 | LOSS 0.1001\n","Validation: EPOCH 0001 / 0001 | BATCH 0712 \\ 0145 | LOSS 0.1004\n","Validation: EPOCH 0001 / 0001 | BATCH 0713 \\ 0145 | LOSS 0.1007\n","Validation: EPOCH 0001 / 0001 | BATCH 0714 \\ 0145 | LOSS 0.1013\n","Validation: EPOCH 0001 / 0001 | BATCH 0715 \\ 0145 | LOSS 0.1016\n","Validation: EPOCH 0001 / 0001 | BATCH 0716 \\ 0145 | LOSS 0.1015\n","Validation: EPOCH 0001 / 0001 | BATCH 0717 \\ 0145 | LOSS 0.1017\n","Validation: EPOCH 0001 / 0001 | BATCH 0718 \\ 0145 | LOSS 0.1021\n","Validation: EPOCH 0001 / 0001 | BATCH 0719 \\ 0145 | LOSS 0.1024\n","Validation: EPOCH 0001 / 0001 | BATCH 0720 \\ 0145 | LOSS 0.1025\n","Validation: EPOCH 0001 / 0001 | BATCH 0721 \\ 0145 | LOSS 0.1027\n","Validation: EPOCH 0001 / 0001 | BATCH 0722 \\ 0145 | LOSS 0.1028\n","Validation: EPOCH 0001 / 0001 | BATCH 0723 \\ 0145 | LOSS 0.1029\n","Validation: EPOCH 0001 / 0001 | BATCH 0724 \\ 0145 | LOSS 0.1031\n","Validation: EPOCH 0001 / 0001 | BATCH 0725 \\ 0145 | LOSS 0.1035\n","Validation: EPOCH 0001 / 0001 | BATCH 0726 \\ 0145 | LOSS 0.1036\n","Validation: EPOCH 0001 / 0001 | BATCH 0727 \\ 0145 | LOSS 0.1039\n","Validation: EPOCH 0001 / 0001 | BATCH 0728 \\ 0145 | LOSS 0.1040\n","Validation: EPOCH 0001 / 0001 | BATCH 0729 \\ 0145 | LOSS 0.1040\n","Validation: EPOCH 0001 / 0001 | BATCH 0730 \\ 0145 | LOSS 0.1042\n","Validation: EPOCH 0001 / 0001 | BATCH 0731 \\ 0145 | LOSS 0.1043\n","Validation: EPOCH 0001 / 0001 | BATCH 0732 \\ 0145 | LOSS 0.1043\n","Validation: EPOCH 0001 / 0001 | BATCH 0733 \\ 0145 | LOSS 0.1043\n","Validation: EPOCH 0001 / 0001 | BATCH 0734 \\ 0145 | LOSS 0.1044\n","Validation: EPOCH 0001 / 0001 | BATCH 0735 \\ 0145 | LOSS 0.1046\n","Validation: EPOCH 0001 / 0001 | BATCH 0736 \\ 0145 | LOSS 0.1046\n","Validation: EPOCH 0001 / 0001 | BATCH 0737 \\ 0145 | LOSS 0.1048\n","Validation: EPOCH 0001 / 0001 | BATCH 0738 \\ 0145 | LOSS 0.1050\n","Validation: EPOCH 0001 / 0001 | BATCH 0739 \\ 0145 | LOSS 0.1050\n","Validation: EPOCH 0001 / 0001 | BATCH 0740 \\ 0145 | LOSS 0.1051\n","Validation: EPOCH 0001 / 0001 | BATCH 0741 \\ 0145 | LOSS 0.1051\n","Validation: EPOCH 0001 / 0001 | BATCH 0742 \\ 0145 | LOSS 0.1051\n","Validation: EPOCH 0001 / 0001 | BATCH 0743 \\ 0145 | LOSS 0.1051\n","Validation: EPOCH 0001 / 0001 | BATCH 0744 \\ 0145 | LOSS 0.1055\n","Validation: EPOCH 0001 / 0001 | BATCH 0745 \\ 0145 | LOSS 0.1055\n","Validation: EPOCH 0001 / 0001 | BATCH 0746 \\ 0145 | LOSS 0.1057\n","Validation: EPOCH 0001 / 0001 | BATCH 0747 \\ 0145 | LOSS 0.1057\n","Validation: EPOCH 0001 / 0001 | BATCH 0748 \\ 0145 | LOSS 0.1059\n","Validation: EPOCH 0001 / 0001 | BATCH 0749 \\ 0145 | LOSS 0.1059\n","Validation: EPOCH 0001 / 0001 | BATCH 0750 \\ 0145 | LOSS 0.1059\n","Validation: EPOCH 0001 / 0001 | BATCH 0751 \\ 0145 | LOSS 0.1061\n","Validation: EPOCH 0001 / 0001 | BATCH 0752 \\ 0145 | LOSS 0.1061\n","Validation: EPOCH 0001 / 0001 | BATCH 0753 \\ 0145 | LOSS 0.1063\n","Validation: EPOCH 0001 / 0001 | BATCH 0754 \\ 0145 | LOSS 0.1063\n","Validation: EPOCH 0001 / 0001 | BATCH 0755 \\ 0145 | LOSS 0.1067\n","Validation: EPOCH 0001 / 0001 | BATCH 0756 \\ 0145 | LOSS 0.1069\n","Validation: EPOCH 0001 / 0001 | BATCH 0757 \\ 0145 | LOSS 0.1068\n","Validation: EPOCH 0001 / 0001 | BATCH 0758 \\ 0145 | LOSS 0.1071\n","Validation: EPOCH 0001 / 0001 | BATCH 0759 \\ 0145 | LOSS 0.1072\n","Validation: EPOCH 0001 / 0001 | BATCH 0760 \\ 0145 | LOSS 0.1072\n","Validation: EPOCH 0001 / 0001 | BATCH 0761 \\ 0145 | LOSS 0.1072\n","Validation: EPOCH 0001 / 0001 | BATCH 0762 \\ 0145 | LOSS 0.1072\n","Validation: EPOCH 0001 / 0001 | BATCH 0763 \\ 0145 | LOSS 0.1073\n","Validation: EPOCH 0001 / 0001 | BATCH 0764 \\ 0145 | LOSS 0.1073\n","Validation: EPOCH 0001 / 0001 | BATCH 0765 \\ 0145 | LOSS 0.1075\n","Validation: EPOCH 0001 / 0001 | BATCH 0766 \\ 0145 | LOSS 0.1075\n","Validation: EPOCH 0001 / 0001 | BATCH 0767 \\ 0145 | LOSS 0.1076\n","Validation: EPOCH 0001 / 0001 | BATCH 0768 \\ 0145 | LOSS 0.1076\n","Validation: EPOCH 0001 / 0001 | BATCH 0769 \\ 0145 | LOSS 0.1076\n","Validation: EPOCH 0001 / 0001 | BATCH 0770 \\ 0145 | LOSS 0.1076\n","Validation: EPOCH 0001 / 0001 | BATCH 0771 \\ 0145 | LOSS 0.1079\n","Validation: EPOCH 0001 / 0001 | BATCH 0772 \\ 0145 | LOSS 0.1084\n","Validation: EPOCH 0001 / 0001 | BATCH 0773 \\ 0145 | LOSS 0.1085\n","Validation: EPOCH 0001 / 0001 | BATCH 0774 \\ 0145 | LOSS 0.1085\n","Validation: EPOCH 0001 / 0001 | BATCH 0775 \\ 0145 | LOSS 0.1086\n","Validation: EPOCH 0001 / 0001 | BATCH 0776 \\ 0145 | LOSS 0.1087\n","Validation: EPOCH 0001 / 0001 | BATCH 0777 \\ 0145 | LOSS 0.1092\n","Validation: EPOCH 0001 / 0001 | BATCH 0778 \\ 0145 | LOSS 0.1092\n","Validation: EPOCH 0001 / 0001 | BATCH 0779 \\ 0145 | LOSS 0.1093\n","Validation: EPOCH 0001 / 0001 | BATCH 0780 \\ 0145 | LOSS 0.1094\n","Validation: EPOCH 0001 / 0001 | BATCH 0781 \\ 0145 | LOSS 0.1096\n","Validation: EPOCH 0001 / 0001 | BATCH 0782 \\ 0145 | LOSS 0.1097\n","Validation: EPOCH 0001 / 0001 | BATCH 0783 \\ 0145 | LOSS 0.1099\n","Validation: EPOCH 0001 / 0001 | BATCH 0784 \\ 0145 | LOSS 0.1100\n","Validation: EPOCH 0001 / 0001 | BATCH 0785 \\ 0145 | LOSS 0.1103\n","Validation: EPOCH 0001 / 0001 | BATCH 0786 \\ 0145 | LOSS 0.1102\n","Validation: EPOCH 0001 / 0001 | BATCH 0787 \\ 0145 | LOSS 0.1103\n","Validation: EPOCH 0001 / 0001 | BATCH 0788 \\ 0145 | LOSS 0.1105\n","Validation: EPOCH 0001 / 0001 | BATCH 0789 \\ 0145 | LOSS 0.1105\n","Validation: EPOCH 0001 / 0001 | BATCH 0790 \\ 0145 | LOSS 0.1105\n","Validation: EPOCH 0001 / 0001 | BATCH 0791 \\ 0145 | LOSS 0.1105\n","Validation: EPOCH 0001 / 0001 | BATCH 0792 \\ 0145 | LOSS 0.1107\n","Validation: EPOCH 0001 / 0001 | BATCH 0793 \\ 0145 | LOSS 0.1107\n","Validation: EPOCH 0001 / 0001 | BATCH 0794 \\ 0145 | LOSS 0.1107\n","Validation: EPOCH 0001 / 0001 | BATCH 0795 \\ 0145 | LOSS 0.1108\n","Validation: EPOCH 0001 / 0001 | BATCH 0796 \\ 0145 | LOSS 0.1109\n","Validation: EPOCH 0001 / 0001 | BATCH 0797 \\ 0145 | LOSS 0.1109\n","Validation: EPOCH 0001 / 0001 | BATCH 0798 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0799 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0800 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0801 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0802 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0803 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0804 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0805 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0806 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0807 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0808 \\ 0145 | LOSS 0.1112\n","Validation: EPOCH 0001 / 0001 | BATCH 0809 \\ 0145 | LOSS 0.1112\n","Validation: EPOCH 0001 / 0001 | BATCH 0810 \\ 0145 | LOSS 0.1113\n","Validation: EPOCH 0001 / 0001 | BATCH 0811 \\ 0145 | LOSS 0.1112\n","Validation: EPOCH 0001 / 0001 | BATCH 0812 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0813 \\ 0145 | LOSS 0.1113\n","Validation: EPOCH 0001 / 0001 | BATCH 0814 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0815 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0816 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0817 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0818 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0819 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0820 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0821 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0822 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0823 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0824 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0825 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0826 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0827 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0828 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0829 \\ 0145 | LOSS 0.1113\n","Validation: EPOCH 0001 / 0001 | BATCH 0830 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0831 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0832 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0833 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0834 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0835 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0836 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0837 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0838 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0839 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0840 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0841 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0842 \\ 0145 | LOSS 0.1118\n","Validation: EPOCH 0001 / 0001 | BATCH 0843 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0844 \\ 0145 | LOSS 0.1120\n","Validation: EPOCH 0001 / 0001 | BATCH 0845 \\ 0145 | LOSS 0.1120\n","Validation: EPOCH 0001 / 0001 | BATCH 0846 \\ 0145 | LOSS 0.1119\n","Validation: EPOCH 0001 / 0001 | BATCH 0847 \\ 0145 | LOSS 0.1118\n","Validation: EPOCH 0001 / 0001 | BATCH 0848 \\ 0145 | LOSS 0.1117\n","Validation: EPOCH 0001 / 0001 | BATCH 0849 \\ 0145 | LOSS 0.1116\n","Validation: EPOCH 0001 / 0001 | BATCH 0850 \\ 0145 | LOSS 0.1115\n","Validation: EPOCH 0001 / 0001 | BATCH 0851 \\ 0145 | LOSS 0.1114\n","Validation: EPOCH 0001 / 0001 | BATCH 0852 \\ 0145 | LOSS 0.1113\n","Validation: EPOCH 0001 / 0001 | BATCH 0853 \\ 0145 | LOSS 0.1112\n","Validation: EPOCH 0001 / 0001 | BATCH 0854 \\ 0145 | LOSS 0.1111\n","Validation: EPOCH 0001 / 0001 | BATCH 0855 \\ 0145 | LOSS 0.1110\n","Validation: EPOCH 0001 / 0001 | BATCH 0856 \\ 0145 | LOSS 0.1109\n","Validation: EPOCH 0001 / 0001 | BATCH 0857 \\ 0145 | LOSS 0.1108\n","Validation: EPOCH 0001 / 0001 | BATCH 0858 \\ 0145 | LOSS 0.1107\n","Validation: EPOCH 0001 / 0001 | BATCH 0859 \\ 0145 | LOSS 0.1106\n","Validation: EPOCH 0001 / 0001 | BATCH 0860 \\ 0145 | LOSS 0.1105\n","Validation: EPOCH 0001 / 0001 | BATCH 0861 \\ 0145 | LOSS 0.1104\n","Validation: EPOCH 0001 / 0001 | BATCH 0862 \\ 0145 | LOSS 0.1104\n","Validation: EPOCH 0001 / 0001 | BATCH 0863 \\ 0145 | LOSS 0.1103\n","Validation: EPOCH 0001 / 0001 | BATCH 0864 \\ 0145 | LOSS 0.1102\n","Validation: EPOCH 0001 / 0001 | BATCH 0865 \\ 0145 | LOSS 0.1101\n","Validation: EPOCH 0001 / 0001 | BATCH 0866 \\ 0145 | LOSS 0.1100\n","Validation: EPOCH 0001 / 0001 | BATCH 0867 \\ 0145 | LOSS 0.1099\n","Validation: EPOCH 0001 / 0001 | BATCH 0868 \\ 0145 | LOSS 0.1098\n","Validation: EPOCH 0001 / 0001 | BATCH 0869 \\ 0145 | LOSS 0.1097\n","Validation: EPOCH 0001 / 0001 | BATCH 0870 \\ 0145 | LOSS 0.1096\n","Validation: EPOCH 0001 / 0001 | BATCH 0871 \\ 0145 | LOSS 0.1095\n","Validation: EPOCH 0001 / 0001 | BATCH 0872 \\ 0145 | LOSS 0.1094\n","Validation: EPOCH 0001 / 0001 | BATCH 0873 \\ 0145 | LOSS 0.1094\n","Validation: EPOCH 0001 / 0001 | BATCH 0874 \\ 0145 | LOSS 0.1093\n","Validation: EPOCH 0001 / 0001 | BATCH 0875 \\ 0145 | LOSS 0.1092\n","Validation: EPOCH 0001 / 0001 | BATCH 0876 \\ 0145 | LOSS 0.1091\n","Validation: EPOCH 0001 / 0001 | BATCH 0877 \\ 0145 | LOSS 0.1090\n","Validation: EPOCH 0001 / 0001 | BATCH 0878 \\ 0145 | LOSS 0.1088\n","Validation: EPOCH 0001 / 0001 | BATCH 0879 \\ 0145 | LOSS 0.1087\n","Validation: EPOCH 0001 / 0001 | BATCH 0880 \\ 0145 | LOSS 0.1086\n","Validation: EPOCH 0001 / 0001 | BATCH 0881 \\ 0145 | LOSS 0.1085\n","Validation: EPOCH 0001 / 0001 | BATCH 0882 \\ 0145 | LOSS 0.1084\n","Validation: EPOCH 0001 / 0001 | BATCH 0883 \\ 0145 | LOSS 0.1084\n","Validation: EPOCH 0001 / 0001 | BATCH 0884 \\ 0145 | LOSS 0.1083\n","Validation: EPOCH 0001 / 0001 | BATCH 0885 \\ 0145 | LOSS 0.1082\n","Validation: EPOCH 0001 / 0001 | BATCH 0886 \\ 0145 | LOSS 0.1081\n","Validation: EPOCH 0001 / 0001 | BATCH 0887 \\ 0145 | LOSS 0.1080\n","Validation: EPOCH 0001 / 0001 | BATCH 0888 \\ 0145 | LOSS 0.1079\n","Validation: EPOCH 0001 / 0001 | BATCH 0889 \\ 0145 | LOSS 0.1079\n","Validation: EPOCH 0001 / 0001 | BATCH 0890 \\ 0145 | LOSS 0.1078\n","Validation: EPOCH 0001 / 0001 | BATCH 0891 \\ 0145 | LOSS 0.1077\n","Validation: EPOCH 0001 / 0001 | BATCH 0892 \\ 0145 | LOSS 0.1076\n","Validation: EPOCH 0001 / 0001 | BATCH 0893 \\ 0145 | LOSS 0.1075\n","Validation: EPOCH 0001 / 0001 | BATCH 0894 \\ 0145 | LOSS 0.1075\n","Validation: EPOCH 0001 / 0001 | BATCH 0895 \\ 0145 | LOSS 0.1074\n","Validation: EPOCH 0001 / 0001 | BATCH 0896 \\ 0145 | LOSS 0.1073\n","Validation: EPOCH 0001 / 0001 | BATCH 0897 \\ 0145 | LOSS 0.1072\n","Validation: EPOCH 0001 / 0001 | BATCH 0898 \\ 0145 | LOSS 0.1071\n","Validation: EPOCH 0001 / 0001 | BATCH 0899 \\ 0145 | LOSS 0.1070\n","Validation: EPOCH 0001 / 0001 | BATCH 0900 \\ 0145 | LOSS 0.1069\n","Validation: EPOCH 0001 / 0001 | BATCH 0901 \\ 0145 | LOSS 0.1068\n","Validation: EPOCH 0001 / 0001 | BATCH 0902 \\ 0145 | LOSS 0.1067\n","Validation: EPOCH 0001 / 0001 | BATCH 0903 \\ 0145 | LOSS 0.1066\n","Validation: EPOCH 0001 / 0001 | BATCH 0904 \\ 0145 | LOSS 0.1066\n","Validation: EPOCH 0001 / 0001 | BATCH 0905 \\ 0145 | LOSS 0.1065\n","Validation: EPOCH 0001 / 0001 | BATCH 0906 \\ 0145 | LOSS 0.1064\n","Validation: EPOCH 0001 / 0001 | BATCH 0907 \\ 0145 | LOSS 0.1063\n","Validation: EPOCH 0001 / 0001 | BATCH 0908 \\ 0145 | LOSS 0.1062\n","Validation: EPOCH 0001 / 0001 | BATCH 0909 \\ 0145 | LOSS 0.1061\n","Validation: EPOCH 0001 / 0001 | BATCH 0910 \\ 0145 | LOSS 0.1061\n","Validation: EPOCH 0001 / 0001 | BATCH 0911 \\ 0145 | LOSS 0.1060\n","Validation: EPOCH 0001 / 0001 | BATCH 0912 \\ 0145 | LOSS 0.1059\n","Validation: EPOCH 0001 / 0001 | BATCH 0913 \\ 0145 | LOSS 0.1058\n","Validation: EPOCH 0001 / 0001 | BATCH 0914 \\ 0145 | LOSS 0.1057\n","Validation: EPOCH 0001 / 0001 | BATCH 0915 \\ 0145 | LOSS 0.1056\n","Validation: EPOCH 0001 / 0001 | BATCH 0916 \\ 0145 | LOSS 0.1055\n","Validation: EPOCH 0001 / 0001 | BATCH 0917 \\ 0145 | LOSS 0.1055\n","Validation: EPOCH 0001 / 0001 | BATCH 0918 \\ 0145 | LOSS 0.1054\n","Validation: EPOCH 0001 / 0001 | BATCH 0919 \\ 0145 | LOSS 0.1053\n","Validation: EPOCH 0001 / 0001 | BATCH 0920 \\ 0145 | LOSS 0.1052\n","Validation: EPOCH 0001 / 0001 | BATCH 0921 \\ 0145 | LOSS 0.1051\n","Validation: EPOCH 0001 / 0001 | BATCH 0922 \\ 0145 | LOSS 0.1050\n","Validation: EPOCH 0001 / 0001 | BATCH 0923 \\ 0145 | LOSS 0.1049\n","Validation: EPOCH 0001 / 0001 | BATCH 0924 \\ 0145 | LOSS 0.1048\n","Validation: EPOCH 0001 / 0001 | BATCH 0925 \\ 0145 | LOSS 0.1048\n","Validation: EPOCH 0001 / 0001 | BATCH 0926 \\ 0145 | LOSS 0.1047\n","Validation: EPOCH 0001 / 0001 | BATCH 0927 \\ 0145 | LOSS 0.1046\n","Validation: EPOCH 0001 / 0001 | BATCH 0928 \\ 0145 | LOSS 0.1045\n","Validation: EPOCH 0001 / 0001 | BATCH 0929 \\ 0145 | LOSS 0.1044\n","Validation: EPOCH 0001 / 0001 | BATCH 0930 \\ 0145 | LOSS 0.1043\n","Validation: EPOCH 0001 / 0001 | BATCH 0931 \\ 0145 | LOSS 0.1042\n","Validation: EPOCH 0001 / 0001 | BATCH 0932 \\ 0145 | LOSS 0.1041\n","Validation: EPOCH 0001 / 0001 | BATCH 0933 \\ 0145 | LOSS 0.1040\n","Validation: EPOCH 0001 / 0001 | BATCH 0934 \\ 0145 | LOSS 0.1039\n","Validation: EPOCH 0001 / 0001 | BATCH 0935 \\ 0145 | LOSS 0.1038\n","Validation: EPOCH 0001 / 0001 | BATCH 0936 \\ 0145 | LOSS 0.1038\n","Validation: EPOCH 0001 / 0001 | BATCH 0937 \\ 0145 | LOSS 0.1037\n","Validation: EPOCH 0001 / 0001 | BATCH 0938 \\ 0145 | LOSS 0.1036\n","Validation: EPOCH 0001 / 0001 | BATCH 0939 \\ 0145 | LOSS 0.1036\n","Validation: EPOCH 0001 / 0001 | BATCH 0940 \\ 0145 | LOSS 0.1035\n","Validation: EPOCH 0001 / 0001 | BATCH 0941 \\ 0145 | LOSS 0.1034\n","Validation: EPOCH 0001 / 0001 | BATCH 0942 \\ 0145 | LOSS 0.1034\n","Validation: EPOCH 0001 / 0001 | BATCH 0943 \\ 0145 | LOSS 0.1033\n","Validation: EPOCH 0001 / 0001 | BATCH 0944 \\ 0145 | LOSS 0.1032\n","Validation: EPOCH 0001 / 0001 | BATCH 0945 \\ 0145 | LOSS 0.1031\n","Validation: EPOCH 0001 / 0001 | BATCH 0946 \\ 0145 | LOSS 0.1030\n","Validation: EPOCH 0001 / 0001 | BATCH 0947 \\ 0145 | LOSS 0.1029\n","Validation: EPOCH 0001 / 0001 | BATCH 0948 \\ 0145 | LOSS 0.1029\n","Validation: EPOCH 0001 / 0001 | BATCH 0949 \\ 0145 | LOSS 0.1028\n","Validation: EPOCH 0001 / 0001 | BATCH 0950 \\ 0145 | LOSS 0.1027\n","Validation: EPOCH 0001 / 0001 | BATCH 0951 \\ 0145 | LOSS 0.1026\n","Validation: EPOCH 0001 / 0001 | BATCH 0952 \\ 0145 | LOSS 0.1026\n","Validation: EPOCH 0001 / 0001 | BATCH 0953 \\ 0145 | LOSS 0.1025\n","Validation: EPOCH 0001 / 0001 | BATCH 0954 \\ 0145 | LOSS 0.1024\n","Validation: EPOCH 0001 / 0001 | BATCH 0955 \\ 0145 | LOSS 0.1023\n","Validation: EPOCH 0001 / 0001 | BATCH 0956 \\ 0145 | LOSS 0.1022\n","Validation: EPOCH 0001 / 0001 | BATCH 0957 \\ 0145 | LOSS 0.1021\n","Validation: EPOCH 0001 / 0001 | BATCH 0958 \\ 0145 | LOSS 0.1020\n","Validation: EPOCH 0001 / 0001 | BATCH 0959 \\ 0145 | LOSS 0.1019\n","Validation: EPOCH 0001 / 0001 | BATCH 0960 \\ 0145 | LOSS 0.1019\n","Validation: EPOCH 0001 / 0001 | BATCH 0961 \\ 0145 | LOSS 0.1018\n","Validation: EPOCH 0001 / 0001 | BATCH 0962 \\ 0145 | LOSS 0.1017\n","Validation: EPOCH 0001 / 0001 | BATCH 0963 \\ 0145 | LOSS 0.1016\n","Validation: EPOCH 0001 / 0001 | BATCH 0964 \\ 0145 | LOSS 0.1016\n","Validation: EPOCH 0001 / 0001 | BATCH 0965 \\ 0145 | LOSS 0.1015\n","Validation: EPOCH 0001 / 0001 | BATCH 0966 \\ 0145 | LOSS 0.1014\n","Validation: EPOCH 0001 / 0001 | BATCH 0967 \\ 0145 | LOSS 0.1013\n","Validation: EPOCH 0001 / 0001 | BATCH 0968 \\ 0145 | LOSS 0.1013\n","Validation: EPOCH 0001 / 0001 | BATCH 0969 \\ 0145 | LOSS 0.1012\n","Validation: EPOCH 0001 / 0001 | BATCH 0970 \\ 0145 | LOSS 0.1011\n","Validation: EPOCH 0001 / 0001 | BATCH 0971 \\ 0145 | LOSS 0.1010\n","Validation: EPOCH 0001 / 0001 | BATCH 0972 \\ 0145 | LOSS 0.1009\n","Validation: EPOCH 0001 / 0001 | BATCH 0973 \\ 0145 | LOSS 0.1009\n","Validation: EPOCH 0001 / 0001 | BATCH 0974 \\ 0145 | LOSS 0.1008\n","Validation: EPOCH 0001 / 0001 | BATCH 0975 \\ 0145 | LOSS 0.1007\n","Validation: EPOCH 0001 / 0001 | BATCH 0976 \\ 0145 | LOSS 0.1006\n","Validation: EPOCH 0001 / 0001 | BATCH 0977 \\ 0145 | LOSS 0.1005\n","Validation: EPOCH 0001 / 0001 | BATCH 0978 \\ 0145 | LOSS 0.1005\n","Validation: EPOCH 0001 / 0001 | BATCH 0979 \\ 0145 | LOSS 0.1004\n","Validation: EPOCH 0001 / 0001 | BATCH 0980 \\ 0145 | LOSS 0.1003\n","Validation: EPOCH 0001 / 0001 | BATCH 0981 \\ 0145 | LOSS 0.1002\n","Validation: EPOCH 0001 / 0001 | BATCH 0982 \\ 0145 | LOSS 0.1002\n","Validation: EPOCH 0001 / 0001 | BATCH 0983 \\ 0145 | LOSS 0.1001\n","Validation: EPOCH 0001 / 0001 | BATCH 0984 \\ 0145 | LOSS 0.1000\n","Validation: EPOCH 0001 / 0001 | BATCH 0985 \\ 0145 | LOSS 0.0999\n","Validation: EPOCH 0001 / 0001 | BATCH 0986 \\ 0145 | LOSS 0.0999\n","Validation: EPOCH 0001 / 0001 | BATCH 0987 \\ 0145 | LOSS 0.0998\n","Validation: EPOCH 0001 / 0001 | BATCH 0988 \\ 0145 | LOSS 0.0997\n","Validation: EPOCH 0001 / 0001 | BATCH 0989 \\ 0145 | LOSS 0.0997\n","Validation: EPOCH 0001 / 0001 | BATCH 0990 \\ 0145 | LOSS 0.0996\n","Validation: EPOCH 0001 / 0001 | BATCH 0991 \\ 0145 | LOSS 0.0995\n","Validation: EPOCH 0001 / 0001 | BATCH 0992 \\ 0145 | LOSS 0.0994\n","Validation: EPOCH 0001 / 0001 | BATCH 0993 \\ 0145 | LOSS 0.0994\n","Validation: EPOCH 0001 / 0001 | BATCH 0994 \\ 0145 | LOSS 0.0993\n","Validation: EPOCH 0001 / 0001 | BATCH 0995 \\ 0145 | LOSS 0.0993\n","Validation: EPOCH 0001 / 0001 | BATCH 0996 \\ 0145 | LOSS 0.0992\n","Validation: EPOCH 0001 / 0001 | BATCH 0997 \\ 0145 | LOSS 0.0991\n","Validation: EPOCH 0001 / 0001 | BATCH 0998 \\ 0145 | LOSS 0.0990\n","Validation: EPOCH 0001 / 0001 | BATCH 0999 \\ 0145 | LOSS 0.0989\n","Validation: EPOCH 0001 / 0001 | BATCH 1000 \\ 0145 | LOSS 0.0989\n","Validation: EPOCH 0001 / 0001 | BATCH 1001 \\ 0145 | LOSS 0.0988\n","Validation: EPOCH 0001 / 0001 | BATCH 1002 \\ 0145 | LOSS 0.0987\n","Validation: EPOCH 0001 / 0001 | BATCH 1003 \\ 0145 | LOSS 0.0986\n","Validation: EPOCH 0001 / 0001 | BATCH 1004 \\ 0145 | LOSS 0.0986\n","Validation: EPOCH 0001 / 0001 | BATCH 1005 \\ 0145 | LOSS 0.0985\n","Validation: EPOCH 0001 / 0001 | BATCH 1006 \\ 0145 | LOSS 0.0984\n","Validation: EPOCH 0001 / 0001 | BATCH 1007 \\ 0145 | LOSS 0.0984\n","Validation: EPOCH 0001 / 0001 | BATCH 1008 \\ 0145 | LOSS 0.0983\n","Validation: EPOCH 0001 / 0001 | BATCH 1009 \\ 0145 | LOSS 0.0982\n","Validation: EPOCH 0001 / 0001 | BATCH 1010 \\ 0145 | LOSS 0.0982\n","Validation: EPOCH 0001 / 0001 | BATCH 1011 \\ 0145 | LOSS 0.0981\n","Validation: EPOCH 0001 / 0001 | BATCH 1012 \\ 0145 | LOSS 0.0981\n","Validation: EPOCH 0001 / 0001 | BATCH 1013 \\ 0145 | LOSS 0.0980\n","Validation: EPOCH 0001 / 0001 | BATCH 1014 \\ 0145 | LOSS 0.0979\n","Validation: EPOCH 0001 / 0001 | BATCH 1015 \\ 0145 | LOSS 0.0979\n","Validation: EPOCH 0001 / 0001 | BATCH 1016 \\ 0145 | LOSS 0.0978\n","Validation: EPOCH 0001 / 0001 | BATCH 1017 \\ 0145 | LOSS 0.0977\n","Validation: EPOCH 0001 / 0001 | BATCH 1018 \\ 0145 | LOSS 0.0977\n","Validation: EPOCH 0001 / 0001 | BATCH 1019 \\ 0145 | LOSS 0.0976\n","Validation: EPOCH 0001 / 0001 | BATCH 1020 \\ 0145 | LOSS 0.0975\n","Validation: EPOCH 0001 / 0001 | BATCH 1021 \\ 0145 | LOSS 0.0974\n","Validation: EPOCH 0001 / 0001 | BATCH 1022 \\ 0145 | LOSS 0.0973\n","Validation: EPOCH 0001 / 0001 | BATCH 1023 \\ 0145 | LOSS 0.0973\n","Validation: EPOCH 0001 / 0001 | BATCH 1024 \\ 0145 | LOSS 0.0972\n","Validation: EPOCH 0001 / 0001 | BATCH 1025 \\ 0145 | LOSS 0.0971\n","Validation: EPOCH 0001 / 0001 | BATCH 1026 \\ 0145 | LOSS 0.0971\n","Validation: EPOCH 0001 / 0001 | BATCH 1027 \\ 0145 | LOSS 0.0970\n","Validation: EPOCH 0001 / 0001 | BATCH 1028 \\ 0145 | LOSS 0.0969\n","Validation: EPOCH 0001 / 0001 | BATCH 1029 \\ 0145 | LOSS 0.0968\n","Validation: EPOCH 0001 / 0001 | BATCH 1030 \\ 0145 | LOSS 0.0968\n","Validation: EPOCH 0001 / 0001 | BATCH 1031 \\ 0145 | LOSS 0.0967\n","Validation: EPOCH 0001 / 0001 | BATCH 1032 \\ 0145 | LOSS 0.0966\n","Validation: EPOCH 0001 / 0001 | BATCH 1033 \\ 0145 | LOSS 0.0966\n","Validation: EPOCH 0001 / 0001 | BATCH 1034 \\ 0145 | LOSS 0.0965\n","Validation: EPOCH 0001 / 0001 | BATCH 1035 \\ 0145 | LOSS 0.0964\n","Validation: EPOCH 0001 / 0001 | BATCH 1036 \\ 0145 | LOSS 0.0964\n","Validation: EPOCH 0001 / 0001 | BATCH 1037 \\ 0145 | LOSS 0.0963\n","Validation: EPOCH 0001 / 0001 | BATCH 1038 \\ 0145 | LOSS 0.0962\n","Validation: EPOCH 0001 / 0001 | BATCH 1039 \\ 0145 | LOSS 0.0962\n","Validation: EPOCH 0001 / 0001 | BATCH 1040 \\ 0145 | LOSS 0.0961\n","Validation: EPOCH 0001 / 0001 | BATCH 1041 \\ 0145 | LOSS 0.0961\n","Validation: EPOCH 0001 / 0001 | BATCH 1042 \\ 0145 | LOSS 0.0960\n","Validation: EPOCH 0001 / 0001 | BATCH 1043 \\ 0145 | LOSS 0.0960\n","Validation: EPOCH 0001 / 0001 | BATCH 1044 \\ 0145 | LOSS 0.0960\n","Validation: EPOCH 0001 / 0001 | BATCH 1045 \\ 0145 | LOSS 0.0959\n","Validation: EPOCH 0001 / 0001 | BATCH 1046 \\ 0145 | LOSS 0.0958\n","Validation: EPOCH 0001 / 0001 | BATCH 1047 \\ 0145 | LOSS 0.0957\n","Validation: EPOCH 0001 / 0001 | BATCH 1048 \\ 0145 | LOSS 0.0957\n","Validation: EPOCH 0001 / 0001 | BATCH 1049 \\ 0145 | LOSS 0.0956\n","Validation: EPOCH 0001 / 0001 | BATCH 1050 \\ 0145 | LOSS 0.0955\n","Validation: EPOCH 0001 / 0001 | BATCH 1051 \\ 0145 | LOSS 0.0955\n","Validation: EPOCH 0001 / 0001 | BATCH 1052 \\ 0145 | LOSS 0.0954\n","Validation: EPOCH 0001 / 0001 | BATCH 1053 \\ 0145 | LOSS 0.0953\n","Validation: EPOCH 0001 / 0001 | BATCH 1054 \\ 0145 | LOSS 0.0952\n","Validation: EPOCH 0001 / 0001 | BATCH 1055 \\ 0145 | LOSS 0.0952\n","Validation: EPOCH 0001 / 0001 | BATCH 1056 \\ 0145 | LOSS 0.0951\n","Validation: EPOCH 0001 / 0001 | BATCH 1057 \\ 0145 | LOSS 0.0950\n","Validation: EPOCH 0001 / 0001 | BATCH 1058 \\ 0145 | LOSS 0.0949\n","Validation: EPOCH 0001 / 0001 | BATCH 1059 \\ 0145 | LOSS 0.0949\n","Validation: EPOCH 0001 / 0001 | BATCH 1060 \\ 0145 | LOSS 0.0948\n","Validation: EPOCH 0001 / 0001 | BATCH 1061 \\ 0145 | LOSS 0.0948\n","Validation: EPOCH 0001 / 0001 | BATCH 1062 \\ 0145 | LOSS 0.0947\n","Validation: EPOCH 0001 / 0001 | BATCH 1063 \\ 0145 | LOSS 0.0946\n","Validation: EPOCH 0001 / 0001 | BATCH 1064 \\ 0145 | LOSS 0.0946\n","Validation: EPOCH 0001 / 0001 | BATCH 1065 \\ 0145 | LOSS 0.0945\n","Validation: EPOCH 0001 / 0001 | BATCH 1066 \\ 0145 | LOSS 0.0945\n","Validation: EPOCH 0001 / 0001 | BATCH 1067 \\ 0145 | LOSS 0.0944\n","Validation: EPOCH 0001 / 0001 | BATCH 1068 \\ 0145 | LOSS 0.0944\n","Validation: EPOCH 0001 / 0001 | BATCH 1069 \\ 0145 | LOSS 0.0943\n","Validation: EPOCH 0001 / 0001 | BATCH 1070 \\ 0145 | LOSS 0.0942\n","Validation: EPOCH 0001 / 0001 | BATCH 1071 \\ 0145 | LOSS 0.0942\n","Validation: EPOCH 0001 / 0001 | BATCH 1072 \\ 0145 | LOSS 0.0941\n","Validation: EPOCH 0001 / 0001 | BATCH 1073 \\ 0145 | LOSS 0.0941\n","Validation: EPOCH 0001 / 0001 | BATCH 1074 \\ 0145 | LOSS 0.0940\n","Validation: EPOCH 0001 / 0001 | BATCH 1075 \\ 0145 | LOSS 0.0939\n","Validation: EPOCH 0001 / 0001 | BATCH 1076 \\ 0145 | LOSS 0.0939\n","Validation: EPOCH 0001 / 0001 | BATCH 1077 \\ 0145 | LOSS 0.0938\n","Validation: EPOCH 0001 / 0001 | BATCH 1078 \\ 0145 | LOSS 0.0938\n","Validation: EPOCH 0001 / 0001 | BATCH 1079 \\ 0145 | LOSS 0.0937\n","Validation: EPOCH 0001 / 0001 | BATCH 1080 \\ 0145 | LOSS 0.0937\n","Validation: EPOCH 0001 / 0001 | BATCH 1081 \\ 0145 | LOSS 0.0936\n","Validation: EPOCH 0001 / 0001 | BATCH 1082 \\ 0145 | LOSS 0.0936\n","Validation: EPOCH 0001 / 0001 | BATCH 1083 \\ 0145 | LOSS 0.0935\n","Validation: EPOCH 0001 / 0001 | BATCH 1084 \\ 0145 | LOSS 0.0935\n","Validation: EPOCH 0001 / 0001 | BATCH 1085 \\ 0145 | LOSS 0.0934\n","Validation: EPOCH 0001 / 0001 | BATCH 1086 \\ 0145 | LOSS 0.0934\n","Validation: EPOCH 0001 / 0001 | BATCH 1087 \\ 0145 | LOSS 0.0933\n","Validation: EPOCH 0001 / 0001 | BATCH 1088 \\ 0145 | LOSS 0.0932\n","Validation: EPOCH 0001 / 0001 | BATCH 1089 \\ 0145 | LOSS 0.0932\n","Validation: EPOCH 0001 / 0001 | BATCH 1090 \\ 0145 | LOSS 0.0931\n","Validation: EPOCH 0001 / 0001 | BATCH 1091 \\ 0145 | LOSS 0.0930\n","Validation: EPOCH 0001 / 0001 | BATCH 1092 \\ 0145 | LOSS 0.0930\n","Validation: EPOCH 0001 / 0001 | BATCH 1093 \\ 0145 | LOSS 0.0929\n","Validation: EPOCH 0001 / 0001 | BATCH 1094 \\ 0145 | LOSS 0.0929\n","Validation: EPOCH 0001 / 0001 | BATCH 1095 \\ 0145 | LOSS 0.0928\n","Validation: EPOCH 0001 / 0001 | BATCH 1096 \\ 0145 | LOSS 0.0928\n","Validation: EPOCH 0001 / 0001 | BATCH 1097 \\ 0145 | LOSS 0.0929\n","Validation: EPOCH 0001 / 0001 | BATCH 1098 \\ 0145 | LOSS 0.0928\n","Validation: EPOCH 0001 / 0001 | BATCH 1099 \\ 0145 | LOSS 0.0928\n","Validation: EPOCH 0001 / 0001 | BATCH 1100 \\ 0145 | LOSS 0.0927\n","Validation: EPOCH 0001 / 0001 | BATCH 1101 \\ 0145 | LOSS 0.0926\n","Validation: EPOCH 0001 / 0001 | BATCH 1102 \\ 0145 | LOSS 0.0926\n","Validation: EPOCH 0001 / 0001 | BATCH 1103 \\ 0145 | LOSS 0.0926\n","Validation: EPOCH 0001 / 0001 | BATCH 1104 \\ 0145 | LOSS 0.0925\n","Validation: EPOCH 0001 / 0001 | BATCH 1105 \\ 0145 | LOSS 0.0925\n","Validation: EPOCH 0001 / 0001 | BATCH 1106 \\ 0145 | LOSS 0.0924\n","Validation: EPOCH 0001 / 0001 | BATCH 1107 \\ 0145 | LOSS 0.0923\n","Validation: EPOCH 0001 / 0001 | BATCH 1108 \\ 0145 | LOSS 0.0923\n","Validation: EPOCH 0001 / 0001 | BATCH 1109 \\ 0145 | LOSS 0.0922\n","Validation: EPOCH 0001 / 0001 | BATCH 1110 \\ 0145 | LOSS 0.0922\n","Validation: EPOCH 0001 / 0001 | BATCH 1111 \\ 0145 | LOSS 0.0921\n","Validation: EPOCH 0001 / 0001 | BATCH 1112 \\ 0145 | LOSS 0.0921\n","Validation: EPOCH 0001 / 0001 | BATCH 1113 \\ 0145 | LOSS 0.0920\n","Validation: EPOCH 0001 / 0001 | BATCH 1114 \\ 0145 | LOSS 0.0920\n","Validation: EPOCH 0001 / 0001 | BATCH 1115 \\ 0145 | LOSS 0.0919\n","Validation: EPOCH 0001 / 0001 | BATCH 1116 \\ 0145 | LOSS 0.0919\n","Validation: EPOCH 0001 / 0001 | BATCH 1117 \\ 0145 | LOSS 0.0918\n","Validation: EPOCH 0001 / 0001 | BATCH 1118 \\ 0145 | LOSS 0.0918\n","Validation: EPOCH 0001 / 0001 | BATCH 1119 \\ 0145 | LOSS 0.0917\n","Validation: EPOCH 0001 / 0001 | BATCH 1120 \\ 0145 | LOSS 0.0916\n","Validation: EPOCH 0001 / 0001 | BATCH 1121 \\ 0145 | LOSS 0.0916\n","Validation: EPOCH 0001 / 0001 | BATCH 1122 \\ 0145 | LOSS 0.0915\n","Validation: EPOCH 0001 / 0001 | BATCH 1123 \\ 0145 | LOSS 0.0914\n","Validation: EPOCH 0001 / 0001 | BATCH 1124 \\ 0145 | LOSS 0.0914\n","Validation: EPOCH 0001 / 0001 | BATCH 1125 \\ 0145 | LOSS 0.0913\n","Validation: EPOCH 0001 / 0001 | BATCH 1126 \\ 0145 | LOSS 0.0912\n","Validation: EPOCH 0001 / 0001 | BATCH 1127 \\ 0145 | LOSS 0.0912\n","Validation: EPOCH 0001 / 0001 | BATCH 1128 \\ 0145 | LOSS 0.0911\n","Validation: EPOCH 0001 / 0001 | BATCH 1129 \\ 0145 | LOSS 0.0911\n","Validation: EPOCH 0001 / 0001 | BATCH 1130 \\ 0145 | LOSS 0.0910\n","Validation: EPOCH 0001 / 0001 | BATCH 1131 \\ 0145 | LOSS 0.0910\n","Validation: EPOCH 0001 / 0001 | BATCH 1132 \\ 0145 | LOSS 0.0909\n","Validation: EPOCH 0001 / 0001 | BATCH 1133 \\ 0145 | LOSS 0.0909\n","Validation: EPOCH 0001 / 0001 | BATCH 1134 \\ 0145 | LOSS 0.0908\n","Validation: EPOCH 0001 / 0001 | BATCH 1135 \\ 0145 | LOSS 0.0908\n","Validation: EPOCH 0001 / 0001 | BATCH 1136 \\ 0145 | LOSS 0.0907\n","Validation: EPOCH 0001 / 0001 | BATCH 1137 \\ 0145 | LOSS 0.0907\n","Validation: EPOCH 0001 / 0001 | BATCH 1138 \\ 0145 | LOSS 0.0906\n","Validation: EPOCH 0001 / 0001 | BATCH 1139 \\ 0145 | LOSS 0.0905\n","Validation: EPOCH 0001 / 0001 | BATCH 1140 \\ 0145 | LOSS 0.0905\n","Validation: EPOCH 0001 / 0001 | BATCH 1141 \\ 0145 | LOSS 0.0904\n","Validation: EPOCH 0001 / 0001 | BATCH 1142 \\ 0145 | LOSS 0.0904\n","Validation: EPOCH 0001 / 0001 | BATCH 1143 \\ 0145 | LOSS 0.0903\n","Validation: EPOCH 0001 / 0001 | BATCH 1144 \\ 0145 | LOSS 0.0903\n","Validation: EPOCH 0001 / 0001 | BATCH 1145 \\ 0145 | LOSS 0.0902\n","Validation: EPOCH 0001 / 0001 | BATCH 1146 \\ 0145 | LOSS 0.0902\n","Validation: EPOCH 0001 / 0001 | BATCH 1147 \\ 0145 | LOSS 0.0901\n","Validation: EPOCH 0001 / 0001 | BATCH 1148 \\ 0145 | LOSS 0.0901\n","Validation: EPOCH 0001 / 0001 | BATCH 1149 \\ 0145 | LOSS 0.0900\n","Validation: EPOCH 0001 / 0001 | BATCH 1150 \\ 0145 | LOSS 0.0900\n","Validation: EPOCH 0001 / 0001 | BATCH 1151 \\ 0145 | LOSS 0.0899\n","Validation: EPOCH 0001 / 0001 | BATCH 1152 \\ 0145 | LOSS 0.0899\n","Validation: EPOCH 0001 / 0001 | BATCH 1153 \\ 0145 | LOSS 0.0898\n"]}],"source":["!python3 '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/train.py' \\\n","--lr 1e-3 --batch_size 4 --num_epoch 1 \\\n","--data_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/datasets_npy' \\\n","--ckpt_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/checkpoint' \\\n","--log_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/log' \\\n","--result_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/results' \\\n","--mode 'train' \\\n","--train_continue 'off'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":366663,"status":"ok","timestamp":1636641847015,"user":{"displayName":"이혁","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ght-yr-bTsO_ykcEl-fzdbbP8xb8FENKF76913C=s64","userId":"03546437808129049357"},"user_tz":-540},"id":"-ao_p3cqonsm","outputId":"879efc83-9314-4f10-fdf1-e06afee9e3de"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","TEST: BATCH 0001 \\ 0144 | LOSS 0.0138\n","TEST: BATCH 0002 \\ 0144 | LOSS 0.0134\n","TEST: BATCH 0003 \\ 0144 | LOSS 0.0580\n","TEST: BATCH 0004 \\ 0144 | LOSS 0.1272\n","TEST: BATCH 0005 \\ 0144 | LOSS 0.1100\n","TEST: BATCH 0006 \\ 0144 | LOSS 0.1042\n","TEST: BATCH 0007 \\ 0144 | LOSS 0.0923\n","TEST: BATCH 0008 \\ 0144 | LOSS 0.0834\n","TEST: BATCH 0009 \\ 0144 | LOSS 0.0766\n","TEST: BATCH 0010 \\ 0144 | LOSS 0.0722\n","TEST: BATCH 0011 \\ 0144 | LOSS 0.0715\n","TEST: BATCH 0012 \\ 0144 | LOSS 0.0676\n","TEST: BATCH 0013 \\ 0144 | LOSS 0.0640\n","TEST: BATCH 0014 \\ 0144 | LOSS 0.0676\n","TEST: BATCH 0015 \\ 0144 | LOSS 0.0668\n","TEST: BATCH 0016 \\ 0144 | LOSS 0.0635\n","TEST: BATCH 0017 \\ 0144 | LOSS 0.0691\n","TEST: BATCH 0018 \\ 0144 | LOSS 0.0721\n","TEST: BATCH 0019 \\ 0144 | LOSS 0.0718\n","TEST: BATCH 0020 \\ 0144 | LOSS 0.0690\n","TEST: BATCH 0021 \\ 0144 | LOSS 0.0668\n","TEST: BATCH 0022 \\ 0144 | LOSS 0.0646\n","TEST: BATCH 0023 \\ 0144 | LOSS 0.0632\n","TEST: BATCH 0024 \\ 0144 | LOSS 0.0622\n","TEST: BATCH 0025 \\ 0144 | LOSS 0.0622\n","TEST: BATCH 0026 \\ 0144 | LOSS 0.0612\n","TEST: BATCH 0027 \\ 0144 | LOSS 0.0606\n","TEST: BATCH 0028 \\ 0144 | LOSS 0.0624\n","TEST: BATCH 0029 \\ 0144 | LOSS 0.0614\n","TEST: BATCH 0030 \\ 0144 | LOSS 0.0620\n","TEST: BATCH 0031 \\ 0144 | LOSS 0.0604\n","TEST: BATCH 0032 \\ 0144 | LOSS 0.0601\n","TEST: BATCH 0033 \\ 0144 | LOSS 0.0589\n","TEST: BATCH 0034 \\ 0144 | LOSS 0.0582\n","TEST: BATCH 0035 \\ 0144 | LOSS 0.0570\n","TEST: BATCH 0036 \\ 0144 | LOSS 0.0604\n","TEST: BATCH 0037 \\ 0144 | LOSS 0.0606\n","TEST: BATCH 0038 \\ 0144 | LOSS 0.0597\n","TEST: BATCH 0039 \\ 0144 | LOSS 0.0586\n","TEST: BATCH 0040 \\ 0144 | LOSS 0.0577\n","TEST: BATCH 0041 \\ 0144 | LOSS 0.0572\n","TEST: BATCH 0042 \\ 0144 | LOSS 0.0576\n","TEST: BATCH 0043 \\ 0144 | LOSS 0.0566\n","TEST: BATCH 0044 \\ 0144 | LOSS 0.0565\n","TEST: BATCH 0045 \\ 0144 | LOSS 0.0561\n","TEST: BATCH 0046 \\ 0144 | LOSS 0.0562\n","TEST: BATCH 0047 \\ 0144 | LOSS 0.0555\n","TEST: BATCH 0048 \\ 0144 | LOSS 0.0570\n","TEST: BATCH 0049 \\ 0144 | LOSS 0.0576\n","TEST: BATCH 0050 \\ 0144 | LOSS 0.0568\n","TEST: BATCH 0051 \\ 0144 | LOSS 0.0560\n","TEST: BATCH 0052 \\ 0144 | LOSS 0.0564\n","TEST: BATCH 0053 \\ 0144 | LOSS 0.0556\n","TEST: BATCH 0054 \\ 0144 | LOSS 0.0549\n","TEST: BATCH 0055 \\ 0144 | LOSS 0.0558\n","TEST: BATCH 0056 \\ 0144 | LOSS 0.0643\n","TEST: BATCH 0057 \\ 0144 | LOSS 0.0653\n","TEST: BATCH 0058 \\ 0144 | LOSS 0.0654\n","TEST: BATCH 0059 \\ 0144 | LOSS 0.0677\n","TEST: BATCH 0060 \\ 0144 | LOSS 0.0671\n","TEST: BATCH 0061 \\ 0144 | LOSS 0.0680\n","TEST: BATCH 0062 \\ 0144 | LOSS 0.0679\n","TEST: BATCH 0063 \\ 0144 | LOSS 0.0692\n","TEST: BATCH 0064 \\ 0144 | LOSS 0.0691\n","TEST: BATCH 0065 \\ 0144 | LOSS 0.0690\n","TEST: BATCH 0066 \\ 0144 | LOSS 0.0719\n","TEST: BATCH 0067 \\ 0144 | LOSS 0.0756\n","TEST: BATCH 0068 \\ 0144 | LOSS 0.0802\n","TEST: BATCH 0069 \\ 0144 | LOSS 0.0829\n","TEST: BATCH 0070 \\ 0144 | LOSS 0.0847\n","TEST: BATCH 0071 \\ 0144 | LOSS 0.0854\n","TEST: BATCH 0072 \\ 0144 | LOSS 0.0874\n","TEST: BATCH 0073 \\ 0144 | LOSS 0.0879\n","TEST: BATCH 0074 \\ 0144 | LOSS 0.0876\n","TEST: BATCH 0075 \\ 0144 | LOSS 0.0884\n","TEST: BATCH 0076 \\ 0144 | LOSS 0.0885\n","TEST: BATCH 0077 \\ 0144 | LOSS 0.0900\n","TEST: BATCH 0078 \\ 0144 | LOSS 0.0915\n","TEST: BATCH 0079 \\ 0144 | LOSS 0.0921\n","TEST: BATCH 0080 \\ 0144 | LOSS 0.0929\n","TEST: BATCH 0081 \\ 0144 | LOSS 0.0941\n","TEST: BATCH 0082 \\ 0144 | LOSS 0.0942\n","TEST: BATCH 0083 \\ 0144 | LOSS 0.0966\n","TEST: BATCH 0084 \\ 0144 | LOSS 0.0964\n","TEST: BATCH 0085 \\ 0144 | LOSS 0.0979\n","TEST: BATCH 0086 \\ 0144 | LOSS 0.1016\n","TEST: BATCH 0087 \\ 0144 | LOSS 0.1021\n","TEST: BATCH 0088 \\ 0144 | LOSS 0.1033\n","TEST: BATCH 0089 \\ 0144 | LOSS 0.1044\n","TEST: BATCH 0090 \\ 0144 | LOSS 0.1045\n","TEST: BATCH 0091 \\ 0144 | LOSS 0.1046\n","TEST: BATCH 0092 \\ 0144 | LOSS 0.1040\n","TEST: BATCH 0093 \\ 0144 | LOSS 0.1048\n","TEST: BATCH 0094 \\ 0144 | LOSS 0.1050\n","TEST: BATCH 0095 \\ 0144 | LOSS 0.1047\n","TEST: BATCH 0096 \\ 0144 | LOSS 0.1080\n","TEST: BATCH 0097 \\ 0144 | LOSS 0.1081\n","TEST: BATCH 0098 \\ 0144 | LOSS 0.1084\n","TEST: BATCH 0099 \\ 0144 | LOSS 0.1088\n","TEST: BATCH 0100 \\ 0144 | LOSS 0.1096\n","TEST: BATCH 0101 \\ 0144 | LOSS 0.1102\n","TEST: BATCH 0102 \\ 0144 | LOSS 0.1140\n","TEST: BATCH 0103 \\ 0144 | LOSS 0.1135\n","TEST: BATCH 0104 \\ 0144 | LOSS 0.1160\n","TEST: BATCH 0105 \\ 0144 | LOSS 0.1152\n","TEST: BATCH 0106 \\ 0144 | LOSS 0.1144\n","TEST: BATCH 0107 \\ 0144 | LOSS 0.1135\n","TEST: BATCH 0108 \\ 0144 | LOSS 0.1126\n","TEST: BATCH 0109 \\ 0144 | LOSS 0.1117\n","TEST: BATCH 0110 \\ 0144 | LOSS 0.1109\n","TEST: BATCH 0111 \\ 0144 | LOSS 0.1101\n","TEST: BATCH 0112 \\ 0144 | LOSS 0.1095\n","TEST: BATCH 0113 \\ 0144 | LOSS 0.1086\n","TEST: BATCH 0114 \\ 0144 | LOSS 0.1079\n","TEST: BATCH 0115 \\ 0144 | LOSS 0.1072\n","TEST: BATCH 0116 \\ 0144 | LOSS 0.1069\n","TEST: BATCH 0117 \\ 0144 | LOSS 0.1062\n","TEST: BATCH 0118 \\ 0144 | LOSS 0.1054\n","TEST: BATCH 0119 \\ 0144 | LOSS 0.1048\n","TEST: BATCH 0120 \\ 0144 | LOSS 0.1043\n","TEST: BATCH 0121 \\ 0144 | LOSS 0.1036\n","TEST: BATCH 0122 \\ 0144 | LOSS 0.1030\n","TEST: BATCH 0123 \\ 0144 | LOSS 0.1023\n","TEST: BATCH 0124 \\ 0144 | LOSS 0.1016\n","TEST: BATCH 0125 \\ 0144 | LOSS 0.1009\n","TEST: BATCH 0126 \\ 0144 | LOSS 0.1003\n","TEST: BATCH 0127 \\ 0144 | LOSS 0.0996\n","TEST: BATCH 0128 \\ 0144 | LOSS 0.0994\n","TEST: BATCH 0129 \\ 0144 | LOSS 0.0987\n","TEST: BATCH 0130 \\ 0144 | LOSS 0.0981\n","TEST: BATCH 0131 \\ 0144 | LOSS 0.0975\n","TEST: BATCH 0132 \\ 0144 | LOSS 0.0970\n","TEST: BATCH 0133 \\ 0144 | LOSS 0.0966\n","TEST: BATCH 0134 \\ 0144 | LOSS 0.0962\n","TEST: BATCH 0135 \\ 0144 | LOSS 0.0957\n","TEST: BATCH 0136 \\ 0144 | LOSS 0.0951\n","TEST: BATCH 0137 \\ 0144 | LOSS 0.0946\n","TEST: BATCH 0138 \\ 0144 | LOSS 0.0941\n","TEST: BATCH 0139 \\ 0144 | LOSS 0.0937\n","TEST: BATCH 0140 \\ 0144 | LOSS 0.0933\n","TEST: BATCH 0141 \\ 0144 | LOSS 0.0928\n","TEST: BATCH 0142 \\ 0144 | LOSS 0.0923\n","TEST: BATCH 0143 \\ 0144 | LOSS 0.0917\n","TEST: BATCH 0144 \\ 0144 | LOSS 0.0912\n","AVERAGE TEST: BATCH 0144 \\ 0144 | LOSS 0.0912\n"]}],"source":["!python3 '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/train.py' \\\n","--lr 1e-3 --batch_size 4 --num_epoch 1 \\\n","--data_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/datasets_npy' \\\n","--ckpt_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/checkpoint' \\\n","--log_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/log' \\\n","--result_dir '/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/results' \\\n","--mode 'test' \\\n","--train_continue 'off'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"m445pfQGqcxx","outputId":"aaba64f4-3897-4277-bbc6-aa42c93f2a82"},"outputs":[{"data":{"text/plain":["Launching TensorBoard..."]},"metadata":{},"output_type":"display_data"}],"source":["tensorboard --logdir='/content/drive/MyDrive/Colab/Detecting_and_Classifying_Car_Damage/log'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oTPcTQ9PdTKQ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNi2UtEdyRYhbM8dUXxL+iO","collapsed_sections":[],"mount_file_id":"1kZWr2IJhGr5aLSmxJyfr-N-wqxuqU3_D","name":"run_unet.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}